<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Experience on Tai&#39;s Blog</title>
    <link>https://yunpengtai.top/tags/experience/</link>
    <description>Recent content in Experience on Tai&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 30 Jul 2022 19:43:00 +0800</lastBuildDate><atom:link href="https://yunpengtai.top/tags/experience/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tips for Training Neural Networks</title>
      <link>https://yunpengtai.top/posts/tips-for-training-neural-networks/</link>
      <pubDate>Sat, 30 Jul 2022 19:43:00 +0800</pubDate>
      
      <guid>https://yunpengtai.top/posts/tips-for-training-neural-networks/</guid>
      <description>Recently, I have read a blog about training neural networks (simplified as NN in the rest part of this post) and it is really amazing. I am going to add my own experience in this post along with summarizing that blog&amp;rsquo;s interesting part.
Nowadays, it seems like that training NN is extremely easy for there are plenty of free frameworks which are simple to use (e.g. PyTorch, Numpy, Tensorflow). Well, training NN is easy when you are copying others&amp;rsquo; work (e.</description>
    </item>
    
  </channel>
</rss>
