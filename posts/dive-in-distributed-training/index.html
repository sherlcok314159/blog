<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Diving in distributed training in PyTorch | Tai's Blog</title><meta name=keywords content="pytorch,训练"><meta name=description content="鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！代码开源在此： DL-Tools Cache effective tools for deep"><meta name=author content><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="eAKh7zszsOtNde1wyq_sUo95ZPH4zTTJhR-_ol4VWDs"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=http://yunpengtai.top/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://yunpengtai.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://yunpengtai.top/favicon-32x32.png><link rel=apple-touch-icon href=http://yunpengtai.top/apple-touch-icon.png><link rel=mask-icon href=http://yunpengtai.top/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>MathJax={loader:{load:["[tex]/boldsymbol"]},tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,tags:"all",packages:{"[+]":["boldsymbol"]}},chtml:{scale:.9}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js integrity="sha256-kbAFUDxdHwlYv01zraGjvjNZayxKtdoiJ38bDTFJtaQ=" crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y3CX2RWEDY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Y3CX2RWEDY",{anonymize_ip:!1})}</script><meta property="og:title" content="Diving in distributed training in PyTorch"><meta property="og:description" content="鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！代码开源在此： DL-Tools Cache effective tools for deep"><meta property="og:type" content="article"><meta property="og:url" content="http://yunpengtai.top/posts/dive-in-distributed-training/"><meta property="og:image" content="http://yunpengtai.top/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-20T10:20:00+08:00"><meta property="article:modified_time" content="2022-11-20T10:20:00+08:00"><meta property="og:site_name" content="Tai's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://yunpengtai.top/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Diving in distributed training in PyTorch"><meta name=twitter:description content="鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！代码开源在此： DL-Tools Cache effective tools for deep"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"http://yunpengtai.top/posts/"},{"@type":"ListItem","position":3,"name":"Diving in distributed training in PyTorch","item":"http://yunpengtai.top/posts/dive-in-distributed-training/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Diving in distributed training in PyTorch","name":"Diving in distributed training in PyTorch","description":"鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！代码开源在此： DL-Tools Cache effective tools for deep","keywords":["pytorch","训练"],"articleBody":"鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！代码开源在此：\nDL-Tools Cache effective tools for deep learning. 用以存放深度学习有用的代码片段 Python 在开始前，我需要特别致谢一下一位挚友，他送了我双显卡的服务器来赞助我做个人研究，否则多卡的相关实验就得付费在云平台上跑了，感谢好朋友一路以来的支持，这份恩情值得一辈子铭记！\nWhy Parallel 我们在两种情况下进行并行化训练1：\n模型一张卡放不下：我们需要将模型不同的结构放置到不同的 GPU 上运行，这种情况叫ModelParallel(MP) 一张卡的 batch size(bs)过小：有些时候数据的最大长度调的比较高（e.g., 512），可用的 bs 就很小，较小的 bs 会导致收敛不稳定，因而将数据分发到多个 GPU 上进行并行训练，这种情况叫DataParallel(DP)。当然，DP 肯定还可以加速训练，常见于大模型的训练中 这里只讲一下 DP 在 pytorch 中的原理和相关实现，即 DataParallel 和 DistributedParallel\nData Parallel 实现原理 实现就是循环往复一个过程：数据分发，模型复制，各自前向传播，汇聚输出，计算损失，梯度回传，梯度汇聚更新，可以参见下图2：\nData Parallel 过程\npytorch 中部分关键源码3截取如下：\nData Parallel 源码 def data_parallel( module, input, device_ids, output_device=None ): if not device_ids: return module(input) if output_device is None: output_device = device_ids[0] # 复制模型 replicas = nn.parallel.replicate(module, device_ids) # 拆分数据 inputs = nn.parallel.scatter(input, device_ids) replicas = replicas[:len(inputs)] # 各自前向传播 outputs = nn.parallel.parallel_apply(replicas, inputs) # 汇聚输出 return nn.parallel.gather(outputs, output_device) 代码使用 因为运行时会将数据平均拆分到 GPU 上，所以我们准备数据的时候， batch size = per_gpu_batch_size * n_gpus\n同时，需要注意主 GPU 需要进行汇聚等操作，因而需要比单卡运行时多留出一些空间\nimport torch.nn as nn # device_ids 默认所有可使用的设备 # output_device 默认cuda:0 net = nn.DataParallel(model, device_ids=[0, 1, 2], output_device=None, dim=0) # input_var can be on any device, including CPU output = net(input_var) 接下来看个更详细的例子4，需要注意的是被 DP 包裹之后涉及到模型相关的，需要调用 DP.module，比如加载模型\nDP 例子 class Model(nn.Module): # Our model def __init__(self, input_size, output_size): super(Model, self).__init__() # for convenience self.fc = nn.Linear(input_size, output_size) def forward(self, input): output = self.fc(input) print(\"\\tIn Model: input size\", input.size(), \"output size\", output.size()) return output bs, input_size, output_size = 6, 8, 10 # define inputs inputs = torch.randn((bs, input_size)).cuda() model = Model(input_size, output_size) if torch.cuda.device_count() \u003e 1: print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\") # dim = 0 [6, xxx] -\u003e [2, ...], [2, ...], [2, ...] on 3 GPUs model = nn.DataParallel(model) # 先 DataParallel，再 cuda model = model.cuda() outputs = model(inputs) print(\"Outside: input size\", inputs.size(), \"output_size\", outputs.size()) # assume 2 GPUS are available # Let's use 2 GPUs! # In Model: input size torch.Size([3, 8]) output size torch.Size([3, 10]) # In Model: input size torch.Size([3, 8]) output size torch.Size([3, 10]) # Outside: input size torch.Size([6, 8]) output_size torch.Size([6, 10]) # save the model torch.save(model.module.state_dict(), PATH) # load again model.module.load_state_dict(torch.load(PATH)) # do anything you want 如果经常使用 huggingface，这里有两个误区需要小心：\n# data parallel object has no save_pretrained model = xxx.from_pretrained(PATH) model = nn.DataParallel(model).cuda() model.save_pretrained(NEW_PATH) # error # 因为 model 被 DP wrap 了，得先取出模型 # model.module.save_pretrained(NEW_PATH) # HF实现貌似是返回 N 个 loss （N 为 GPU 数量） # 然后对 N 个 loss 取 mean outputs = model(**inputs) loss, logits = outputs.loss, outputs.logits loss = loss.mean() loss.backward() # 返回的 logits 是汇聚后的 # HF 实现和我们手动算 loss 有细微差异 # 手动算略好于 HF loss2 = loss_fct(logits, labels) assert loss != loss2 # True 显存不均匀 了解前面的原理后，就会明白为什么会显存不均匀。因为 GPU0 比其他 GPU 多了汇聚的工作，得留一些显存，而其他 GPU 显然是不需要的。那么，解决方案就是让其他 GPU 的 batch size 开大点，GPU0 维持原状，即不按照默认实现的平分数据\n首先我们继承原来的 DataParallel（此处参考5），这里我们给定第一个 GPU 的 bs 就可以，这个是实际的 bs 而不是乘上梯度后的。假如你想要总的 bs 为 64，梯度累积为 2，一共 2 张 GPU，而一张最多只能 18，那么保险一点 GPU0 设置为 14，GPU1 是 18，也就是说你 DataLoader 每个 batch 大小是 32，gpu0_bsz=14\nclass BalancedDataParallel(DataParallel): def __init__(self, gpu0_bsz, *args, **kwargs): self.gpu0_bsz = gpu0_bsz super().__init__(*args, **kwargs) 核心代码就在于我们重新分配 chunk_sizes，实现思路就是将总的减去第一个 GPU 的再除以剩下的设备，源码的话有些死板，用的时候不妨参考我的6\n修改后的 scatter 代码 def scatter(self, inputs, kwargs, device_ids): # 不同于源码，获取 batch size 更加灵活 # 支持只有 kwargs 的情况，如 model(**inputs) if len(inputs) \u003e 0: bsz = inputs[0].size(self.dim) elif kwargs: bsz = list(kwargs.values())[0].size(self.dim) else: raise ValueError(\"You must pass inputs to the model!\") num_dev = len(self.device_ids) gpu0_bsz = self.gpu0_bsz # 除第一块之外每块GPU的bsz bsz_unit = (bsz - gpu0_bsz) // (num_dev - 1) if gpu0_bsz \u003c bsz_unit: # adapt the chunk sizes chunk_sizes = [gpu0_bsz] + [bsz_unit] * (num_dev - 1) delta = bsz - sum(chunk_sizes) # 补足偏移量 # 会有显存溢出的风险，因而最好给定的 bsz 是可以整除的 # e.g., 总的 =52 =\u003e bsz_0=16, bsz_1=bsz_2=18 # 总的 =53 =\u003e bsz_0=16, bsz_1=19, bsz_2=18 for i in range(delta): chunk_sizes[i + 1] += 1 if gpu0_bsz == 0: chunk_sizes = chunk_sizes[1:] else: return super().scatter(inputs, kwargs, device_ids) return scatter_kwargs(inputs, kwargs, device_ids, chunk_sizes, dim=self.dim) 优缺点 优点：便于操作，理解简单 缺点：GPU 分配不均匀；每次更新完都得销毁线程（运行程序后会有一个进程，一个进程可以有很多个线程）重新复制模型，因而速度慢 Distributed Data Parallel 实现原理 与 DataParallel 不同的是，Distributed Data Parallel 会开设多个进程而非线程，进程数 = GPU 数，每个进程都可以独立进行训练，也就是说代码的所有部分都会被每个进程同步调用，如果你某个地方 print 张量，你会发现 device 的差异 sampler 会将数据按照进程数切分，确保不同进程的数据不同 每个进程独立进行前向训练 每个进程利用 Ring All-Reduce 进行通信，将梯度信息进行聚合 每个进程同步更新模型参数，进行新一轮训练 按进程切分 如何确保数据不同呢？不妨看看 DistributedSampler 的源码\nDistributedSampler 的源码 # 判断数据集长度是否可以整除 GPU 数 # 如果不能，选择舍弃还是补全，进而决定总数 # If the dataset length is evenly divisible by # of replicas # then there is no need to drop any data, since the dataset # will be split equally. if (self.drop_last and len(self.dataset) % self.num_replicas != 0): # num_replicas = num_gpus self.num_samples = math.ceil((len(self.dataset) - self.num_replicas) /self.num_replicas) else: self.num_samples = math.ceil(len(self.dataset) / self.num_replicas) self.total_size = self.num_samples * self.num_replicas # 根据是否 shuffle 来创建 indices if self.shuffle: # deterministically shuffle based on epoch and seed g = torch.Generator() g.manual_seed(self.seed + self.epoch) indices = torch.randperm(len(self.dataset), generator=g).tolist() else: indices = list(range(len(self.dataset))) if not self.drop_last: # add extra samples to make it evenly divisible padding_size = self.total_size - len(indices) if padding_size \u003c= len(indices): # 不够就按 indices 顺序加 # e.g., indices 为 [0, 1, 2, 3 ...]，而 padding_size 为4 # 加好之后的 indices[..., 0, 1, 2, 3] indices += indices[:padding_size] else: indices += (indices * math.ceil(padding_size / len(indices)))[:padding_size] else: # remove tail of data to make it evenly divisible. indices = indices[:self.total_size] assert len(indices) == self.total_size # subsample # rank 代表进程 id indices = indices[self.rank:self.total_size:self.num_replicas] return iter(indices) Ring All-Reduce 那么什么是Ring All-Reduce呢？又为啥可以降低通信成本呢？\n首先将每块 GPU 上的梯度拆分成四个部分，比如$g_0 = [a_0; b_0; c_0; d_0]$，如下图（此部分原理致谢下王老师，讲的很清晰7）：\nRing All-Reduce 1\n所有 GPU 的传播都是同步进行的，传播的规律有两条：\n只与自己下一个位置的 GPU 进行通信，比如 0 \u003e 1，3 \u003e 0 四个部分，哪块 GPU 上占的多，就由该块 GPU 往它下一个传，初始从主节点传播，即 GPU0，你可以想象跟接力一样，a 传 b，b 负责传给 c 第一次传播如下：\nRing All-Reduce 2\n那么结果就是：\nRing All-Reduce 3\n那么，按照谁多谁往下传的原则，此时应该是 GPU1 往 GPU2 传 a0 和 a1，GPU2 往 GPU3 传 b1 和 b2，以此类推\nRing All-Reduce 4\n接下来再传播就会有 GPU3 a 的部分全有，GPU0 上 b 的部分全有等，就再往下传\nRing All-Reduce 5\n再来几遍便可以使得每块 GPU 上都获得了来自其他 GPU 的梯度啦\nRing All-Reduce 6\n代码使用 基础概念 第一个是后端的选择，即数据传输协议，从下表可以看出8，当使用 CPU 时可以选择gloo而 GPU 则可以是nccl\nBackend gloo mpi nccl Device CPU GPU CPU GPU CPU GPU send ✓ ✘ ✓ ? ✘ ✓ recv ✓ ✘ ✓ ? ✘ ✓ broadcast ✓ ✓ ✓ ? ✘ ✓ all_reduce ✓ ✓ ✓ ? ✘ ✓ reduce ✓ ✘ ✓ ? ✘ ✓ all_gather ✓ ✘ ✓ ? ✘ ✓ gather ✓ ✘ ✓ ? ✘ ✓ scatter ✓ ✘ ✓ ? ✘ ✘ reduce_scatter ✘ ✘ ✘ ✘ ✘ ✓ all_to_all ✘ ✘ ✓ ? ✘ ✓ barrier ✓ ✘ ✓ ? ✘ ✓ 接下来是一些参数的解释9：\nArg Meaning group 一次发起的所有进程构成一个 group，除非想更精细通信，创建 new_group world_size 一个 group 中进程数目，即为 GPU 的数量 rank 进程 id，主节点 rank=0，其他的在 0 和 world_size-1 之间 local_rank 进程在本地节点/机器的 id 举个例子，假如你有两台服务器（又被称为 node），每台服务器有 4 张 GPU，那么，world_size 即为 8，rank=[0, 1, 2, 3, 4, 5, 6, 7], 每个服务器上的进程的 local_rank 为[0, 1, 2, 3]\n然后是初始化方法的选择，有TCP和共享文件两种，一般指定 rank=0 为 master 节点\nTCP 显而易见是通过网络进行传输，需要指定主节点的 ip（可以为主节点实际 IP，或者是 localhost）和空闲的端口\nimport torch.distributed as dist dist.init_process_group(backend, init_method='tcp://ip:port', rank=rank, world_size=world_size) 共享文件的话需要手动删除上次启动时残留的文件，加上官方有一堆警告，还是建议使用 TCP\ndist.init_process_group(backend, init_method='file://Path', rank=rank, world_size=world_size) launch 方法 初始化 这里先讲用 launch 的方法，关于 torch.multiprocessing 留到后面讲\n在启动后，rank 和 world_size 都会自动被 DDP 写入环境中，可以提前准备好参数类，如argparse这种\nargs.rank = int(os.environ['RANK']) args.world_size = int(os.environ['WORLD_SIZE']) args.local_rank = int(os.environ['LOCAL_RANK']) 首先，在使用distributed包的任何其他函数之前，按照 tcp 方法进行初始化，需要注意的是需要手动指定一共可用的设备CUDA_VISIBLE_DEVICES\nDDP launch 源码 def dist_setup_launch(args): # tell DDP available devices [NECESSARY] os.environ['CUDA_VISIBLE_DEVICES'] = args.devices args.rank = int(os.environ['RANK']) args.world_size = int(os.environ['WORLD_SIZE']) args.local_rank = int(os.environ['LOCAL_RANK']) dist.init_process_group(args.backend, args.init_method, rank=args.rank, world_size=args.world_size) # this is optional, otherwise you may need to specify the # device when you move something e.g., model.cuda(1) # or model.to(args.rank) # Setting device makes things easy: model.cuda() torch.cuda.set_device(args.rank) print('The Current Rank is %d | The Total Ranks are %d' %(args.rank, args.world_size)) DistributedSampler 接下来创建 DistributedSampler，是否 pin_memory，根据你本机的内存决定。pin_memory 的意思是提前在内存中申请一部分专门存放 Tensor。假如说你内存比较小，就会跟虚拟内存，即硬盘进行交换，这样转义到 GPU 上会比内存直接到 GPU 耗时。\n因而，如果你的内存比较大，可以设置为 True；然而，如果开了导致卡顿的情况，建议关闭\n加载 DataLoader from torch.utils.data import DataLoader, DistributedSampler train_sampler = DistributedSampler(train_dataset, seed=args.seed) train_dataloader = DataLoader(train_dataset, pin_memory=True, shuffle=(train_sampler is None), batch_size=args.per_gpu_train_bs, num_workers=args.num_workers, sampler=train_sampler) eval_sampler = DistributedSampler(eval_dataset, seed=args.seed) eval_dataloader = DataLoader(eval_dataset, pin_memory=True, batch_size=args.per_gpu_eval_bs, num_workers=args.num_workers, sampler=eval_sampler) 加载模型 然后加载模型，跟 DataParallel 不同的是需要提前放置到 cuda 上，还记得上面关于设置 cuda_device 的语句嘛，因为设置好之后每个进程只能看见一个 GPU，所以直接model.cuda()，不需要指定 device\n同时，我们必须给 DDP 提示目前是哪个 rank\nfrom torch.nn.parallel import DistributedDataParallel as DDP model = model.cuda() # tell DDP which rank model = DDP(model, find_unused_parameters=True, device_ids=[rank]) 注意，当模型带有 Batch Norm 时：\nif args.syncBN: nn.SyncBatchNorm.convert_sync_batchnorm(model).cuda() 训练相关 每个 epoch 开始训练的时候，记得用 sampler 的 set_epoch，使得每个 epoch 打乱顺序是不一致的\n关于梯度回传和参数更新，跟正常情况无异\nfor epoch in range(epochs): # record epochs train_dataloader.sampler.set_epoch(epoch) outputs = model(inputs) loss = loss_fct(outputs, labels) loss.backward() optimizer.step() optimizer.zero_grad() 这里有一点需要小心，这个 loss 是各个进程的 loss 之和，如果想要存储每个 step 平均损失，可以进行 all_reduce 操作，进行平均，不妨看官方的小例子来理解下：\n\u003e\u003e\u003e # All tensors below are of torch.int64 type. \u003e\u003e\u003e # We have 2 process groups, 2 ranks. \u003e\u003e\u003e tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank \u003e\u003e\u003e tensor tensor([1, 2]) # Rank 0 tensor([3, 4]) # Rank 1 \u003e\u003e\u003e dist.all_reduce(tensor, op=ReduceOp.SUM) \u003e\u003e\u003e tensor tensor([4, 6]) # Rank 0 tensor([4, 6]) # Rank 1 @torch.no_grad() def reduce_value(value, average=True): world_size = get_world_size() if world_size \u003c 2: # 单 GPU 的情况 return value dist.all_reduce(value) if average: value /= world_size return value 看到这，肯定有小伙伴要问，那这样我们是不是得先求平均损失再回传梯度啊，不用，因为，当我们回传 loss 后，DDP 会自动对所有梯度进行平均10，也就是说回传后我们更新的梯度和 DP 或者单卡同样 batch 训练都是一致的\nloss = loss_fct(...) loss.backward() # 注意在 backward 后面 loss = reduce_value(loss, world_size) mean_loss = (step * mean_loss + loss.item()) / (step + 1) 还有个注意点就是学习率的变化，这个是和 batch size 息息相关的，如果 batch 扩充了几倍，也就是说 step 比之前少了很多，还采用同一个学习率，肯定会出问题的，这里，我们进行线性增大11\nN = world_size lr = args.lr * N 肯定有人说，诶，你线性增大肯定不能保证梯度的 variance 一致了，正确的应该是正比于$\\sqrt{N}$，关于这个的讨论不妨参考12\nevaluate 相关 接下来，细心的同学肯定好奇了，如果验证集也切分了，metric 怎么计算呢？此时就需要咱们把每个进程得到的预测情况集合起来，t 就是一个我们需要 gather 的张量，最后将每个进程中的 t 按照第一维度拼接，先看官方小例子来理解 all_gather\n\u003e\u003e\u003e # All tensors below are of torch.int64 dtype. \u003e\u003e\u003e # We have 2 process groups, 2 ranks. \u003e\u003e\u003e tensor_list = [torch.zeros(2, dtype=torch.int64) for _ in range(2)] \u003e\u003e\u003e tensor_list [tensor([0, 0]), tensor([0, 0])] # Rank 0 and 1 \u003e\u003e\u003e tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank \u003e\u003e\u003e tensor tensor([1, 2]) # Rank 0 tensor([3, 4]) # Rank 1 \u003e\u003e\u003e dist.all_gather(tensor_list, tensor) \u003e\u003e\u003e tensor_list [tensor([1, 2]), tensor([3, 4])] # Rank 0 [tensor([1, 2]), tensor([3, 4])] # Rank 1 def sync_across_gpus(t, world_size): gather_t_tensor = [torch.zeros_like(t) for _ in range(world_size)] dist.all_gather(gather_t_tensor, t) return torch.cat(gather_t_tensor, dim=0) 可以简单参考我前面提供的源码的 evaluate 部分，我们首先将预测和标签比对，把结果为 bool 的张量存储下来，最终 gather 求和取平均。\n这里还有个有趣的地方，tensor 默认的类型可能是 int，bool 型的 res 拼接后自动转为 0 和 1 了，另外 bool 型的张量是不支持 gather 的\ndef eval(...): results = torch.tensor([]).cuda() for step, (inputs, labels) in enumerate(dataloader): outputs = model(inputs) res = (outputs.argmax(-1) == labels) results = torch.cat([results, res], dim=0) results = sync_across_gpus(results, world_size) mean_acc = (results.sum() / len(results)).item() return mean_acc 模型保存与加载 模型保存，参考部分官方教程13，我们只需要在主进程保存模型即可，注意，这里是被 DDP 包裹后的，DDP 并没有 state_dict，这里 barrier 的目的是为了让其他进程等待主进程保存模型，以防不同步\ndef save_checkpoint(rank, model, path): if is_main_process(rank): # All processes should see same parameters as they all # start from same random parameters and gradients are # synchronized in backward passes. # Therefore, saving it in one process is sufficient. torch.save(model.module.state_dict(), path) # Use a barrier() to keep process 1 waiting for process 0 dist.barrier() 加载的时候别忘了 map_location，我们一开始会保存模型至主进程，这样就会导致 cuda:0 显存被占据，我们需要将模型 remap 到其他设备\ndef load_checkpoint(rank, model, path): # remap the model from cuda:0 to other devices map_location = {'cuda:%d' % 0: 'cuda:%d' % rank} model.module.load_state_dict( torch.load(path, map_location=map_location) ) 进程销毁 运行结束后记得销毁进程：\ndef cleanup(): dist.destroy_process_group() cleanup() 如何启动 在终端输入下列命令【单机多卡】\npython -m torch.distributed.launch --nproc_per_node=NUM_GPUS main.py (--arg1 --arg2 --arg3 and all other arguments of your training script) 目前 torch 1.10 以后更推荐用 run\ntorch.distributed.launch -\u003e torch.distributed.run / torchrun 多机多卡是这样的：\n# 第一个节点启动 python -m torch.distributed.launch \\ --nproc_per_node=NUM_GPUS \\ --nnodes=2 \\ --node_rank=0 \\ --master_addr=\"192.168.1.1\" \\ --master_port=1234 main.py # 第二个节点启动 python -m torch.distributed.launch \\ --nproc_per_node=NUM_GPUS \\ --nnodes=2 \\ --node_rank=1 \\ --master_addr=\"192.168.1.1\" \\ --master_port=1234 main.py mp 方法 第二个方法就是利用 torch 的多线程包\nimport torch.multiprocessing as mp # rank mp 会自动填入 def main(rank, arg1, ...): pass if __name__ == '__main__': mp.spawn(main, nprocs=TOTAL_GPUS, args=(arg1, ...)) 这里输入参数时务必注意要给定 iterable 形式，比如你的 main 方法除了 rank 还接受一个 int 类型参数，你 spawn 方法时需要以元组形式给定：\nif __name__ == '__main__': # Note that is (1, ) not (1) mp.spawn(main, nprocs=TOTAL_GPUS, args=(1, )) 同时因为此种方法是自动给定 rank，我们不需要在初始化时告诉可用的设备有哪些，否则多个进程无法同时启动\ndef dist_setup_mp(args): # there is no need to set CUDA_VISIBLE_DEVICES # os.environ['CUDA_VISIBLE_DEVICES'] = args.devices 这种运行的时候就跟正常的 python 文件一致：python main.py\n优缺点 优点： 相比于 DP 而言，不需要反复创建和销毁线程；Ring All-Reduce 算法提高通信效率；模型同步方便 缺点：操作起来可能有些复杂，一般可满足需求的可先试试看 DataParallel Possible Bugs Producer process has been terminated before all shared CUDA tensors released. See Note Sharing CUDA tensors\n这个应该是用 mp 方法时在 DataLoader 里设置 num_workers 大于导致，应该是 torch 的 multiprocessing 会每一个 num_worker 复制一个模型14\nRuntimeError: cannot pin ‘torch.cuda.ByteTensor’ only dense CPU tensors can be pinned\n还记得我们前面对于pin_memory的解释，是在内存中专门开辟一块空间，专门用于与 GPU 的通信，那么没到 GPU 之前就是 CPU，也就是 CPU tensors 才能被 pin\n出现这个 bug 的原因可能是你在 DataLoader 内部处理时已经将张量放到了 GPU 上15，比如自定义collate_func\nhttps://blog.csdn.net/qq_37541097/article/details/109736159 ↩︎\nhttps://www.cnblogs.com/ljwgis/p/15471530.html ↩︎\nhttps://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html?highlight=dataparallel ↩︎\nhttps://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html ↩︎\nhttps://github.com/kimiyoung/transformer-xl ↩︎\nhttps://github.com/sherlcok314159/dl-tools/blob/main/balanced_data_parallel/README.md ↩︎\nhttps://www.youtube.com/watch?v=rj-hjS5L8Bw ↩︎\nhttps://pytorch.org/docs/stable/distributed.html#backends ↩︎\nhttps://stackoverflow.com/questions/58271635/in-distributed-computing-what-are-world-size-and-rank ↩︎\nhttps://discuss.pytorch.org/t/average-loss-in-dp-and-ddp/93306/4 ↩︎\nhttps://arxiv.org/abs/1706.02677 ↩︎\nhttps://github.com/Lightning-AI/lightning/discussions/3706 ↩︎\nhttps://pytorch.org/tutorials/intermediate/ddp_tutorial.html ↩︎\nhttps://discuss.pytorch.org/t/w-cudaipctypes-cpp-22-producer-process-has-been-terminated-before-all-shared-cuda-tensors-released-see-note-sharing-cuda-tensors/124445/1 ↩︎\nhttps://discuss.pytorch.org/t/what-are-dense-cpu-tensor/55703 ↩︎\n","wordCount":"5172","inLanguage":"en","datePublished":"2022-11-20T10:20:00+08:00","dateModified":"2022-11-20T10:20:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://yunpengtai.top/posts/dive-in-distributed-training/"},"publisher":{"@type":"Organization","name":"Tai's Blog","logo":{"@type":"ImageObject","url":"http://yunpengtai.top/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://yunpengtai.top accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://yunpengtai.top/archives/ title=归档><span>归档</span></a></li><li><a href=http://yunpengtai.top/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li><li><a href=http://yunpengtai.top/categories/%E6%8A%98%E8%85%BE title=折腾><span>折腾</span></a></li><li><a href=http://yunpengtai.top/tags/ title=标签><span>标签</span></a></li><li><a href=http://yunpengtai.top/friends/ title=友人><span>友人</span></a></li><li><a href=http://yunpengtai.top/about/ title=关于><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://yunpengtai.top>Home</a>&nbsp;»&nbsp;<a href=http://yunpengtai.top/posts/>Posts</a></div><h1 class=post-title>Diving in distributed training in PyTorch</h1><div class=post-meta><span title='2022-11-20 10:20:00 +0800 CST'>November 20, 2022</span>&nbsp;·&nbsp;5172 words</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#why-parallel aria-label="Why Parallel">Why Parallel</a></li><li><a href=#data-parallel aria-label="Data Parallel">Data Parallel</a><ul><li><a href=#%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86 aria-label=实现原理>实现原理</a></li><li><a href=#%e4%bb%a3%e7%a0%81%e4%bd%bf%e7%94%a8 aria-label=代码使用>代码使用</a></li><li><a href=#%e6%98%be%e5%ad%98%e4%b8%8d%e5%9d%87%e5%8c%80 aria-label=显存不均匀>显存不均匀</a></li><li><a href=#%e4%bc%98%e7%bc%ba%e7%82%b9 aria-label=优缺点>优缺点</a></li></ul></li><li><a href=#distributed-data-parallel aria-label="Distributed Data Parallel">Distributed Data Parallel</a><ul><li><a href=#%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86-1 aria-label=实现原理>实现原理</a><ul><li><a href=#%e6%8c%89%e8%bf%9b%e7%a8%8b%e5%88%87%e5%88%86 aria-label=按进程切分>按进程切分</a></li><li><a href=#ring-all-reduce aria-label="Ring All-Reduce">Ring All-Reduce</a></li></ul></li><li><a href=#%e4%bb%a3%e7%a0%81%e4%bd%bf%e7%94%a8-1 aria-label=代码使用>代码使用</a><ul><li><a href=#%e5%9f%ba%e7%a1%80%e6%a6%82%e5%bf%b5 aria-label=基础概念>基础概念</a></li><li><a href=#launch-%e6%96%b9%e6%b3%95 aria-label="launch 方法">launch 方法</a><ul><li><a href=#%e5%88%9d%e5%a7%8b%e5%8c%96 aria-label=初始化>初始化</a></li><li><a href=#distributedsampler aria-label=DistributedSampler>DistributedSampler</a></li><li><a href=#%e5%8a%a0%e8%bd%bd%e6%a8%a1%e5%9e%8b aria-label=加载模型>加载模型</a></li><li><a href=#%e8%ae%ad%e7%bb%83%e7%9b%b8%e5%85%b3 aria-label=训练相关>训练相关</a></li><li><a href=#evaluate-%e7%9b%b8%e5%85%b3 aria-label="evaluate 相关">evaluate 相关</a></li><li><a href=#%e6%a8%a1%e5%9e%8b%e4%bf%9d%e5%ad%98%e4%b8%8e%e5%8a%a0%e8%bd%bd aria-label=模型保存与加载>模型保存与加载</a></li><li><a href=#%e8%bf%9b%e7%a8%8b%e9%94%80%e6%af%81 aria-label=进程销毁>进程销毁</a></li><li><a href=#%e5%a6%82%e4%bd%95%e5%90%af%e5%8a%a8 aria-label=如何启动>如何启动</a></li></ul></li><li><a href=#mp-%e6%96%b9%e6%b3%95 aria-label="mp 方法">mp 方法</a></li></ul></li><li><a href=#%e4%bc%98%e7%bc%ba%e7%82%b9-1 aria-label=优缺点>优缺点</a></li><li><a href=#possible-bugs aria-label="Possible Bugs">Possible Bugs</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！代码开源在此：</p><div class=github><div class=github_bar><svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" viewBox="0 0 50 50"><path d="M17.791 46.836C18.502 46.53 19 45.823 19 45v-5.4c0-.197.016-.402.041-.61C19.027 38.994 19.014 38.997 19 39c0 0-3 0-3.6.0-1.5.0-2.8-.6-3.4-1.8-.7-1.3-1-3.5-2.8-4.7C8.9 32.3 9.1 32 9.7 32c.6.1 1.9.9 2.7 2 .9 1.1 1.8 2 3.4 2 2.487.0 3.82-.125 4.622-.555C21.356 34.056 22.649 33 24 33v-.025c-5.668-.182-9.289-2.066-10.975-4.975-3.665.042-6.856.405-8.677.707-.058-.327-.108-.656-.151-.987 1.797-.296 4.843-.647 8.345-.714-.112-.276-.209-.559-.291-.849-3.511-.178-6.541-.039-8.187.097-.02-.332-.047-.663-.051-.999 1.649-.135 4.597-.27 8.018-.111-.079-.5-.13-1.011-.13-1.543.0-1.7.6-3.5 1.7-5-.5-1.7-1.2-5.3.2-6.6 2.7.0 4.6 1.3 5.5 2.1C21 13.4 22.9 13 25 13s4 .4 5.6 1.1c.9-.8 2.8-2.1 5.5-2.1 1.5 1.4.7 5 .2 6.6 1.1 1.5 1.7 3.2 1.6 5 0 .484-.045.951-.11 1.409 3.499-.172 6.527-.034 8.204.102-.002.337-.033.666-.051.999-1.671-.138-4.775-.28-8.359-.089-.089.336-.197.663-.325.98 3.546.046 6.665.389 8.548.689-.043.332-.093.661-.151.987-1.912-.306-5.171-.664-8.879-.682-1.665 2.878-5.22 4.755-10.777 4.974V33c2.6.0 5 3.9 5 6.6V45c0 .823.498 1.53 1.209 1.836C41.37 43.804 48 35.164 48 25 48 12.318 37.683 2 25 2S2 12.318 2 25C2 35.164 8.63 43.804 17.791 46.836z"/></svg><a class=github_name href=https://github.com/sherlcok314159/dl-tools target=_blank>DL-Tools</a></div><div class=github_description>Cache effective tools for deep learning. 用以存放深度学习有用的代码片段</div><div class=github_language>Python</div></div><p><strong>在开始前，我需要特别致谢一下一位挚友，他送了我双显卡的服务器来赞助我做个人研究，否则多卡的相关实验就得付费在云平台上跑了，感谢好朋友一路以来的支持，这份恩情值得一辈子铭记！</strong></p><h2 id=why-parallel>Why Parallel<a hidden class=anchor aria-hidden=true href=#why-parallel>#</a></h2><p>我们在两种情况下进行并行化训练<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>：</p><ol><li><strong>模型一张卡放不下</strong>：我们需要将模型不同的结构放置到不同的 GPU 上运行，这种情况叫<em>ModelParallel(MP)</em></li><li><strong>一张卡的 batch size(bs)过小</strong>：有些时候数据的最大长度调的比较高（e.g., 512），可用的 bs 就很小，较小的 bs 会导致收敛不稳定，因而将数据分发到多个 GPU 上进行并行训练，这种情况叫<em>DataParallel(DP)</em>。当然，DP 肯定还可以加速训练，常见于大模型的训练中</li></ol><p>这里只讲一下 DP 在 pytorch 中的原理和相关实现，即 DataParallel 和 DistributedParallel</p><h2 id=data-parallel>Data Parallel<a hidden class=anchor aria-hidden=true href=#data-parallel>#</a></h2><h3 id=实现原理>实现原理<a hidden class=anchor aria-hidden=true href=#实现原理>#</a></h3><p>实现就是循环往复一个过程：数据分发，模型复制，各自前向传播，汇聚输出，计算损失，梯度回传，梯度汇聚更新，可以参见下图<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>：</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/cGkHbLx8S7jlpOd.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/cGkHbLx8S7jlpOd.png#center alt="Data Parallel 过程" width=520px height=440px><figcaption><p><a href=https://www.cnblogs.com/ljwgis/p/15471530.html>Data Parallel 过程</a></p></figcaption></figure></a><p>pytorch 中部分关键源码<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>截取如下：</p><p><details><summary markdown=span>Data Parallel 源码</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>data_parallel</span><span class=p>(</span>
</span></span><span class=line><span class=cl>	<span class=n>module</span><span class=p>,</span>
</span></span><span class=line><span class=cl>	<span class=nb>input</span><span class=p>,</span>
</span></span><span class=line><span class=cl>	<span class=n>device_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>	<span class=n>output_device</span><span class=o>=</span><span class=kc>None</span>
</span></span><span class=line><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>device_ids</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>module</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>output_device</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>output_device</span> <span class=o>=</span> <span class=n>device_ids</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 复制模型</span>
</span></span><span class=line><span class=cl>    <span class=n>replicas</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>parallel</span><span class=o>.</span><span class=n>replicate</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 拆分数据</span>
</span></span><span class=line><span class=cl>    <span class=n>inputs</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>parallel</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>replicas</span> <span class=o>=</span> <span class=n>replicas</span><span class=p>[:</span><span class=nb>len</span><span class=p>(</span><span class=n>inputs</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 各自前向传播</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>parallel</span><span class=o>.</span><span class=n>parallel_apply</span><span class=p>(</span><span class=n>replicas</span><span class=p>,</span> <span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 汇聚输出</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>nn</span><span class=o>.</span><span class=n>parallel</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>output_device</span><span class=p>)</span>
</span></span></code></pre></div></details></p><h3 id=代码使用>代码使用<a hidden class=anchor aria-hidden=true href=#代码使用>#</a></h3><div class="notice notice-note"><div class=notice-title><svg xmlns="http://www.w3.org/2000/svg" class="icon notice-icon" viewBox="0 0 512 512"><path d="M504 256A248 248 0 118 256a248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165 8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z"/></svg></div><p>因为运行时会将数据平均拆分到 GPU 上，所以我们准备数据的时候， batch size = per_gpu_batch_size * n_gpus</p></div><p>同时，需要注意主 GPU 需要进行汇聚等操作，因而需要比单卡运行时<em>多留出一些空间</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=c1># device_ids 默认所有可使用的设备</span>
</span></span><span class=line><span class=cl><span class=c1># output_device 默认cuda:0</span>
</span></span><span class=line><span class=cl><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                      <span class=n>output_device</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># input_var can be on any device, including CPU</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>net</span><span class=p>(</span><span class=n>input_var</span><span class=p>)</span>  
</span></span></code></pre></div><p>接下来看个更详细的例子<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>，需要注意的是被 DP 包裹之后涉及到模型相关的，需要调用 DP.module，比如<em>加载模型</em></p><p><details><summary markdown=span>DP 例子</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Model</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Our model</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_size</span><span class=p>,</span> <span class=n>output_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>Model</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># for convenience</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_size</span><span class=p>,</span> <span class=n>output_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=nb>input</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\t</span><span class=s2>In Model: input size&#34;</span><span class=p>,</span> <span class=nb>input</span><span class=o>.</span><span class=n>size</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>              <span class=s2>&#34;output size&#34;</span><span class=p>,</span> <span class=n>output</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>bs</span><span class=p>,</span> <span class=n>input_size</span><span class=p>,</span> <span class=n>output_size</span> <span class=o>=</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=c1># define inputs</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>((</span><span class=n>bs</span><span class=p>,</span> <span class=n>input_size</span><span class=p>))</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Model</span><span class=p>(</span><span class=n>input_size</span><span class=p>,</span> <span class=n>output_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Let&#39;s use&#34;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>(),</span> <span class=s2>&#34;GPUs!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># dim = 0 [6, xxx] -&gt; [2, ...], [2, ...], [2, ...] on 3 GPUs</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 先 DataParallel，再 cuda</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Outside: input size&#34;</span><span class=p>,</span> <span class=n>inputs</span><span class=o>.</span><span class=n>size</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>	  <span class=s2>&#34;output_size&#34;</span><span class=p>,</span> <span class=n>outputs</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=c1># assume 2 GPUS are available</span>
</span></span><span class=line><span class=cl><span class=c1># Let&#39;s use 2 GPUs!</span>
</span></span><span class=line><span class=cl><span class=c1>#    In Model: input size torch.Size([3, 8]) output size torch.Size([3, 10])</span>
</span></span><span class=line><span class=cl><span class=c1>#    In Model: input size torch.Size([3, 8]) output size torch.Size([3, 10])</span>
</span></span><span class=line><span class=cl><span class=c1># Outside: input size torch.Size([6, 8]) output_size torch.Size([6, 10])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># save the model</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span> <span class=n>PATH</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># load again</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>PATH</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=c1># do anything you want</span>
</span></span></code></pre></div></details></p><p>如果经常使用 huggingface，这里有两个误区需要小心：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># data parallel object has no save_pretrained</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>xxx</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>PATH</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>NEW_PATH</span><span class=p>)</span> <span class=c1># error</span>
</span></span><span class=line><span class=cl><span class=c1># 因为 model 被 DP wrap 了，得先取出模型 #</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>NEW_PATH</span><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># HF实现貌似是返回 N 个 loss （N 为 GPU 数量）</span>
</span></span><span class=line><span class=cl><span class=c1># 然后对 N 个 loss 取 mean</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>loss</span><span class=p>,</span> <span class=n>logits</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>loss</span><span class=p>,</span> <span class=n>outputs</span><span class=o>.</span><span class=n>logits</span>
</span></span><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>loss</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 返回的 logits 是汇聚后的</span>
</span></span><span class=line><span class=cl><span class=c1># HF 实现和我们手动算 loss 有细微差异</span>
</span></span><span class=line><span class=cl><span class=c1># 手动算略好于 HF</span>
</span></span><span class=line><span class=cl><span class=n>loss2</span> <span class=o>=</span> <span class=n>loss_fct</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=n>loss</span> <span class=o>!=</span> <span class=n>loss2</span>
</span></span><span class=line><span class=cl><span class=c1># True</span>
</span></span></code></pre></div><h3 id=显存不均匀>显存不均匀<a hidden class=anchor aria-hidden=true href=#显存不均匀>#</a></h3><p>了解前面的原理后，就会明白为什么会显存不均匀。因为 GPU0 比其他 GPU 多了汇聚的工作，得留一些显存，而其他 GPU 显然是不需要的。那么，解决方案就是让其他 GPU 的 batch size 开大点，GPU0 维持原状，即不按照默认实现的<em>平分数据</em></p><p>首先我们继承原来的 DataParallel（此处参考<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>），这里我们给定第一个 GPU 的 bs 就可以，这个是实际的 bs 而不是乘上梯度后的。假如你想要总的 bs 为 64，梯度累积为 2，一共 2 张 GPU，而一张最多只能 18，那么保险一点 GPU0 设置为 14，GPU1 是 18，也就是说你 DataLoader 每个 batch 大小是 32，<code>gpu0_bsz=14</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>BalancedDataParallel</span><span class=p>(</span><span class=n>DataParallel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>gpu0_bsz</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gpu0_bsz</span> <span class=o>=</span> <span class=n>gpu0_bsz</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span></code></pre></div><p>核心代码就在于我们重新分配 chunk_sizes，实现思路就是将总的减去第一个 GPU 的再除以剩下的设备，源码的话有些死板，用的时候不妨参考我的<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup></p><p><details><summary markdown=span>修改后的 scatter 代码</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>scatter</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>kwargs</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 不同于源码，获取 batch size 更加灵活</span>
</span></span><span class=line><span class=cl>    <span class=c1># 支持只有 kwargs 的情况，如 model(**inputs)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>bsz</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=n>kwargs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>bsz</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>kwargs</span><span class=o>.</span><span class=n>values</span><span class=p>())[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;You must pass inputs to the model!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_dev</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>gpu0_bsz</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gpu0_bsz</span>
</span></span><span class=line><span class=cl>    <span class=c1># 除第一块之外每块GPU的bsz</span>
</span></span><span class=line><span class=cl>    <span class=n>bsz_unit</span> <span class=o>=</span> <span class=p>(</span><span class=n>bsz</span> <span class=o>-</span> <span class=n>gpu0_bsz</span><span class=p>)</span> <span class=o>//</span> <span class=p>(</span><span class=n>num_dev</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>gpu0_bsz</span> <span class=o>&lt;</span> <span class=n>bsz_unit</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># adapt the chunk sizes</span>
</span></span><span class=line><span class=cl>        <span class=n>chunk_sizes</span> <span class=o>=</span> <span class=p>[</span><span class=n>gpu0_bsz</span><span class=p>]</span> <span class=o>+</span> <span class=p>[</span><span class=n>bsz_unit</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>num_dev</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>delta</span> <span class=o>=</span> <span class=n>bsz</span> <span class=o>-</span> <span class=nb>sum</span><span class=p>(</span><span class=n>chunk_sizes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 补足偏移量</span>
</span></span><span class=line><span class=cl>        <span class=c1># 会有显存溢出的风险，因而最好给定的 bsz 是可以整除的</span>
</span></span><span class=line><span class=cl>        <span class=c1># e.g., 总的 =52 =&gt; bsz_0=16, bsz_1=bsz_2=18</span>
</span></span><span class=line><span class=cl>        <span class=c1># 总的 =53 =&gt; bsz_0=16, bsz_1=19, bsz_2=18</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>delta</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>chunk_sizes</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>gpu0_bsz</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>chunk_sizes</span> <span class=o>=</span> <span class=n>chunk_sizes</span><span class=p>[</span><span class=mi>1</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>kwargs</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>scatter_kwargs</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>kwargs</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>,</span> <span class=n>chunk_sizes</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>dim</span><span class=p>)</span>
</span></span></code></pre></div></details></p><h3 id=优缺点>优缺点<a hidden class=anchor aria-hidden=true href=#优缺点>#</a></h3><ul><li>优点：便于操作，理解简单</li><li>缺点：GPU 分配不均匀；每次更新完都得销毁<strong>线程</strong>（运行程序后会有一个进程，一个进程可以有很多个线程）重新复制模型，因而速度慢</li></ul><h2 id=distributed-data-parallel>Distributed Data Parallel<a hidden class=anchor aria-hidden=true href=#distributed-data-parallel>#</a></h2><h3 id=实现原理-1>实现原理<a hidden class=anchor aria-hidden=true href=#实现原理-1>#</a></h3><ol><li>与 DataParallel 不同的是，Distributed Data Parallel 会开设多个进程而非线程，进程数 = GPU 数，每个进程都可以独立进行训练，也就是说代码的所有部分都会被每个进程同步调用，如果你某个地方 print 张量，你会发现 device 的差异</li><li>sampler 会将数据按照进程数切分，<strong>确保不同进程的数据不同</strong></li><li>每个进程独立进行前向训练</li><li>每个进程利用 Ring All-Reduce 进行通信，将梯度信息进行聚合</li><li>每个进程同步更新模型参数，进行新一轮训练</li></ol><h4 id=按进程切分>按进程切分<a hidden class=anchor aria-hidden=true href=#按进程切分>#</a></h4><p>如何确保数据不同呢？不妨看看 DistributedSampler 的源码</p><p><details><summary markdown=span>DistributedSampler 的源码</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 判断数据集长度是否可以整除 GPU 数</span>
</span></span><span class=line><span class=cl><span class=c1># 如果不能，选择舍弃还是补全，进而决定总数</span>
</span></span><span class=line><span class=cl><span class=c1># If the dataset length is evenly divisible by # of replicas</span>
</span></span><span class=line><span class=cl><span class=c1># then there is no need to drop any data, since the dataset</span>
</span></span><span class=line><span class=cl><span class=c1># will be split equally.</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>drop_last</span> <span class=ow>and</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span> <span class=o>%</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># num_replicas = num_gpus</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>num_samples</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>((</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span> <span class=o>-</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span><span class=p>)</span> <span class=o>/</span><span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>num_samples</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span> <span class=o>/</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>total_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_samples</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 根据是否 shuffle 来创建 indices</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>shuffle</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># deterministically shuffle based on epoch and seed</span>
</span></span><span class=line><span class=cl>    <span class=n>g</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>Generator</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>g</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>seed</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>epoch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randperm</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>),</span> <span class=n>generator</span><span class=o>=</span><span class=n>g</span><span class=p>)</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>drop_last</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># add extra samples to make it evenly divisible</span>
</span></span><span class=line><span class=cl>    <span class=n>padding_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>total_size</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>padding_size</span> <span class=o>&lt;=</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 不够就按 indices 顺序加</span>
</span></span><span class=line><span class=cl>        <span class=c1># e.g., indices 为 [0, 1, 2, 3 ...]，而 padding_size 为4</span>
</span></span><span class=line><span class=cl>        <span class=c1># 加好之后的 indices[..., 0, 1, 2, 3]</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>+=</span> <span class=n>indices</span><span class=p>[:</span><span class=n>padding_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>+=</span> <span class=p>(</span><span class=n>indices</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>padding_size</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)))[:</span><span class=n>padding_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># remove tail of data to make it evenly divisible.</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=n>indices</span><span class=p>[:</span><span class=bp>self</span><span class=o>.</span><span class=n>total_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>total_size</span>
</span></span><span class=line><span class=cl><span class=c1># subsample</span>
</span></span><span class=line><span class=cl><span class=c1># rank 代表进程 id</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>indices</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=p>:</span><span class=bp>self</span><span class=o>.</span><span class=n>total_size</span><span class=p>:</span><span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=nb>iter</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>
</span></span></code></pre></div></details></p><h4 id=ring-all-reduce>Ring All-Reduce<a hidden class=anchor aria-hidden=true href=#ring-all-reduce>#</a></h4><p>那么什么是<strong>Ring All-Reduce</strong>呢？又为啥可以降低通信成本呢？</p><p>首先将每块 GPU 上的梯度拆分成四个部分，比如$g_0 = [a_0; b_0; c_0; d_0]$，如下图（此部分原理致谢下王老师，讲的很清晰<sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>）：</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/q72OKSHhmuXYWvN.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/q72OKSHhmuXYWvN.png#center alt="Ring All-Reduce 1" width=450px height=250px><figcaption><p><a href="https://www.youtube.com/watch?v=rj-hjS5L8Bw">Ring All-Reduce 1</a></p></figcaption></figure></a><p>所有 GPU 的传播都是<strong>同步</strong>进行的，传播的规律有两条：</p><ol><li>只与自己<em>下一个位置</em>的 GPU 进行通信，比如 0 > 1，3 > 0</li><li>四个部分，哪块 GPU 上占的多，就由该块 GPU 往它下一个传，初始从主节点传播，即 GPU0，你可以想象跟接力一样，a 传 b，b 负责传给 c</li></ol><p>第一次传播如下：</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/MNWF2dtB7wOsIoK.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/MNWF2dtB7wOsIoK.png#center alt="Ring All-Reduce 2" width=450px height=250px><figcaption><p><a href="https://www.youtube.com/watch?v=rj-hjS5L8Bw">Ring All-Reduce 2</a></p></figcaption></figure></a><p>那么结果就是：</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/4mfqWSMjO3IokxH.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/4mfqWSMjO3IokxH.png#center alt="Ring All-Reduce 3" width=450px height=250px><figcaption><p><a href="https://www.youtube.com/watch?v=rj-hjS5L8Bw">Ring All-Reduce 3</a></p></figcaption></figure></a><p>那么，按照谁多谁往下传的原则，此时应该是 GPU1 往 GPU2 传 a0 和 a1，GPU2 往 GPU3 传 b1 和 b2，以此类推</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/4mfqWSMjO3IokxH.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/4mfqWSMjO3IokxH.png#center alt="Ring All-Reduce 4" width=450px height=250px><figcaption><p><a href="https://www.youtube.com/watch?v=rj-hjS5L8Bw">Ring All-Reduce 4</a></p></figcaption></figure></a><p>接下来再传播就会有 GPU3 a 的部分全有，GPU0 上 b 的部分全有等，就再往下传</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/v3jzp4PIQSYERZy.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/v3jzp4PIQSYERZy.png#center alt="Ring All-Reduce 5" width=450px height=250px><figcaption><p><a href="https://www.youtube.com/watch?v=rj-hjS5L8Bw">Ring All-Reduce 5</a></p></figcaption></figure></a><p>再来几遍便可以使得每块 GPU 上都获得了来自其他 GPU 的梯度啦</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/OA2Ikvxt59YGiVH.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/OA2Ikvxt59YGiVH.png#center alt="Ring All-Reduce 6" width=450px height=250px><figcaption><p><a href="https://www.youtube.com/watch?v=rj-hjS5L8Bw">Ring All-Reduce 6</a></p></figcaption></figure></a><h3 id=代码使用-1>代码使用<a hidden class=anchor aria-hidden=true href=#代码使用-1>#</a></h3><h4 id=基础概念>基础概念<a hidden class=anchor aria-hidden=true href=#基础概念>#</a></h4><p>第一个是后端的选择，即数据传输协议，从下表可以看出<sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup>，当使用 CPU 时可以选择<code>gloo</code>而 GPU 则可以是<code>nccl</code></p><table><thead><tr><th style=text-align:center><strong>Backend</strong></th><th style=text-align:center><strong>gloo</strong></th><th style=text-align:center></th><th style=text-align:center><strong>mpi</strong></th><th style=text-align:center></th><th style=text-align:center><strong>nccl</strong></th><th style=text-align:center></th></tr></thead><tbody><tr><td style=text-align:center>Device</td><td style=text-align:center>CPU</td><td style=text-align:center>GPU</td><td style=text-align:center>CPU</td><td style=text-align:center>GPU</td><td style=text-align:center>CPU</td><td style=text-align:center>GPU</td></tr><tr><td style=text-align:center>send</td><td style=text-align:center>✓</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>recv</td><td style=text-align:center>✓</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>broadcast</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>all_reduce</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>reduce</td><td style=text-align:center>✓</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>all_gather</td><td style=text-align:center>✓</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>gather</td><td style=text-align:center>✓</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>scatter</td><td style=text-align:center>✓</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✘</td></tr><tr><td style=text-align:center>reduce_scatter</td><td style=text-align:center>✘</td><td style=text-align:center>✘</td><td style=text-align:center>✘</td><td style=text-align:center>✘</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>all_to_all</td><td style=text-align:center>✘</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr><tr><td style=text-align:center>barrier</td><td style=text-align:center>✓</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td><td style=text-align:center>?</td><td style=text-align:center>✘</td><td style=text-align:center>✓</td></tr></tbody></table><p>接下来是一些参数的解释<sup id=fnref:9><a href=#fn:9 class=footnote-ref role=doc-noteref>9</a></sup>：</p><table><thead><tr><th style=text-align:center>Arg</th><th style=text-align:center>Meaning</th></tr></thead><tbody><tr><td style=text-align:center>group</td><td style=text-align:center>一次发起的所有进程构成一个 group，除非想更精细通信，创建 new_group</td></tr><tr><td style=text-align:center>world_size</td><td style=text-align:center>一个 group 中进程数目，即为 GPU 的数量</td></tr><tr><td style=text-align:center>rank</td><td style=text-align:center>进程 id，主节点 rank=0，其他的在 0 和 world_size-1 之间</td></tr><tr><td style=text-align:center>local_rank</td><td style=text-align:center>进程在本地节点/机器的 id</td></tr></tbody></table><p>举个例子，假如你有两台服务器（又被称为 node），每台服务器有 4 张 GPU，那么，world_size 即为 8，rank=[0, 1, 2, 3, 4, 5, 6, 7], 每个服务器上的进程的 local_rank 为[0, 1, 2, 3]</p><p>然后是<strong>初始化方法</strong>的选择，有<code>TCP</code>和<code>共享文件</code>两种，一般指定 rank=0 为 master 节点</p><p>TCP 显而易见是通过网络进行传输，需要指定主节点的 ip（可以为主节点实际 IP，或者是 localhost）和空闲的端口</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.distributed</span> <span class=k>as</span> <span class=nn>dist</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span><span class=n>backend</span><span class=p>,</span> <span class=n>init_method</span><span class=o>=</span><span class=s1>&#39;tcp://ip:port&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=o>=</span><span class=n>world_size</span><span class=p>)</span>
</span></span></code></pre></div><p>共享文件的话需要手动删除上次启动时残留的文件，加上官方有一堆警告，还是建议使用 TCP</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span><span class=n>backend</span><span class=p>,</span> <span class=n>init_method</span><span class=o>=</span><span class=s1>&#39;file://Path&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=o>=</span><span class=n>world_size</span><span class=p>)</span>
</span></span></code></pre></div><h4 id=launch-方法>launch 方法<a hidden class=anchor aria-hidden=true href=#launch-方法>#</a></h4><h5 id=初始化>初始化<a hidden class=anchor aria-hidden=true href=#初始化>#</a></h5><p>这里先讲用 launch 的方法，关于 torch.multiprocessing 留到后面讲</p><p>在启动后，rank 和 world_size 都会自动被 DDP 写入环境中，可以提前准备好参数类，如<code>argparse</code>这种</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>args</span><span class=o>.</span><span class=n>rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;RANK&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>args</span><span class=o>.</span><span class=n>world_size</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;WORLD_SIZE&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>args</span><span class=o>.</span><span class=n>local_rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;LOCAL_RANK&#39;</span><span class=p>])</span>
</span></span></code></pre></div><p>首先，在使用<code>distributed</code>包的任何其他函数之前，按照 tcp 方法进行初始化，需要注意的是需要手动指定一共可用的设备<code>CUDA_VISIBLE_DEVICES</code></p><p><details><summary markdown=span>DDP launch 源码</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>dist_setup_launch</span><span class=p>(</span><span class=n>args</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># tell DDP available devices [NECESSARY]</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>args</span><span class=o>.</span><span class=n>devices</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>.</span><span class=n>rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;RANK&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>.</span><span class=n>world_size</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;WORLD_SIZE&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>.</span><span class=n>local_rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;LOCAL_RANK&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>backend</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>args</span><span class=o>.</span><span class=n>init_method</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>rank</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>rank</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>world_size</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># this is optional, otherwise you may need to specify the</span>
</span></span><span class=line><span class=cl>    <span class=c1># device when you move something e.g., model.cuda(1)</span>
</span></span><span class=line><span class=cl>    <span class=c1># or model.to(args.rank)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Setting device makes things easy: model.cuda()</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>set_device</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>rank</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;The Current Rank is </span><span class=si>%d</span><span class=s1> | The Total Ranks are </span><span class=si>%d</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>          <span class=o>%</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>rank</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>world_size</span><span class=p>))</span>
</span></span></code></pre></div></details></p><h5 id=distributedsampler>DistributedSampler<a hidden class=anchor aria-hidden=true href=#distributedsampler>#</a></h5><p>接下来创建 DistributedSampler，是否 pin_memory，根据你本机的内存决定。pin_memory 的意思是提前在内存中申请一部分专门存放 Tensor。假如说你内存比较小，就会跟虚拟内存，即硬盘进行交换，这样转义到 GPU 上会比内存直接到 GPU 耗时。</p><p>因而，如果你的内存比较大，可以设置为 True；然而，如果开了导致卡顿的情况，建议关闭</p><p><details><summary markdown=span>加载 DataLoader</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>DataLoader</span><span class=p>,</span> <span class=n>DistributedSampler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train_sampler</span> <span class=o>=</span> <span class=n>DistributedSampler</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>,</span> <span class=n>seed</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>train_dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>shuffle</span><span class=o>=</span><span class=p>(</span><span class=n>train_sampler</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                              <span class=n>batch_size</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>per_gpu_train_bs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>num_workers</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>num_workers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>sampler</span><span class=o>=</span><span class=n>train_sampler</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>eval_sampler</span> <span class=o>=</span> <span class=n>DistributedSampler</span><span class=p>(</span><span class=n>eval_dataset</span><span class=p>,</span> <span class=n>seed</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>eval_dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>eval_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=n>batch_size</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>per_gpu_eval_bs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=n>num_workers</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>num_workers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=n>sampler</span><span class=o>=</span><span class=n>eval_sampler</span><span class=p>)</span>
</span></span></code></pre></div></details></p><h5 id=加载模型>加载模型<a hidden class=anchor aria-hidden=true href=#加载模型>#</a></h5><p>然后加载模型，跟 DataParallel 不同的是需要提前放置到 cuda 上，还记得上面关于设置 cuda_device 的语句嘛，因为设置好之后每个进程只能看见一个 GPU，所以直接<code>model.cuda()</code>，不需要指定 device</p><p>同时，我们必须给 DDP 提示目前是哪个 rank</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.nn.parallel</span> <span class=kn>import</span> <span class=n>DistributedDataParallel</span> <span class=k>as</span> <span class=n>DDP</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># tell DDP which rank</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>DDP</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>find_unused_parameters</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=p>[</span><span class=n>rank</span><span class=p>])</span>
</span></span></code></pre></div><p>注意，当模型带有 Batch Norm 时：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=n>args</span><span class=o>.</span><span class=n>syncBN</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>nn</span><span class=o>.</span><span class=n>SyncBatchNorm</span><span class=o>.</span><span class=n>convert_sync_batchnorm</span><span class=p>(</span><span class=n>model</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span></code></pre></div><h5 id=训练相关>训练相关<a hidden class=anchor aria-hidden=true href=#训练相关>#</a></h5><p>每个 epoch 开始训练的时候，记得用 sampler 的 set_epoch，使得每个 epoch 打乱顺序是不一致的</p><p>关于梯度回传和参数更新，跟正常情况无异</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># record epochs</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataloader</span><span class=o>.</span><span class=n>sampler</span><span class=o>.</span><span class=n>set_epoch</span><span class=p>(</span><span class=n>epoch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>loss_fct</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span></code></pre></div><p>这里有一点需要小心，这个 loss 是各个进程的 loss 之和，如果想要存储每个 step 平均损失，可以进行 all_reduce 操作，进行平均，不妨看官方的小例子来理解下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=c1># All tensors below are of torch.int64 type.</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=c1># We have 2 process groups, 2 ranks.</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>rank</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span> <span class=c1># Rank 0</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span> <span class=c1># Rank 1</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>dist</span><span class=o>.</span><span class=n>all_reduce</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>op</span><span class=o>=</span><span class=n>ReduceOp</span><span class=o>.</span><span class=n>SUM</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>4</span><span class=p>,</span> <span class=mi>6</span><span class=p>])</span> <span class=c1># Rank 0</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>4</span><span class=p>,</span> <span class=mi>6</span><span class=p>])</span> <span class=c1># Rank 1</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@torch.no_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>reduce_value</span><span class=p>(</span><span class=n>value</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>world_size</span> <span class=o>=</span> <span class=n>get_world_size</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>world_size</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>:</span>  <span class=c1># 单 GPU 的情况</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>value</span>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>all_reduce</span><span class=p>(</span><span class=n>value</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>average</span><span class=p>:</span>
</span></span><span class=line><span class=cl>	    <span class=n>value</span> <span class=o>/=</span> <span class=n>world_size</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>value</span>
</span></span></code></pre></div><p>看到这，肯定有小伙伴要问，那这样我们是不是得先求平均损失再回传梯度啊，不用，因为，当我们回传 loss 后，DDP 会自动对所有<em>梯度进行平均</em><sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>，也就是说回传后我们更新的梯度和 DP 或者单卡同样 batch 训练都是一致的</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>loss_fct</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># 注意在 backward 后面</span>
</span></span><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>reduce_value</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mean_loss</span> <span class=o>=</span> <span class=p>(</span><span class=n>step</span> <span class=o>*</span> <span class=n>mean_loss</span> <span class=o>+</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>())</span> <span class=o>/</span> <span class=p>(</span><span class=n>step</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><p>还有个注意点就是学习率的变化，这个是和 batch size 息息相关的，如果 batch 扩充了几倍，也就是说 step 比之前少了很多，还采用同一个学习率，肯定会出问题的，这里，我们进行线性增大<sup id=fnref:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>N</span> <span class=o>=</span> <span class=n>world_size</span>
</span></span><span class=line><span class=cl><span class=n>lr</span> <span class=o>=</span> <span class=n>args</span><span class=o>.</span><span class=n>lr</span> <span class=o>*</span> <span class=n>N</span>
</span></span></code></pre></div><p>肯定有人说，诶，你线性增大肯定不能保证梯度的 variance 一致了，正确的应该是正比于$\sqrt{N}$，关于这个的讨论不妨参考<sup id=fnref:12><a href=#fn:12 class=footnote-ref role=doc-noteref>12</a></sup></p><h5 id=evaluate-相关>evaluate 相关<a hidden class=anchor aria-hidden=true href=#evaluate-相关>#</a></h5><p>接下来，细心的同学肯定好奇了，如果验证集也切分了，metric 怎么计算呢？此时就需要咱们把每个进程得到的预测情况集合起来，t 就是一个我们需要 gather 的张量，最后将每个进程中的 t 按照第一维度拼接，先看官方小例子来理解 all_gather</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=c1># All tensors below are of torch.int64 dtype.</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=c1># We have 2 process groups, 2 ranks.</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor_list</span> <span class=o>=</span> <span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>)]</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor_list</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>tensor</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]),</span> <span class=n>tensor</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>])]</span> <span class=c1># Rank 0 and 1</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>rank</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span> <span class=c1># Rank 0</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span> <span class=c1># Rank 1</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>dist</span><span class=o>.</span><span class=n>all_gather</span><span class=p>(</span><span class=n>tensor_list</span><span class=p>,</span> <span class=n>tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor_list</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]),</span> <span class=n>tensor</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])]</span> <span class=c1># Rank 0</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]),</span> <span class=n>tensor</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])]</span> <span class=c1># Rank 1</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>sync_across_gpus</span><span class=p>(</span><span class=n>t</span><span class=p>,</span> <span class=n>world_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>gather_t_tensor</span> <span class=o>=</span> <span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>t</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span>
</span></span><span class=line><span class=cl>                       <span class=nb>range</span><span class=p>(</span><span class=n>world_size</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>all_gather</span><span class=p>(</span><span class=n>gather_t_tensor</span><span class=p>,</span> <span class=n>t</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>gather_t_tensor</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span></code></pre></div><p>可以简单参考我前面提供的源码的 evaluate 部分，我们首先将预测和标签比对，把结果为 bool 的张量存储下来，最终 gather 求和取平均。</p><p>这里还有个有趣的地方，tensor 默认的类型可能是 int，bool 型的 res 拼接后自动转为 0 和 1 了，另外 bool 型的张量是不支持 gather 的</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>eval</span><span class=p>(</span><span class=o>...</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([])</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>step</span><span class=p>,</span> <span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span> <span class=o>=</span> <span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>results</span><span class=p>,</span> <span class=n>res</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>sync_across_gpus</span><span class=p>(</span><span class=n>results</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mean_acc</span> <span class=o>=</span> <span class=p>(</span><span class=n>results</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>))</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mean_acc</span>
</span></span></code></pre></div><h5 id=模型保存与加载>模型保存与加载<a hidden class=anchor aria-hidden=true href=#模型保存与加载>#</a></h5><p>模型保存，参考部分官方教程<sup id=fnref:13><a href=#fn:13 class=footnote-ref role=doc-noteref>13</a></sup>，我们只需要在主进程保存模型即可，注意，这里是被 DDP 包裹后的，DDP 并没有 state_dict，这里 barrier 的目的是为了让其他进程等待主进程保存模型，以防不同步</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>save_checkpoint</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>is_main_process</span><span class=p>(</span><span class=n>rank</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    	<span class=c1># All processes should see same parameters as they all</span>
</span></span><span class=line><span class=cl>        <span class=c1># start from same random parameters and gradients are</span>
</span></span><span class=line><span class=cl>        <span class=c1># synchronized in backward passes.</span>
</span></span><span class=line><span class=cl>        <span class=c1># Therefore, saving it in one process is sufficient.</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span> <span class=n>path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Use a barrier() to keep process 1 waiting for process 0</span>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>barrier</span><span class=p>()</span>
</span></span></code></pre></div><p>加载的时候别忘了 map_location，我们一开始会保存模型至主进程，这样就会导致 cuda:0 显存被占据，我们需要将模型 remap 到其他设备</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_checkpoint</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># remap the model from cuda:0 to other devices</span>
</span></span><span class=line><span class=cl>    <span class=n>map_location</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;cuda:</span><span class=si>%d</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=mi>0</span><span class=p>:</span> <span class=s1>&#39;cuda:</span><span class=si>%d</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=n>rank</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=n>map_location</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><h5 id=进程销毁>进程销毁<a hidden class=anchor aria-hidden=true href=#进程销毁>#</a></h5><p>运行结束后记得销毁进程：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>cleanup</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>destroy_process_group</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cleanup</span><span class=p>()</span>
</span></span></code></pre></div><h5 id=如何启动>如何启动<a hidden class=anchor aria-hidden=true href=#如何启动>#</a></h5><p>在终端输入下列命令【单机多卡】</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python -m torch.distributed.launch --nproc_per_node<span class=o>=</span>NUM_GPUS
</span></span><span class=line><span class=cl>          main.py <span class=o>(</span>--arg1 --arg2 --arg3 and all other
</span></span><span class=line><span class=cl>          arguments of your training script<span class=o>)</span>
</span></span></code></pre></div><p>目前 torch 1.10 以后更推荐用 run</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>distributed</span><span class=o>.</span><span class=n>launch</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>distributed</span><span class=o>.</span><span class=n>run</span> <span class=o>/</span> <span class=n>torchrun</span>
</span></span></code></pre></div><p>多机多卡是这样的：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 第一个节点启动</span>
</span></span><span class=line><span class=cl>python -m torch.distributed.launch <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nproc_per_node<span class=o>=</span>NUM_GPUS <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nnodes<span class=o>=</span><span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --node_rank<span class=o>=</span><span class=m>0</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --master_addr<span class=o>=</span><span class=s2>&#34;192.168.1.1&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --master_port<span class=o>=</span><span class=m>1234</span> main.py
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 第二个节点启动</span>
</span></span><span class=line><span class=cl>python -m torch.distributed.launch <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nproc_per_node<span class=o>=</span>NUM_GPUS <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nnodes<span class=o>=</span><span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --node_rank<span class=o>=</span><span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --master_addr<span class=o>=</span><span class=s2>&#34;192.168.1.1&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --master_port<span class=o>=</span><span class=m>1234</span> main.py
</span></span></code></pre></div><h4 id=mp-方法>mp 方法<a hidden class=anchor aria-hidden=true href=#mp-方法>#</a></h4><p>第二个方法就是利用 torch 的多线程包</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.multiprocessing</span> <span class=k>as</span> <span class=nn>mp</span>
</span></span><span class=line><span class=cl><span class=c1># rank mp 会自动填入</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>arg1</span><span class=p>,</span> <span class=o>...</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>pass</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>mp</span><span class=o>.</span><span class=n>spawn</span><span class=p>(</span><span class=n>main</span><span class=p>,</span> <span class=n>nprocs</span><span class=o>=</span><span class=n>TOTAL_GPUS</span><span class=p>,</span> <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=n>arg1</span><span class=p>,</span> <span class=o>...</span><span class=p>))</span>
</span></span></code></pre></div><p>这里输入参数时务必注意要给定 iterable 形式，比如你的 main 方法除了 rank 还接受一个 int 类型参数，你 spawn 方法时需要以元组形式给定：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># Note that is (1, ) not (1)</span>
</span></span><span class=line><span class=cl>    <span class=n>mp</span><span class=o>.</span><span class=n>spawn</span><span class=p>(</span><span class=n>main</span><span class=p>,</span> <span class=n>nprocs</span><span class=o>=</span><span class=n>TOTAL_GPUS</span><span class=p>,</span> <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=p>))</span>
</span></span></code></pre></div><p>同时因为此种方法是自动给定 rank，我们不需要在初始化时告诉可用的设备有哪些，否则多个进程无法同时启动</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>dist_setup_mp</span><span class=p>(</span><span class=n>args</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># there is no need to set CUDA_VISIBLE_DEVICES</span>
</span></span><span class=line><span class=cl>    <span class=c1># os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = args.devices</span>
</span></span></code></pre></div><p>这种运行的时候就跟正常的 python 文件一致：<code>python main.py</code></p><h3 id=优缺点-1>优缺点<a hidden class=anchor aria-hidden=true href=#优缺点-1>#</a></h3><ul><li><strong>优点</strong>： 相比于 DP 而言，不需要反复创建和销毁线程；Ring All-Reduce 算法提高通信效率；模型同步方便</li><li><strong>缺点</strong>：操作起来可能有些复杂，一般可满足需求的可先试试看 DataParallel</li></ul><h3 id=possible-bugs>Possible Bugs<a hidden class=anchor aria-hidden=true href=#possible-bugs>#</a></h3><div class="notice notice-warning"><div class=notice-title><svg xmlns="http://www.w3.org/2000/svg" class="icon notice-icon" viewBox="0 0 576 512"><path d="M570 440c18 32-5 72-42 72H48c-37 0-60-40-42-72L246 24c19-32 65-32 84 0l240 416zm-282-86a46 46 0 100 92 46 46 0 000-92zm-44-165 8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z"/></svg></div><p>Producer process has been terminated before all shared CUDA tensors released. See Note Sharing CUDA tensors</p></div><p>这个应该是用 mp 方法时在 DataLoader 里设置 num_workers 大于导致，应该是 torch 的 multiprocessing 会每一个 num_worker 复制一个模型<sup id=fnref:14><a href=#fn:14 class=footnote-ref role=doc-noteref>14</a></sup></p><div class="notice notice-warning"><div class=notice-title><svg xmlns="http://www.w3.org/2000/svg" class="icon notice-icon" viewBox="0 0 576 512"><path d="M570 440c18 32-5 72-42 72H48c-37 0-60-40-42-72L246 24c19-32 65-32 84 0l240 416zm-282-86a46 46 0 100 92 46 46 0 000-92zm-44-165 8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z"/></svg></div><p>RuntimeError: cannot pin ‘torch.cuda.ByteTensor’ only dense CPU tensors can be pinned</p></div><p>还记得我们前面对于<code>pin_memory</code>的解释，是在内存中专门开辟一块空间，专门用于与 GPU 的通信，那么没到 GPU 之前就是 CPU，也就是 CPU tensors 才能被 pin</p><p>出现这个 bug 的原因可能是你在 DataLoader 内部处理时已经将张量放到了 GPU 上<sup id=fnref:15><a href=#fn:15 class=footnote-ref role=doc-noteref>15</a></sup>，比如自定义<code>collate_func</code></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://blog.csdn.net/qq_37541097/article/details/109736159>https://blog.csdn.net/qq_37541097/article/details/109736159</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://www.cnblogs.com/ljwgis/p/15471530.html>https://www.cnblogs.com/ljwgis/p/15471530.html</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href="https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html?highlight=dataparallel">https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html?highlight=dataparallel</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p><a href=https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html>https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p><a href=https://github.com/kimiyoung/transformer-xl>https://github.com/kimiyoung/transformer-xl</a>&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p><a href=https://github.com/sherlcok314159/dl-tools/blob/main/balanced_data_parallel/README.md>https://github.com/sherlcok314159/dl-tools/blob/main/balanced_data_parallel/README.md</a>&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p><a href="https://www.youtube.com/watch?v=rj-hjS5L8Bw">https://www.youtube.com/watch?v=rj-hjS5L8Bw</a>&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8><p><a href=https://pytorch.org/docs/stable/distributed.html#backends>https://pytorch.org/docs/stable/distributed.html#backends</a>&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:9><p><a href=https://stackoverflow.com/questions/58271635/in-distributed-computing-what-are-world-size-and-rank>https://stackoverflow.com/questions/58271635/in-distributed-computing-what-are-world-size-and-rank</a>&#160;<a href=#fnref:9 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:10><p><a href=https://discuss.pytorch.org/t/average-loss-in-dp-and-ddp/93306/4>https://discuss.pytorch.org/t/average-loss-in-dp-and-ddp/93306/4</a>&#160;<a href=#fnref:10 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:11><p><a href=https://arxiv.org/abs/1706.02677>https://arxiv.org/abs/1706.02677</a>&#160;<a href=#fnref:11 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:12><p><a href=https://github.com/Lightning-AI/lightning/discussions/3706>https://github.com/Lightning-AI/lightning/discussions/3706</a>&#160;<a href=#fnref:12 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:13><p><a href=https://pytorch.org/tutorials/intermediate/ddp_tutorial.html>https://pytorch.org/tutorials/intermediate/ddp_tutorial.html</a>&#160;<a href=#fnref:13 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:14><p><a href=https://discuss.pytorch.org/t/w-cudaipctypes-cpp-22-producer-process-has-been-terminated-before-all-shared-cuda-tensors-released-see-note-sharing-cuda-tensors/124445/1>https://discuss.pytorch.org/t/w-cudaipctypes-cpp-22-producer-process-has-been-terminated-before-all-shared-cuda-tensors-released-see-note-sharing-cuda-tensors/124445/1</a>&#160;<a href=#fnref:14 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:15><p><a href=https://discuss.pytorch.org/t/what-are-dense-cpu-tensor/55703>https://discuss.pytorch.org/t/what-are-dense-cpu-tensor/55703</a>&#160;<a href=#fnref:15 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div style="margin-top:2em;padding:1em;border:0 solid;border-radius:10px;background-color:var(--code-bg)"><h3>如果您想要引用，请考虑如下格式：</h3><div style=padding-top:.5em>台运鹏. (Nov. 20, 2022). 《Diving in distributed training in PyTorch》[Blog
post]. Retrieved from http://yunpengtai.top/posts/dive-in-distributed-training/</div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>@online{blog-152455e9c9fc6289f3c842281b3dea63,
</span></span><span class=line><span class=cl>        title={Diving in distributed training in PyTorch},
</span></span><span class=line><span class=cl>        author={Yunpeng Tai},
</span></span><span class=line><span class=cl>        year={2022},
</span></span><span class=line><span class=cl>        month={Nov},
</span></span><span class=line><span class=cl>        note={http://yunpengtai.top/posts/dive-in-distributed-training/},
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><div style=padding-bottom:.4em>自由转载-非商用-非衍生-保持署名（<a href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-SA 4.0）</a></div></div><footer class=post-footer><ul class=post-tags><li><a href=http://yunpengtai.top/tags/pytorch/>pytorch</a></li><li><a href=http://yunpengtai.top/tags/%E8%AE%AD%E7%BB%83/>训练</a></li></ul><nav class=paginav><a class=prev href=http://yunpengtai.top/posts/generalized-linear-models/><span class=title>« Prev</span><br><span>Generalized Linear Models</span></a>
<a class=next href=http://yunpengtai.top/posts/deep-back-propagation/><span class=title>Next »</span><br><span>Going Deeper into Back-Propagation</span></a></nav></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/artalk@2.8.6/dist/Artalk.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/@artalk/plugin-katex@0.2.4/dist/artalk-plugin-katex.min.js></script><div id=Comments></div><script>const savedTheme=localStorage.getItem("pref-theme");let darkMode="auto";savedTheme!==null&&(darkMode=savedTheme==="dark");const artalk=Artalk.init({el:"#Comments",pageKey:"",pageTitle:"Diving in distributed training in PyTorch",server:"https://comment.yunpengtai.top",site:"Tai's Blog",darkMode,versionCheck:!1});document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?artalk.setDarkMode(!1):artalk.setDarkMode(!0)})</script></article></main><footer class=footer><span>&copy; 2025 <a href=http://yunpengtai.top>Tai's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/sherlcok314159/MyPaperMod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.min.js",function(){pangu.spacingPage()})</script><script>(function(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}})()</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>