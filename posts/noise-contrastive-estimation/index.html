<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Noise Contrastive Estimation | Tai's Blog</title><meta name=keywords content="proxy problem,contrastive learning"><meta name=description content="难以承受之重 文本生成是 NLP 任务中比较典型的一类，记参数为$\boldsymbol{\theta }$，给定的 context 为$\boldsymbol{c}$"><meta name=author content><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="eAKh7zszsOtNde1wyq_sUo95ZPH4zTTJhR-_ol4VWDs"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yunpengtai.top/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yunpengtai.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yunpengtai.top/favicon-32x32.png><link rel=apple-touch-icon href=https://yunpengtai.top/apple-touch-icon.png><link rel=mask-icon href=https://yunpengtai.top/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script>MathJax={loader:{load:["[tex]/boldsymbol"]},tex:{tags:"all",inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,packages:{"[+]":["boldsymbol"]}}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js integrity="sha256-kbAFUDxdHwlYv01zraGjvjNZayxKtdoiJ38bDTFJtaQ=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y3CX2RWEDY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Y3CX2RWEDY",{anonymize_ip:!1})}</script><meta property="og:title" content="Noise Contrastive Estimation"><meta property="og:description" content="难以承受之重 文本生成是 NLP 任务中比较典型的一类，记参数为$\boldsymbol{\theta }$，给定的 context 为$\boldsymbol{c}$"><meta property="og:type" content="article"><meta property="og:url" content="https://yunpengtai.top/posts/noise-contrastive-estimation/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-29T14:40:00+08:00"><meta property="article:modified_time" content="2023-05-29T14:40:00+08:00"><meta property="og:site_name" content="Tai's Blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://yunpengtai.top/posts/"},{"@type":"ListItem","position":3,"name":"Noise Contrastive Estimation","item":"https://yunpengtai.top/posts/noise-contrastive-estimation/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Noise Contrastive Estimation","name":"Noise Contrastive Estimation","description":"难以承受之重 文本生成是 NLP 任务中比较典型的一类，记参数为$\\boldsymbol{\\theta }$，给定的 context 为$\\boldsymbol{c}$","keywords":["proxy problem","contrastive learning"],"articleBody":"难以承受之重 文本生成是 NLP 任务中比较典型的一类，记参数为$\\boldsymbol{\\theta }$，给定的 context 为$\\boldsymbol{c}$，需要生成的文本记为$\\boldsymbol{w}$，我们通常通过最大似然法来使得模型预测的分布$p_{\\boldsymbol{\\theta}}$尽可能接近训练集分布$p_{d}(\\boldsymbol{w})$\n$$ \\boldsymbol{\\theta ^{\\ast}} = \\mathop{\\arg \\max}_{\\boldsymbol{\\theta }} \\ \\mathbb{E}_{\\boldsymbol{c}, \\boldsymbol{w} \\sim p_{d}} \\log p_{\\boldsymbol{\\theta }}(\\boldsymbol{w}|\\boldsymbol{c};\\boldsymbol{\\theta }) $$\n而在建模时，我们通常会在模型加入 Softmax 来将 score 转换为概率，使得对词表$\\mathcal{V}$所有词预测概率相加为 1：\n$$ p(\\boldsymbol{w}|\\boldsymbol{c};\\boldsymbol{\\theta}) = \\frac{u_{\\boldsymbol{\\theta }}(\\boldsymbol{w}, \\boldsymbol{c})}{\\underbrace{ {\\color{blue}\\sum_{\\boldsymbol{w}' \\in \\mathcal{V}} u_{\\boldsymbol{\\theta}}(\\boldsymbol{w}', \\boldsymbol{c})} }_{ \\text{Partition Function} }}, u_{\\boldsymbol{\\theta }}(\\boldsymbol{w}, \\boldsymbol{c}) = \\exp(s_{\\theta }(\\boldsymbol{w}, \\boldsymbol{c})) $$\n分母是用来归一化的，也被称作配分函数（Partition Function），为了使得表达更简便，我们将上述公式进一步压缩，将分母统称为$Z(\\boldsymbol{\\theta })$\n若是普通的多分类问题，参数量不大，求$Z(\\boldsymbol{\\theta })$感觉不到压力，可若是文本生成任务，例如，「文本____是自然语言处理的任务」，此时你得去整个词表$\\mathcal{V}$中来挑选词来填空，去计算$Z(\\boldsymbol{\\theta })$就是十分昂贵的事情了\n丢给参数 那么，有人就说了，不行那就直接交给参数处理吧，让模型自己去学，看看模型自己能不能学出归一化：\n$$ p(\\boldsymbol{w}|\\boldsymbol{c};\\boldsymbol{\\theta}) = \\frac{u_{\\boldsymbol{\\theta }}(\\boldsymbol{w}, \\boldsymbol{c})}{Z(\\boldsymbol{\\theta })} = u_{\\boldsymbol{\\theta }}(\\boldsymbol{w}, \\boldsymbol{c})\\exp(z^{\\boldsymbol{c}}), \\, z^{\\boldsymbol{c}} = -\\log Z(\\boldsymbol{\\theta }) $$\n接着应用最大似然：\n$$ \\begin{align} \\boldsymbol{\\theta ^{\\ast}} \u0026 = \\mathop{\\arg \\max}_{\\boldsymbol{\\theta }} \\ \\mathbb{E}_{\\boldsymbol{c}, \\boldsymbol{w} \\sim p_{d}} \\log p_{\\boldsymbol{\\theta }}(\\boldsymbol{w}|\\boldsymbol{c};\\boldsymbol{\\theta }) \\\\ \u0026= \\mathop{\\arg \\max}_{\\boldsymbol{\\theta }, \\boldsymbol{z}} \\ \\mathbb{E}_{\\boldsymbol{c}, \\boldsymbol{w} \\sim p_{d}} \\log u_{\\boldsymbol{\\theta }}(\\boldsymbol{w},\\boldsymbol{c})\\exp(z^{\\boldsymbol{c}}) \\end{align} $$ 这样的结果就是，为了最大化期望，会使得$Z(\\boldsymbol{\\theta }) \\to 0$，效果会很不好\n曲径通幽 那么 Noise Contrastive Estimation（NCE）说，既然这样，我们能不能引入参数的同时也可以出色地预估$Z(\\boldsymbol{\\theta })$呢？于是乎，它将问题从原本的多分类问题转换为二分类问题 Proxy Problem，指用新的任务或指标来完成对原本任务的建模 ，具体如下：\n首先，存在一个噪声分布$p_{n}$和经验概率分布$p_{d}$，这里$p_{d}$是从训练集提取的，就类似 word2vec 的训练，将句子切分成词 现代 NLP 基本都是 token，这里是为了表达简便 ，统计某几个词一起出现的概率，那么$p(\\boldsymbol{w}|\\boldsymbol{c})$就是对于$\\boldsymbol{c}$而言，下一个词是$\\boldsymbol{w}$的概率。举个例子，对于 love 而言：$p_{d}=\\{ \\text{games}: 0.9, \\text{study}: 0.1 \\}$\n每次从$p_{d}$中抽出一个候选词，从$p_{n}$中抽取$k$个候选词。模型的任务即为区分候选词是从训练集还是噪声中采样而来的，通过这个代理任务使得$p_{\\boldsymbol{\\theta}}(\\boldsymbol{c})$去逼近于$p_{d}(\\boldsymbol{c})$\n我们规定，当$\\mathcal{D}=1$时代表从训练集采样，而$\\mathcal{D}=0$则代表从噪声中采样，那么：\n$$ \\begin{align} p(\\boldsymbol{w}|\\mathcal{D} =1, \\boldsymbol{c}) \u0026 = p_{d}(\\boldsymbol{w})\\\\ p(\\boldsymbol{w}|\\mathcal{D} = 0, {\\boldsymbol{c}}) \u0026 = p_{n}({\\boldsymbol{w}}) \\end{align} $$\n那么总概率即为：\n$$ p_{joint}(\\boldsymbol{w}) =\\frac{1}{k+1}p_{d}(\\boldsymbol{w}) + \\frac{k}{k+1} p_{n}(\\boldsymbol{w}) $$\n接下来求一下来自哪个采样的条件概率：\n$$ \\begin{align} p(\\mathcal{D}=1|\\boldsymbol{w}) \u0026 = \\frac{p(\\mathcal{D}=1,\\boldsymbol{w})}{p_{joint}(\\boldsymbol{w})} = \\frac{p(\\boldsymbol{w}|\\mathcal{D}=1)p(\\mathcal{D}=1)}{p_{joint}(\\boldsymbol{w})} \\\\ \u0026 = \\frac{p_{d}(\\boldsymbol{w})}{p_{d}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\end{align} $$\n同理：\n$$ p(\\mathcal{D}=0|\\boldsymbol{w}) = \\frac{kp_{n}(\\boldsymbol{w})}{p_{d}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} $$\n$\\mathcal{D}$代表训练集和噪声集的集合，那么 NCE 的目标即为最大化期望：\n$$ \\boldsymbol{\\theta }^{\\ast} = \\mathop{\\arg \\max}_{\\boldsymbol{\\theta }}\\ \\mathbb{E}_{\\boldsymbol{w} \\sim \\mathcal{D}} \\log p(\\mathcal{D}|\\boldsymbol{w}) $$\n又因为我们想要让模型分布$p_{\\boldsymbol{\\theta }}$尽可能接近训练集分布$p_{d}$，于是我们在求条件概率时，将$p_{d}$换成$p_{\\boldsymbol{\\theta }}$，即：\n$$ \\begin{align} p(\\mathcal{D}=1|\\boldsymbol{w}) \u0026 = \\frac{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\\\ p(\\mathcal{D}=0|\\boldsymbol{w}) \u0026 = \\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\end{align} $$\n我们展开期望看看：\n$$ \\begin{align} \\mathbb{E}_{\\boldsymbol{w}\\sim \\mathcal{D}} \\log p(\\mathcal{D}|\\boldsymbol{w}) \u0026 = \\int_{\\boldsymbol{w}} p(\\boldsymbol{w})\\log p(\\mathcal{D}|\\boldsymbol{w}) \\, d\\boldsymbol{w} \\\\ \u0026= \\int_{\\boldsymbol{w}} \\frac{1}{k+1}(p_{d}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w}))\\log p(\\mathcal{D}|\\boldsymbol{w})\\, d \\boldsymbol{w} \\\\ \u0026= \\frac{1}{k+1} \\left( \\int_{\\boldsymbol{w}} p_{d}(\\boldsymbol{w}) \\log p(\\mathcal{D}=1|\\boldsymbol{w}) \\, d \\boldsymbol{w} + \\int _{\\boldsymbol{w}} k p_{n}(\\boldsymbol{w}) \\log p(\\mathcal{D}=0|\\boldsymbol{w}) \\, d\\boldsymbol{w} \\right) \\\\ \u0026= \\frac{1}{k+1}\\bigg(\\mathbb{E}_{\\boldsymbol{w} \\sim p_{d}} \\log p(\\mathcal{D}=1|\\boldsymbol{w})+k\\mathbb{E}_{\\boldsymbol{w} \\sim p_{n}}\\log p(\\mathcal{D}=0|\\boldsymbol{w})\\bigg) \\end{align} $$\n上述期望计算初看肯定有两处疑问：\n第一、为啥要基于$\\boldsymbol{w}$而非$\\boldsymbol{c}$来展开概率计算呢？当然两者都可以，但是我们的目标是为了让模型分布去拟合训练集分布，若是按照$\\boldsymbol{c}$展开，也就是$p_{\\boldsymbol{\\theta }}(\\boldsymbol{c})\\approx p_{d}(\\boldsymbol{c})$，让模型预测输入的 feature 不合理\n第二、不是说好用模型分布代替数据分布吗？为什么$p(\\boldsymbol{w})$还是用的数据分布，我想可能是为了训练方便考虑，若两处都是模型分布，训练势必更难；同时，数据分布是一个既定事实，可以充当额外的信息量给模型，加快收敛\n因为$k$是常数，对优化目标函数无影响，下式省略之，那么，我们的目标函数即为：\n$$ J(\\boldsymbol{\\theta }) =\\mathbb{E}_{\\boldsymbol{w} \\sim p_{d}} \\log p(\\mathcal{D}=1|\\boldsymbol{w})+k\\mathbb{E}_{\\boldsymbol{w} \\sim p_{n}}\\log p(\\mathcal{D}=0|\\boldsymbol{w}) $$\n极限的视角 你肯定好奇 Proxy Problem 是否可以近似原来的建模，目标函数相对于$\\boldsymbol{\\theta }$的微分告诉了我们答案\n$$ J(\\boldsymbol{\\theta }) =\\mathbb{E}_{\\boldsymbol{w} \\sim p_{d}} \\log p(\\mathcal{D}=1|\\boldsymbol{w})+k\\mathbb{E}_{\\boldsymbol{w} \\sim p_{n}}\\log p(\\mathcal{D}=0|\\boldsymbol{w}) $$\n那么，我们求关于参数$\\boldsymbol{\\theta }$的微分：\n$$ \\begin{align} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } J(\\boldsymbol{\\theta }) \u0026 = \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\mathbb{E}_{\\boldsymbol{w} \\sim p_{d}} \\log p(\\mathcal{D}=1|\\boldsymbol{w})+\\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } k\\mathbb{E}_{\\boldsymbol{w} \\sim p_{n}}\\log p(\\mathcal{D}=0|\\boldsymbol{w}) \\\\ \u0026= \\mathbb{E}_{\\boldsymbol{w}\\sim p_{d}} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log \\frac{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} + k\\mathbb{E}_{\\boldsymbol{w}\\sim p_{n}} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log \\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\end{align} $$\n那么接下来我们拆开来求目标函数相对于参数的微分：\n$$ \\begin{align} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \u0026 = \\frac{p_{\\theta }(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\\\ \u0026= \\frac{p_{\\theta }(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})} \\frac{p_{\\boldsymbol{\\theta}}'(\\boldsymbol{w})(p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w}))-p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})p_{\\boldsymbol{\\theta}}'(\\boldsymbol{w})}{(p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w}))^{2} } \\\\ \u0026= \\frac{p_{\\boldsymbol{\\theta }}'(\\boldsymbol{w})kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})(p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w}))} \\\\ \u0026= \\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} {\\color{blue}\\frac{p_{\\boldsymbol{\\theta }}'(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})}} \\\\ \u0026=\\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{w}) \\end{align} $$\n另一部分：\n$$ \\begin{align} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log \\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \u0026 =\\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})}{kp_{n}(\\boldsymbol{w})} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\\\ \u0026= \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})}{kp_{n}(\\boldsymbol{w})} \\frac{0-kp_{n}(\\boldsymbol{w})p_{\\boldsymbol{\\theta}}'(\\boldsymbol{w})}{(p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w}))^{2}} \\\\ \u0026= -\\frac{p_{\\boldsymbol{\\theta}}'(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} {\\color{blue}\\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})}}\\\\ \u0026= - \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{w}) \\end{align} $$\n合起来看看：\n$$ \\begin{align} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } J(\\boldsymbol{\\theta }) \u0026 = \\mathbb{E}_{\\boldsymbol{w} \\sim p_{d}} \\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{w}) -k \\mathbb{E}_{\\boldsymbol{w} \\sim p_{n}}\\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{w}) \\\\ \u0026= \\sum_{\\boldsymbol{w}} p_{d}(\\boldsymbol{w}) \\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log p_{\\boldsymbol{\\theta }}(\\boldsymbol{w}) -k \\sum_{\\boldsymbol{w}}p_{n}(\\boldsymbol{w})\\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{w}) \\\\ \u0026= \\sum_{\\boldsymbol{w}} \\underbrace{ {\\color{blue}\\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})}} }_{ k \\to \\infty, ratio \\to 1 }\\bigg(p_{d}(\\boldsymbol{w}) - p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})\\bigg) \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log p_{\\boldsymbol{\\theta }}(\\boldsymbol{w}) \\\\ \u0026\\approx \\sum_{\\boldsymbol{w}}\\bigg(p_{d}(\\boldsymbol{w}) - p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})\\bigg) \\frac{ \\partial }{ \\partial \\boldsymbol{\\theta } } \\log p_{\\boldsymbol{\\theta }}(\\boldsymbol{w}) \\end{align} $$\n对于第四步的近似，可以举个例子，比如$10000/(1+10000)$，其实因为$1$太小了，可以忽略不计\n这也是为什么这个 Proxy Problem 可以 work 的原因，当采样的噪声样本足够多时，NCE 的梯度就接近于一开始我们想要直接去做最大似然的梯度\n两次近似 尽管通过引入参数可以去估计$Z(\\boldsymbol{\\theta })$很巧妙，但有一个很大的问题，对于每一组词而言，尽管$\\mathcal{V}$是一样的，然而基于的$\\boldsymbol{c}$不一致，那么$p(\\boldsymbol{w}|\\boldsymbol{c})$也是不同的，即每组词你得去保存一个参数$z^{\\boldsymbol{c}}$\n这个时候作者 不是NCE提出论文，而是http://arxiv.org/abs/1206.6426 发现了「神之一手」，直接令$Z(\\boldsymbol{\\theta })\\approx 1$，也就是俗称的 self-normalization，换句话说，压根没有转换为概率，你看到这肯定会露出不屑的表情，我也一样\n自归一化 work 的原因是什么呢？引用原著的说法：\nWe believe this is because the model has so many free parameters that meeting the approximate per-context normalization constraint encouraged by the objective function is easy.\n作者的意思就是参数很多，于是就有了 power，模型自己可以去学习归一化，当然，原著中做了对比，发现效果几乎没影响，才这么做的\n其实我看来还是目标函数选的好，因为当梯度近似为$0$时，$p_{d}$和$p_{\\boldsymbol{\\theta }}$很接近\n这里其实有个容易误解的点，其实这个目标函数只是为了拟合一对词$(\\boldsymbol{c}, \\boldsymbol{w})$：\n$$ J(\\boldsymbol{\\theta }) =\\mathbb{E}_{\\boldsymbol{w} \\sim p_{d}} \\log p(\\mathcal{D}=1|\\boldsymbol{w})+k\\mathbb{E}_{\\boldsymbol{w} \\sim p_{n}}\\log p(\\mathcal{D}=0|\\boldsymbol{w}) $$\n对于每组词都要计算期望，即考虑所有候选可能太过奢侈，所以原著进行了第二次近似，也有一些资料是说抽取$k$个是蒙特卡洛模拟的一种\n$$ J^{\\boldsymbol{c}}(\\boldsymbol{\\theta }) = \\log p(\\mathcal{D}=1|\\boldsymbol{w}_{0}) + \\sum_{i=1}^{k} \\log p(\\mathcal{D}=0|\\boldsymbol{w}_{i}) $$\n那么对于所有的词组该如何建模呢？我们定义一个全局 NCE 进行优化就行了：\n$$ J(\\boldsymbol{\\theta }) = \\sum_{\\boldsymbol{c}} p(\\boldsymbol{c)}J^{\\boldsymbol{c}}(\\boldsymbol{\\theta }) $$\nsigmoid 客串 当然，如果你看现在很多机器学习库的实现，你会发现跟上面的式子可能有点不一样？\n进行变形一下：\n$$ \\begin{align} p(\\mathcal{D}=1|\\boldsymbol{w}) \u0026 = \\frac{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})+kp_{n}(\\boldsymbol{w})} \\\\ \u0026= \\frac{1}{1+ \\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})}} \\\\ \u0026= \\frac{1}{1+ \\exp\\left(\\log \\left( \\frac{kp_{n}(\\boldsymbol{w})}{p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})} \\right)\\right)} \\\\ \u0026= \\frac{1}{1+\\exp(\\log kp_{n}(\\boldsymbol{w})-\\log p_{\\boldsymbol{\\theta }}(\\boldsymbol{w}))} \\\\ \u0026= \\frac{1}{1+\\exp({\\color{red}-}(\\underbrace{ \\log p_{\\boldsymbol{\\theta }}(\\boldsymbol{w})-\\log kp_{n}(\\boldsymbol{w})) }_{ x })} \\end{align} $$\n将里面看成一个参数$x$，那么就看到了 sigmoid 函数：\n$$ p(\\mathcal{D}=1|\\boldsymbol{w}) = \\sigma(\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})-\\log kp_{n}(\\boldsymbol{w})) $$\n同理：\n$$ p(\\mathcal{D}=0|\\boldsymbol{w}) = \\sigma(\\log kp_{n}(\\boldsymbol{w}) - \\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{w})) $$\n损失函数基本就呼之欲出了：\n$$ \\begin{align} L(\\boldsymbol{\\theta }) \u0026 = - \\sum_{\\boldsymbol{c}} p(\\boldsymbol{c})\\left( \\log p(\\mathcal{D}=1|\\boldsymbol{w}_{0})+\\sum_{i=1}^{k} \\log p(\\mathcal{D}=0|\\boldsymbol{w}_{i}) \\right) \\\\ \u0026= -\\sum_{\\boldsymbol{c}} p(\\boldsymbol{c}) \\left( \\log \\sigma(\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{w}_{0})-\\log kp_{n}(\\boldsymbol{w}_{0})) + \\sum_{i=1}^{k} \\log \\sigma(\\log kp_{n}(\\boldsymbol{w}_{i})- \\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{w}_{i})))\\right) \\\\ \u0026= -\\sum_{\\boldsymbol{c}} p(\\boldsymbol{c})\\bigg(\\log\\sigma(s_{\\boldsymbol{\\theta }}(\\boldsymbol{c}, \\boldsymbol{w}_{0} )-\\log kp_{n}(\\boldsymbol{w}_{0}))+\\sum_{i=1}^{k} \\log \\sigma(\\log kp_{n}(\\boldsymbol{w}_{i})- s_{\\boldsymbol{\\theta }}(\\boldsymbol{c}, \\boldsymbol{w}_{i}))\\bigg) \\end{align} $$\n上代码 这里的$p_{n}$选的是 log-uniform，类别越往后出现的概率就越小，所以如果要用，可以将类别按照数目进行排序，将多的放在前面，举个例子，类别 A, B, C, D 分别出现的数目为 10, 20, 100, 15，那么类别排序就应该是 C B D A，类别 0 对应的就是 C。range_max 对应的就是类别总数，这里就是 4\n$$ \\log_{uniform}(class) = \\frac{\\log(class + 2) - \\log (class + 1)}{\\log(range_{max} + 1)} $$\n下面是训练的 loss，eval 的时候没有 noise，找出 labels 对应的 logits，然后算指标就行了，同时，这里考虑数值稳定性，用 pytorch 官方的 softplus 来取代 logsigmoid，详见Numerical Stability\nimport math from einops import repeat import torch.nn.functional as F from torch import arange, randn, tensor, log, multinomial def nce_loss(logits_pos, logits_neg, log_pn_pos, log_pn_neg, k): \"\"\"Compute the noise contrastive estimation loss in https://arxiv.org/abs/1806.03664. Params: - logits_pos: Tensor. Shape: (bs, 1). Logits corresponding to labels. - logits_neg: Tensor. Shape: (bs * k, 1). Logits corresponding to sampled classes. - log_pn_pos: Tensor. Shape: (bs, 1). Log-probability of labels sampled from noise distribution. - log_pn_neg: Tensor. Shape: (bs * k, 1). Log-probability of noise candidates sampled from noise distribution. - k: int. The number of noise candidates per training example. Note: This implementation assumes each context is equally shown which leads to final averge.\"\"\" logk = math.log(k) # For numerical stability, replace logsigmoid by the torch softplus # for it considers the overflow situation. # log(sigmoid(x)) = -softplus(-x) # final return also contains minus(-), thus remove all the minus(-) pos = F.softplus((logk + log_pn_pos) - logits_pos).mean() neg = F.softplus(logits_neg - (logk + log_pn_neg)).mean() return pos + neg def log_uniform(num_sampled, range_max, replacement=True): \"\"\"Sample classes from log-uniform distribution.: p(class) = (log(class + 2) - log(class + 1)) / (log(range_max + 1)). sampled_classes: [0, range_max). Also note that the data distribution should follow the log_uniform. e.g., the classes should be in decreasing order of frequencey when in text generation. Params: - num_sampled: int. The number to be sampled. - range_max: int. The number of total classes. - replacement: bool. If false, sampled candidates are unique. Examples: \u003e\u003e\u003e log_uniform(2, 10) \u003e\u003e\u003e # tensor([7, 2]) \"\"\" classes = arange(0, range_max) probs = log((classes + 2) / (classes + 1)) / math.log(range_max + 1) return probs, multinomial(probs, num_sampled, replacement=replacement) def main(): bs, k = 2, 4 num_classes = 8 logits = randn(bs, num_classes) labels = tensor([2, 4]) probs, noise_classes = log_uniform(bs * k, num_classes) logits_pos = logits.take_along_dim(labels[:, None], dim=1) log_pn_pos = probs[labels] log_pn_neg = probs[noise_classes] logits_k = repeat(logits, '(b 1) h -\u003e (b k) h', k=k) logits_neg = logits_k.take_along_dim(noise_classes.reshape(bs * k, -1), dim=1) loss = nce_loss(logits_pos, logits_neg, log_pn_pos, log_pn_neg, k) print('nce loss: %f' %loss) if __name__ == '__main__': main() 至于实验，先鸽一下，留在后面与 info-nce，negative-sampling 等做对比\nReferences http://proceedings.mlr.press/v9/gutmann10a.html http://arxiv.org/abs/1206.6426 https://leimao.github.io/article/Noise-Contrastive-Estimation/ https://www.tensorflow.org/api_docs/python/tf/random/log_uniform_candidate_sampler ","wordCount":"3934","inLanguage":"en","datePublished":"2023-05-29T14:40:00+08:00","dateModified":"2023-05-29T14:40:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://yunpengtai.top/posts/noise-contrastive-estimation/"},"publisher":{"@type":"Organization","name":"Tai's Blog","logo":{"@type":"ImageObject","url":"https://yunpengtai.top/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://yunpengtai.top accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://yunpengtai.top/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://yunpengtai.top/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://yunpengtai.top/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://yunpengtai.top/friends/ title=Friends><span>Friends</span></a></li><li><a href=https://yunpengtai.top/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://yunpengtai.top>Home</a>&nbsp;»&nbsp;<a href=https://yunpengtai.top/posts/>Posts</a></div><h1 class=post-title>Noise Contrastive Estimation</h1><div class=post-meta><span title='2023-05-29 14:40:00 +0800 CST'>May 29, 2023</span>&nbsp;·&nbsp;3934 words</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e9%9a%be%e4%bb%a5%e6%89%bf%e5%8f%97%e4%b9%8b%e9%87%8d aria-label=难以承受之重>难以承受之重</a></li><li><a href=#%e4%b8%a2%e7%bb%99%e5%8f%82%e6%95%b0 aria-label=丢给参数>丢给参数</a></li><li><a href=#%e6%9b%b2%e5%be%84%e9%80%9a%e5%b9%bd aria-label=曲径通幽>曲径通幽</a></li><li><a href=#%e6%9e%81%e9%99%90%e7%9a%84%e8%a7%86%e8%a7%92 aria-label=极限的视角>极限的视角</a></li><li><a href=#%e4%b8%a4%e6%ac%a1%e8%bf%91%e4%bc%bc aria-label=两次近似>两次近似</a></li><li><a href=#sigmoid-%e5%ae%a2%e4%b8%b2 aria-label="sigmoid 客串">sigmoid 客串</a></li><li><a href=#%e4%b8%8a%e4%bb%a3%e7%a0%81 aria-label=上代码>上代码</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h3 id=难以承受之重>难以承受之重<a hidden class=anchor aria-hidden=true href=#难以承受之重>#</a></h3><p>文本生成是 NLP 任务中比较典型的一类，记参数为<code>$\boldsymbol{\theta }$</code>，给定的 context 为<code>$\boldsymbol{c}$</code>，需要生成的文本记为<code>$\boldsymbol{w}$</code>，我们通常通过最大似然法来使得模型预测的分布<code>$p_{\boldsymbol{\theta}}$</code>尽可能接近训练集分布<code>$p_{d}(\boldsymbol{w})$</code></p><p><code>$$ \boldsymbol{\theta ^{\ast}} = \mathop{\arg \max}_{\boldsymbol{\theta }} \ \mathbb{E}_{\boldsymbol{c}, \boldsymbol{w} \sim p_{d}} \log p_{\boldsymbol{\theta }}(\boldsymbol{w}|\boldsymbol{c};\boldsymbol{\theta }) $$</code></p><p>而在建模时，我们通常会在模型加入 Softmax 来将 score 转换为概率，使得对词表<code>$\mathcal{V}$</code>所有词预测概率相加为 1：</p><p><code>$$ p(\boldsymbol{w}|\boldsymbol{c};\boldsymbol{\theta}) = \frac{u_{\boldsymbol{\theta }}(\boldsymbol{w}, \boldsymbol{c})}{\underbrace{ {\color{blue}\sum_{\boldsymbol{w}' \in \mathcal{V}} u_{\boldsymbol{\theta}}(\boldsymbol{w}', \boldsymbol{c})} }_{ \text{Partition Function} }}, u_{\boldsymbol{\theta }}(\boldsymbol{w}, \boldsymbol{c}) = \exp(s_{\theta }(\boldsymbol{w}, \boldsymbol{c})) $$</code></p><p>分母是用来归一化的，也被称作配分函数（Partition Function），为了使得表达更简便，我们将上述公式进一步压缩，将分母统称为<code>$Z(\boldsymbol{\theta })$</code></p><p>若是普通的多分类问题，参数量不大，求<code>$Z(\boldsymbol{\theta })$</code>感觉不到压力，可若是文本生成任务，例如，「文本____是自然语言处理的任务」，此时你得去整个词表<code>$\mathcal{V}$</code>中来挑选词来填空，去计算<code>$Z(\boldsymbol{\theta })$</code>就是十分昂贵的事情了</p><h3 id=丢给参数>丢给参数<a hidden class=anchor aria-hidden=true href=#丢给参数>#</a></h3><p>那么，有人就说了，不行那就直接交给参数处理吧，让模型自己去学，看看模型自己能不能学出归一化：</p><p><code>$$ p(\boldsymbol{w}|\boldsymbol{c};\boldsymbol{\theta}) = \frac{u_{\boldsymbol{\theta }}(\boldsymbol{w}, \boldsymbol{c})}{Z(\boldsymbol{\theta })} = u_{\boldsymbol{\theta }}(\boldsymbol{w}, \boldsymbol{c})\exp(z^{\boldsymbol{c}}), \, z^{\boldsymbol{c}} = -\log Z(\boldsymbol{\theta }) $$</code></p><p>接着应用最大似然：</p><p><code>$$ \begin{align} \boldsymbol{\theta ^{\ast}} & = \mathop{\arg \max}_{\boldsymbol{\theta }} \ \mathbb{E}_{\boldsymbol{c}, \boldsymbol{w} \sim p_{d}} \log p_{\boldsymbol{\theta }}(\boldsymbol{w}|\boldsymbol{c};\boldsymbol{\theta }) \\ &= \mathop{\arg \max}_{\boldsymbol{\theta }, \boldsymbol{z}} \ \mathbb{E}_{\boldsymbol{c}, \boldsymbol{w} \sim p_{d}} \log u_{\boldsymbol{\theta }}(\boldsymbol{w},\boldsymbol{c})\exp(z^{\boldsymbol{c}}) \end{align} $$</code>
这样的结果就是，为了最大化期望，会使得<code>$Z(\boldsymbol{\theta }) \to 0$</code>，效果会很不好</p><h3 id=曲径通幽>曲径通幽<a hidden class=anchor aria-hidden=true href=#曲径通幽>#</a></h3><p>那么 Noise Contrastive Estimation（NCE）说，既然这样，我们能不能引入参数的同时也可以出色地预估<code>$Z(\boldsymbol{\theta })$</code>呢？于是乎，它将问题从原本的多分类问题转换为二分类问题
<span class=sidenote-number><small class=sidenote>Proxy Problem，指用新的任务或指标来完成对原本任务的建模</small></span>
，具体如下：</p><p>首先，存在一个噪声分布<code>$p_{n}$</code>和经验概率分布<code>$p_{d}$</code>，这里<code>$p_{d}$</code>是从训练集提取的，就类似 word2vec 的训练，将句子切分成词
<span class=sidenote-number><small class=sidenote>现代 NLP 基本都是 token，这里是为了表达简便</small></span>
，统计某几个词一起出现的概率，那么<code>$p(\boldsymbol{w}|\boldsymbol{c})$</code>就是对于<code>$\boldsymbol{c}$</code>而言，下一个词是<code>$\boldsymbol{w}$</code>的概率。举个例子，对于 love 而言：<code>$p_{d}=\{ \text{games}: 0.9, \text{study}: 0.1 \}$</code></p><p>每次从<code>$p_{d}$</code>中抽出一个候选词，从<code>$p_{n}$</code>中抽取<code>$k$</code>个候选词。模型的任务即为区分候选词是从训练集还是噪声中采样而来的，通过这个代理任务使得<code>$p_{\boldsymbol{\theta}}(\boldsymbol{c})$</code>去逼近于<code>$p_{d}(\boldsymbol{c})$</code></p><p>我们规定，当<code>$\mathcal{D}=1$</code>时代表从训练集采样，而<code>$\mathcal{D}=0$</code>则代表从噪声中采样，那么：</p><p><code>$$ \begin{align} p(\boldsymbol{w}|\mathcal{D} =1, \boldsymbol{c}) & = p_{d}(\boldsymbol{w})\\ p(\boldsymbol{w}|\mathcal{D} = 0, {\boldsymbol{c}}) & = p_{n}({\boldsymbol{w}}) \end{align} $$</code></p><p>那么总概率即为：</p><p><code>$$ p_{joint}(\boldsymbol{w}) =\frac{1}{k+1}p_{d}(\boldsymbol{w}) + \frac{k}{k+1} p_{n}(\boldsymbol{w}) $$</code></p><p>接下来求一下来自哪个采样的条件概率：</p><p><code>$$ \begin{align} p(\mathcal{D}=1|\boldsymbol{w}) & = \frac{p(\mathcal{D}=1,\boldsymbol{w})}{p_{joint}(\boldsymbol{w})} = \frac{p(\boldsymbol{w}|\mathcal{D}=1)p(\mathcal{D}=1)}{p_{joint}(\boldsymbol{w})} \\ & = \frac{p_{d}(\boldsymbol{w})}{p_{d}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \end{align} $$</code></p><p>同理：</p><p><code>$$ p(\mathcal{D}=0|\boldsymbol{w}) = \frac{kp_{n}(\boldsymbol{w})}{p_{d}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} $$</code></p><p><code>$\mathcal{D}$</code>代表训练集和噪声集的集合，那么 NCE 的目标即为最大化期望：</p><p><code>$$ \boldsymbol{\theta }^{\ast} = \mathop{\arg \max}_{\boldsymbol{\theta }}\ \mathbb{E}_{\boldsymbol{w} \sim \mathcal{D}} \log p(\mathcal{D}|\boldsymbol{w}) $$</code></p><p>又因为我们想要让模型分布<code>$p_{\boldsymbol{\theta }}$</code>尽可能接近训练集分布<code>$p_{d}$</code>，于是我们在求条件概率时，将<code>$p_{d}$</code>换成<code>$p_{\boldsymbol{\theta }}$</code>，即：</p><p><code>$$ \begin{align} p(\mathcal{D}=1|\boldsymbol{w}) & = \frac{p_{\boldsymbol{\theta }}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \\ p(\mathcal{D}=0|\boldsymbol{w}) & = \frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \end{align} $$</code></p><p>我们展开期望看看：</p><p><code>$$ \begin{align} \mathbb{E}_{\boldsymbol{w}\sim \mathcal{D}} \log p(\mathcal{D}|\boldsymbol{w}) & = \int_{\boldsymbol{w}} p(\boldsymbol{w})\log p(\mathcal{D}|\boldsymbol{w}) \, d\boldsymbol{w} \\ &= \int_{\boldsymbol{w}} \frac{1}{k+1}(p_{d}(\boldsymbol{w})+kp_{n}(\boldsymbol{w}))\log p(\mathcal{D}|\boldsymbol{w})\, d \boldsymbol{w} \\ &= \frac{1}{k+1} \left( \int_{\boldsymbol{w}} p_{d}(\boldsymbol{w}) \log p(\mathcal{D}=1|\boldsymbol{w}) \, d \boldsymbol{w} + \int _{\boldsymbol{w}} k p_{n}(\boldsymbol{w}) \log p(\mathcal{D}=0|\boldsymbol{w}) \, d\boldsymbol{w} \right) \\ &= \frac{1}{k+1}\bigg(\mathbb{E}_{\boldsymbol{w} \sim p_{d}} \log p(\mathcal{D}=1|\boldsymbol{w})+k\mathbb{E}_{\boldsymbol{w} \sim p_{n}}\log p(\mathcal{D}=0|\boldsymbol{w})\bigg) \end{align} $$</code></p><p>上述期望计算初看肯定有两处疑问：</p><p>第一、为啥要基于<code>$\boldsymbol{w}$</code>而非<code>$\boldsymbol{c}$</code>来展开概率计算呢？当然两者都可以，但是我们的目标是为了让模型分布去拟合训练集分布，若是按照<code>$\boldsymbol{c}$</code>展开，也就是<code>$p_{\boldsymbol{\theta }}(\boldsymbol{c})\approx p_{d}(\boldsymbol{c})$</code>，让模型预测输入的 feature 不合理</p><p>第二、不是说好用模型分布代替数据分布吗？为什么<code>$p(\boldsymbol{w})$</code>还是用的数据分布，我想可能是为了训练方便考虑，若两处都是模型分布，训练势必更难；同时，数据分布是一个既定事实，可以充当额外的信息量给模型，加快收敛</p><p>因为<code>$k$</code>是常数，对优化目标函数无影响，下式省略之，那么，我们的目标函数即为：</p><p><code>$$ J(\boldsymbol{\theta }) =\mathbb{E}_{\boldsymbol{w} \sim p_{d}} \log p(\mathcal{D}=1|\boldsymbol{w})+k\mathbb{E}_{\boldsymbol{w} \sim p_{n}}\log p(\mathcal{D}=0|\boldsymbol{w}) $$</code></p><h3 id=极限的视角>极限的视角<a hidden class=anchor aria-hidden=true href=#极限的视角>#</a></h3><p>你肯定好奇 Proxy Problem 是否可以近似原来的建模，目标函数相对于<code>$\boldsymbol{\theta }$</code>的微分告诉了我们答案</p><p><code>$$ J(\boldsymbol{\theta }) =\mathbb{E}_{\boldsymbol{w} \sim p_{d}} \log p(\mathcal{D}=1|\boldsymbol{w})+k\mathbb{E}_{\boldsymbol{w} \sim p_{n}}\log p(\mathcal{D}=0|\boldsymbol{w}) $$</code></p><p>那么，我们求关于参数<code>$\boldsymbol{\theta }$</code>的微分：</p><p><code>$$ \begin{align} \frac{ \partial }{ \partial \boldsymbol{\theta } } J(\boldsymbol{\theta }) & = \frac{ \partial }{ \partial \boldsymbol{\theta } } \mathbb{E}_{\boldsymbol{w} \sim p_{d}} \log p(\mathcal{D}=1|\boldsymbol{w})+\frac{ \partial }{ \partial \boldsymbol{\theta } } k\mathbb{E}_{\boldsymbol{w} \sim p_{n}}\log p(\mathcal{D}=0|\boldsymbol{w}) \\ &= \mathbb{E}_{\boldsymbol{w}\sim p_{d}} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log \frac{p_{\boldsymbol{\theta }}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} + k\mathbb{E}_{\boldsymbol{w}\sim p_{n}} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log \frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \end{align} $$</code></p><p>那么接下来我们拆开来求目标函数相对于参数的微分：</p><p><code>$$ \begin{align} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log \frac{p_{\boldsymbol{\theta}}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} & = \frac{p_{\theta }(\boldsymbol{w})+kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})} \frac{ \partial }{ \partial \boldsymbol{\theta } } \frac{p_{\boldsymbol{\theta}}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \\ &= \frac{p_{\theta }(\boldsymbol{w})+kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})} \frac{p_{\boldsymbol{\theta}}'(\boldsymbol{w})(p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w}))-p_{\boldsymbol{\theta}}(\boldsymbol{w})p_{\boldsymbol{\theta}}'(\boldsymbol{w})}{(p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w}))^{2} } \\ &= \frac{p_{\boldsymbol{\theta }}'(\boldsymbol{w})kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})(p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w}))} \\ &= \frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} {\color{blue}\frac{p_{\boldsymbol{\theta }}'(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})}} \\ &=\frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log p_{\boldsymbol{\theta}}(\boldsymbol{w}) \end{align} $$</code></p><p>另一部分：</p><p><code>$$ \begin{align} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log \frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} & =\frac{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})}{kp_{n}(\boldsymbol{w})} \frac{ \partial }{ \partial \boldsymbol{\theta } } \frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \\ &= \frac{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})}{kp_{n}(\boldsymbol{w})} \frac{0-kp_{n}(\boldsymbol{w})p_{\boldsymbol{\theta}}'(\boldsymbol{w})}{(p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w}))^{2}} \\ &= -\frac{p_{\boldsymbol{\theta}}'(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} {\color{blue}\frac{p_{\boldsymbol{\theta}}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})}}\\ &= - \frac{p_{\boldsymbol{\theta}}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log p_{\boldsymbol{\theta}}(\boldsymbol{w}) \end{align} $$</code></p><p>合起来看看：</p><p><code>$$ \begin{align} \frac{ \partial }{ \partial \boldsymbol{\theta } } J(\boldsymbol{\theta }) & = \mathbb{E}_{\boldsymbol{w} \sim p_{d}} \frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log p_{\boldsymbol{\theta}}(\boldsymbol{w}) -k \mathbb{E}_{\boldsymbol{w} \sim p_{n}}\frac{p_{\boldsymbol{\theta}}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log p_{\boldsymbol{\theta}}(\boldsymbol{w}) \\ &= \sum_{\boldsymbol{w}} p_{d}(\boldsymbol{w}) \frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log p_{\boldsymbol{\theta }}(\boldsymbol{w}) -k \sum_{\boldsymbol{w}}p_{n}(\boldsymbol{w})\frac{p_{\boldsymbol{\theta}}(\boldsymbol{w})}{p_{\boldsymbol{\theta}}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \frac{ \partial }{ \partial \boldsymbol{\theta } } \log p_{\boldsymbol{\theta}}(\boldsymbol{w}) \\ &= \sum_{\boldsymbol{w}} \underbrace{ {\color{blue}\frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})}} }_{ k \to \infty, ratio \to 1 }\bigg(p_{d}(\boldsymbol{w}) - p_{\boldsymbol{\theta }}(\boldsymbol{w})\bigg) \frac{ \partial }{ \partial \boldsymbol{\theta } } \log p_{\boldsymbol{\theta }}(\boldsymbol{w}) \\ &\approx \sum_{\boldsymbol{w}}\bigg(p_{d}(\boldsymbol{w}) - p_{\boldsymbol{\theta }}(\boldsymbol{w})\bigg) \frac{ \partial }{ \partial \boldsymbol{\theta } } \log p_{\boldsymbol{\theta }}(\boldsymbol{w}) \end{align} $$</code></p><p>对于第四步的近似，可以举个例子，比如<code>$10000/(1+10000)$</code>，其实因为<code>$1$</code>太小了，可以忽略不计</p><p>这也是为什么这个 Proxy Problem 可以 work 的原因，当采样的噪声样本足够多时，NCE 的梯度就接近于一开始我们想要直接去做最大似然的梯度</p><h3 id=两次近似>两次近似<a hidden class=anchor aria-hidden=true href=#两次近似>#</a></h3><p>尽管通过引入参数可以去估计<code>$Z(\boldsymbol{\theta })$</code>很巧妙，但有一个很大的问题，对于每一组词而言，尽管<code>$\mathcal{V}$</code>是一样的，然而基于的<code>$\boldsymbol{c}$</code>不一致，那么<code>$p(\boldsymbol{w}|\boldsymbol{c})$</code>也是不同的，即每组词你得去保存一个参数<code>$z^{\boldsymbol{c}}$</code></p><p>这个时候作者
<span class=sidenote-number><small class=sidenote>不是NCE提出论文，而是http://arxiv.org/abs/1206.6426</small></span>
发现了「神之一手」，直接令<code>$Z(\boldsymbol{\theta })\approx 1$</code>，也就是俗称的 self-normalization，换句话说，压根没有转换为概率，你看到这肯定会露出不屑的表情，我也一样</p><p>自归一化 work 的原因是什么呢？引用原著的说法：</p><p>We believe this is because the model has so many free parameters that meeting the approximate per-context normalization constraint encouraged by the objective function is easy.</p><p>作者的意思就是参数很多，于是就有了 power，模型自己可以去学习归一化，当然，原著中做了对比，发现效果几乎没影响，才这么做的</p><p>其实我看来还是目标函数选的好，因为当梯度近似为<code>$0$</code>时，<code>$p_{d}$</code>和<code>$p_{\boldsymbol{\theta }}$</code>很接近</p><p>这里其实有个容易误解的点，其实这个目标函数只是为了拟合一对词<code>$(\boldsymbol{c}, \boldsymbol{w})$</code>：</p><p><code>$$ J(\boldsymbol{\theta }) =\mathbb{E}_{\boldsymbol{w} \sim p_{d}} \log p(\mathcal{D}=1|\boldsymbol{w})+k\mathbb{E}_{\boldsymbol{w} \sim p_{n}}\log p(\mathcal{D}=0|\boldsymbol{w}) $$</code></p><p>对于每组词都要计算期望，即考虑所有候选可能太过奢侈，所以原著进行了第二次近似，也有一些资料是说抽取<code>$k$</code>个是蒙特卡洛模拟的一种</p><p><code>$$ J^{\boldsymbol{c}}(\boldsymbol{\theta }) = \log p(\mathcal{D}=1|\boldsymbol{w}_{0}) + \sum_{i=1}^{k} \log p(\mathcal{D}=0|\boldsymbol{w}_{i}) $$</code></p><p>那么对于所有的词组该如何建模呢？我们定义一个全局 NCE 进行优化就行了：</p><p><code>$$ J(\boldsymbol{\theta }) = \sum_{\boldsymbol{c}} p(\boldsymbol{c)}J^{\boldsymbol{c}}(\boldsymbol{\theta }) $$</code></p><h3 id=sigmoid-客串>sigmoid 客串<a hidden class=anchor aria-hidden=true href=#sigmoid-客串>#</a></h3><p>当然，如果你看现在很多机器学习库的实现，你会发现跟上面的式子可能有点不一样？</p><p>进行变形一下：</p><p><code>$$ \begin{align} p(\mathcal{D}=1|\boldsymbol{w}) & = \frac{p_{\boldsymbol{\theta }}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})+kp_{n}(\boldsymbol{w})} \\ &= \frac{1}{1+ \frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})}} \\ &= \frac{1}{1+ \exp\left(\log \left( \frac{kp_{n}(\boldsymbol{w})}{p_{\boldsymbol{\theta }}(\boldsymbol{w})} \right)\right)} \\ &= \frac{1}{1+\exp(\log kp_{n}(\boldsymbol{w})-\log p_{\boldsymbol{\theta }}(\boldsymbol{w}))} \\ &= \frac{1}{1+\exp({\color{red}-}(\underbrace{ \log p_{\boldsymbol{\theta }}(\boldsymbol{w})-\log kp_{n}(\boldsymbol{w})) }_{ x })} \end{align} $$</code></p><p>将里面看成一个参数<code>$x$</code>，那么就看到了 sigmoid 函数：</p><p><code>$$ p(\mathcal{D}=1|\boldsymbol{w}) = \sigma(\log p_{\boldsymbol{\theta}}(\boldsymbol{w})-\log kp_{n}(\boldsymbol{w})) $$</code></p><p>同理：</p><p><code>$$ p(\mathcal{D}=0|\boldsymbol{w}) = \sigma(\log kp_{n}(\boldsymbol{w}) - \log p_{\boldsymbol{\theta}}(\boldsymbol{w})) $$</code></p><p>损失函数基本就呼之欲出了：</p><p><code>$$ \begin{align} L(\boldsymbol{\theta }) & = - \sum_{\boldsymbol{c}} p(\boldsymbol{c})\left( \log p(\mathcal{D}=1|\boldsymbol{w}_{0})+\sum_{i=1}^{k} \log p(\mathcal{D}=0|\boldsymbol{w}_{i}) \right) \\ &= -\sum_{\boldsymbol{c}} p(\boldsymbol{c}) \left( \log \sigma(\log p_{\boldsymbol{\theta}}(\boldsymbol{w}_{0})-\log kp_{n}(\boldsymbol{w}_{0})) + \sum_{i=1}^{k} \log \sigma(\log kp_{n}(\boldsymbol{w}_{i})- \log p_{\boldsymbol{\theta}}(\boldsymbol{w}_{i})))\right) \\ &= -\sum_{\boldsymbol{c}} p(\boldsymbol{c})\bigg(\log\sigma(s_{\boldsymbol{\theta }}(\boldsymbol{c}, \boldsymbol{w}_{0} )-\log kp_{n}(\boldsymbol{w}_{0}))+\sum_{i=1}^{k} \log \sigma(\log kp_{n}(\boldsymbol{w}_{i})- s_{\boldsymbol{\theta }}(\boldsymbol{c}, \boldsymbol{w}_{i}))\bigg) \end{align} $$</code></p><h3 id=上代码>上代码<a hidden class=anchor aria-hidden=true href=#上代码>#</a></h3><p>这里的<code>$p_{n}$</code>选的是 log-uniform，类别越往后出现的概率就越小，所以如果要用，可以将类别按照数目进行排序，将多的放在前面，举个例子，类别 A, B, C, D 分别出现的数目为 10, 20, 100, 15，那么类别排序就应该是 C B D A，类别 0 对应的就是 C。range_max 对应的就是类别总数，这里就是 4</p><p><code>$$ \log_{uniform}(class) = \frac{\log(class + 2) - \log (class + 1)}{\log(range_{max} + 1)} $$</code></p><p>下面是训练的 loss，eval 的时候没有 noise，找出 labels 对应的 logits，然后算指标就行了，同时，这里考虑数值稳定性，用 pytorch 官方的 softplus 来取代 logsigmoid，详见<a href=https://yunpengtai.top/posts/numerical-stability/>Numerical Stability</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>math</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>einops</span> <span class=kn>import</span> <span class=n>repeat</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch</span> <span class=kn>import</span> <span class=n>arange</span><span class=p>,</span> <span class=n>randn</span><span class=p>,</span> <span class=n>tensor</span><span class=p>,</span> <span class=n>log</span><span class=p>,</span> <span class=n>multinomial</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>nce_loss</span><span class=p>(</span><span class=n>logits_pos</span><span class=p>,</span> <span class=n>logits_neg</span><span class=p>,</span> <span class=n>log_pn_pos</span><span class=p>,</span> <span class=n>log_pn_neg</span><span class=p>,</span> <span class=n>k</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Compute the noise contrastive estimation loss in
</span></span></span><span class=line><span class=cl><span class=s2>    https://arxiv.org/abs/1806.03664.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Params:
</span></span></span><span class=line><span class=cl><span class=s2>        - logits_pos: Tensor. Shape: (bs, 1). Logits corresponding to labels.
</span></span></span><span class=line><span class=cl><span class=s2>        - logits_neg: Tensor. Shape: (bs * k, 1). Logits corresponding to sampled classes.
</span></span></span><span class=line><span class=cl><span class=s2>        - log_pn_pos: Tensor. Shape: (bs, 1). Log-probability of labels sampled from noise distribution.
</span></span></span><span class=line><span class=cl><span class=s2>        - log_pn_neg: Tensor. Shape: (bs * k, 1). Log-probability of noise candidates sampled from noise distribution.
</span></span></span><span class=line><span class=cl><span class=s2>        - k: int. The number of noise candidates per training example.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Note:
</span></span></span><span class=line><span class=cl><span class=s2>        This implementation assumes each context is equally shown which leads to final averge.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logk</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># For numerical stability, replace logsigmoid by the torch softplus</span>
</span></span><span class=line><span class=cl>    <span class=c1># for it considers the overflow situation.</span>
</span></span><span class=line><span class=cl>    <span class=c1># log(sigmoid(x)) = -softplus(-x)</span>
</span></span><span class=line><span class=cl>    <span class=c1># final return also contains minus(-), thus remove all the minus(-)</span>
</span></span><span class=line><span class=cl>    <span class=n>pos</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softplus</span><span class=p>((</span><span class=n>logk</span> <span class=o>+</span> <span class=n>log_pn_pos</span><span class=p>)</span> <span class=o>-</span> <span class=n>logits_pos</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>neg</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softplus</span><span class=p>(</span><span class=n>logits_neg</span> <span class=o>-</span> <span class=p>(</span><span class=n>logk</span> <span class=o>+</span> <span class=n>log_pn_neg</span><span class=p>))</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>pos</span> <span class=o>+</span> <span class=n>neg</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>log_uniform</span><span class=p>(</span><span class=n>num_sampled</span><span class=p>,</span> <span class=n>range_max</span><span class=p>,</span> <span class=n>replacement</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Sample classes from log-uniform distribution.:
</span></span></span><span class=line><span class=cl><span class=s2>    p(class) = (log(class + 2) - log(class + 1)) / (log(range_max + 1)).
</span></span></span><span class=line><span class=cl><span class=s2>    sampled_classes: [0, range_max).
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Also note that the data distribution should follow the log_uniform.
</span></span></span><span class=line><span class=cl><span class=s2>    e.g., the classes should be in decreasing order of frequencey when in text generation.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Params:
</span></span></span><span class=line><span class=cl><span class=s2>        - num_sampled: int. The number to be sampled.
</span></span></span><span class=line><span class=cl><span class=s2>        - range_max: int. The number of total classes.
</span></span></span><span class=line><span class=cl><span class=s2>        - replacement: bool. If false, sampled candidates are unique.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Examples:
</span></span></span><span class=line><span class=cl><span class=s2>        &gt;&gt;&gt; log_uniform(2, 10)
</span></span></span><span class=line><span class=cl><span class=s2>        &gt;&gt;&gt; # tensor([7, 2])
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>classes</span> <span class=o>=</span> <span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>range_max</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>probs</span> <span class=o>=</span> <span class=n>log</span><span class=p>((</span><span class=n>classes</span> <span class=o>+</span> <span class=mi>2</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>classes</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span> <span class=o>/</span> <span class=n>math</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>range_max</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>probs</span><span class=p>,</span> <span class=n>multinomial</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>num_sampled</span><span class=p>,</span> <span class=n>replacement</span><span class=o>=</span><span class=n>replacement</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>bs</span><span class=p>,</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl>    <span class=n>num_classes</span> <span class=o>=</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logits</span> <span class=o>=</span> <span class=n>randn</span><span class=p>(</span><span class=n>bs</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>tensor</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>probs</span><span class=p>,</span> <span class=n>noise_classes</span> <span class=o>=</span> <span class=n>log_uniform</span><span class=p>(</span><span class=n>bs</span> <span class=o>*</span> <span class=n>k</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logits_pos</span> <span class=o>=</span> <span class=n>logits</span><span class=o>.</span><span class=n>take_along_dim</span><span class=p>(</span><span class=n>labels</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>log_pn_pos</span> <span class=o>=</span> <span class=n>probs</span><span class=p>[</span><span class=n>labels</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>log_pn_neg</span> <span class=o>=</span> <span class=n>probs</span><span class=p>[</span><span class=n>noise_classes</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>logits_k</span> <span class=o>=</span> <span class=n>repeat</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=s1>&#39;(b 1) h -&gt; (b k) h&#39;</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logits_neg</span> <span class=o>=</span> <span class=n>logits_k</span><span class=o>.</span><span class=n>take_along_dim</span><span class=p>(</span><span class=n>noise_classes</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>bs</span> <span class=o>*</span> <span class=n>k</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>nce_loss</span><span class=p>(</span><span class=n>logits_pos</span><span class=p>,</span> <span class=n>logits_neg</span><span class=p>,</span> <span class=n>log_pn_pos</span><span class=p>,</span> <span class=n>log_pn_neg</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;nce loss: </span><span class=si>%f</span><span class=s1>&#39;</span> <span class=o>%</span><span class=n>loss</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>main</span><span class=p>()</span>
</span></span></code></pre></div><p>至于实验，先鸽一下，留在后面与 info-nce，negative-sampling 等做对比</p><h3 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h3><ol><li><a href=http://proceedings.mlr.press/v9/gutmann10a.html>http://proceedings.mlr.press/v9/gutmann10a.html</a></li><li><a href=http://arxiv.org/abs/1206.6426>http://arxiv.org/abs/1206.6426</a></li><li><a href=https://leimao.github.io/article/Noise-Contrastive-Estimation/>https://leimao.github.io/article/Noise-Contrastive-Estimation/</a></li><li><a href=https://www.tensorflow.org/api_docs/python/tf/random/log_uniform_candidate_sampler>https://www.tensorflow.org/api_docs/python/tf/random/log_uniform_candidate_sampler</a></li></ol></div><blockquote class=quote-copyright>Author: Yunpengtai<p>Link: https://yunpengtai.top/posts/noise-contrastive-estimation/<p>License: CC BY-NC-SA 4.0. You must provide a link to the source.</blockquote><footer class=post-footer><ul class=post-tags><li><a href=https://yunpengtai.top/tags/proxy-problem/>proxy problem</a></li><li><a href=https://yunpengtai.top/tags/contrastive-learning/>contrastive learning</a></li></ul><nav class=paginav><a class=prev href=https://yunpengtai.top/posts/bias-variance-decomposition/><span class=title>« Prev</span><br><span>Bias Variance Decomposition</span></a>
<a class=next href=https://yunpengtai.top/posts/fast-greedy-map-inference-for-dpp/><span class=title>Next »</span><br><span>Fast Greedy MAP Inference for DPP</span></a></nav></footer><link rel=stylesheet href=https://unpkg.com/katex@0.16.7/dist/katex.min.css><script src=https://unpkg.com/katex@0.16.7/dist/katex.min.js></script>
<link href=https://cdnjs.cloudflare.com/ajax/libs/artalk/2.8.6/Artalk.css rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/artalk/2.8.6/Artalk.js></script>
<script src=https://unpkg.com/@artalk/plugin-katex@latest/dist/artalk-plugin-katex.js></script><div id=Comments></div><script>Artalk.init({el:"#Comments",pageKey:"",pageTitle:"Noise Contrastive Estimation",server:"https://comment.yunpengtai.top",site:"Tai's Blog"})</script></article></main><footer class=footer><span>&copy; 2024 <a href=https://yunpengtai.top>Tai's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/sherlcok314159/MyPaperMod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>(function(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}})()</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("//cdn.bootcss.com/pangu/4.0.7/pangu.min.js",function(){pangu.spacingPage()})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>