<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Going Deeper into Back-propagation | Tai's Blog</title><meta name=keywords content="Gradients,Optimization"><meta name=description content="1. Gradient descent optimization Gradient-based methods make use of the gradient information to adjust the parameters. Among them, gradient descent can be the simplest. Gradient descent makes the parameters to walk a small step in the direction of the negative gradient.
$$ \mathbf{w}^{\tau + 1} = \mathbf{w}^{\tau} - \eta \nabla_{\mathbf{w}^{\tau}} E \tag{1.1} $$
where \(\eta, \tau, E\) label learning rate (\(\eta > 0\)), the iteration step and the loss function."><meta name=author content><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="eAKh7zszsOtNde1wyq_sUo95ZPH4zTTJhR-_ol4VWDs"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yunpengtai.top/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yunpengtai.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yunpengtai.top/favicon-32x32.png><link rel=apple-touch-icon href=https://yunpengtai.top/apple-touch-icon.png><link rel=mask-icon href=https://yunpengtai.top/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script>MathJax={loader:{load:["[tex]/boldsymbol"]},tex:{tags:"all",inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,packages:{"[+]":["boldsymbol"]}}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js integrity="sha256-kbAFUDxdHwlYv01zraGjvjNZayxKtdoiJ38bDTFJtaQ=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y3CX2RWEDY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Y3CX2RWEDY",{anonymize_ip:!1})}</script><meta property="og:title" content="Going Deeper into Back-propagation"><meta property="og:description" content="1. Gradient descent optimization Gradient-based methods make use of the gradient information to adjust the parameters. Among them, gradient descent can be the simplest. Gradient descent makes the parameters to walk a small step in the direction of the negative gradient.
$$ \mathbf{w}^{\tau + 1} = \mathbf{w}^{\tau} - \eta \nabla_{\mathbf{w}^{\tau}} E \tag{1.1} $$
where \(\eta, \tau, E\) label learning rate (\(\eta > 0\)), the iteration step and the loss function."><meta property="og:type" content="article"><meta property="og:url" content="https://yunpengtai.top/posts/back-propagation/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-09-07T11:10:00+08:00"><meta property="article:modified_time" content="2022-09-07T11:10:00+08:00"><meta property="og:site_name" content="Tai's Blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://yunpengtai.top/posts/"},{"@type":"ListItem","position":3,"name":"Going Deeper into Back-propagation","item":"https://yunpengtai.top/posts/back-propagation/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Going Deeper into Back-propagation","name":"Going Deeper into Back-propagation","description":"1. Gradient descent optimization Gradient-based methods make use of the gradient information to adjust the parameters. Among them, gradient descent can be the simplest. Gradient descent makes the parameters to walk a small step in the direction of the negative gradient.\n$$ \\mathbf{w}^{\\tau + 1} = \\mathbf{w}^{\\tau} - \\eta \\nabla_{\\mathbf{w}^{\\tau}} E \\tag{1.1} $$\nwhere \\(\\eta, \\tau, E\\) label learning rate (\\(\\eta \u0026gt; 0\\)), the iteration step and the loss function.","keywords":["Gradients","Optimization"],"articleBody":"1. Gradient descent optimization Gradient-based methods make use of the gradient information to adjust the parameters. Among them, gradient descent can be the simplest. Gradient descent makes the parameters to walk a small step in the direction of the negative gradient.\n$$ \\mathbf{w}^{\\tau + 1} = \\mathbf{w}^{\\tau} - \\eta \\nabla_{\\mathbf{w}^{\\tau}} E \\tag{1.1} $$\nwhere \\(\\eta, \\tau, E\\) label learning rate (\\(\\eta \u003e 0\\)), the iteration step and the loss function.\nWait! But why is the negative gradient?\n2. Why negative gradient The function increases the most sharply by following the direction of the gradient.\nThe below is an example. The three-dimensional plane is \\(z = F(x, y)\\). The black point is on the plane. You can try to move the point to see how the arrow changes. Interestingly, the arrow always points to the direction which leads to the biggest increase of the function value. Note that when you move one step, the gradient just changes. Thus if you still want to increase the function value in the most sharp way, another computation is needed.\nThe starting point of the arrow is the mapping of the black point to the \\(xoy\\) plane. The arrow is parallel to the gradient.\nthe illustration of the direction of gradient Let us use another graph to better understand what the mapping means. The left graph is contour plot while the right is the plane. The red point is just the mapping of the black point to $xoy$ plane. The blue arrow is just the direction of the gradient. And you can move the point to feel about it.\nanother illustration That is the intuitive way to feel about the gradient. Furthermore, we can just try to prove it.\nConsider a Taylor Expansion:\n$$ \\begin{aligned} F(\\mathbf{r_0} + \\mathbf{r}) \u0026= F(\\mathbf{r}_0) + \\nabla_{\\mathbf{r}_0}F \\cdot \\mathbf{r}\\\\ \u0026= F(\\mathbf{r}_0) + \\|\\nabla_{\\mathbf{r}_0}F\\|\\cdot \\|\\mathbf{r}\\| \\cdot \\cos \\theta \\end{aligned}\\tag{2.1} $$ When you decide to move a small step, the two magnitudes are certain. If $\\theta=0$, you can maximize the function value (i.e. in the direction of the gradient).\nThus if we want to minimize our loss function, we need to go in the opposite direction of the gradient. That is why we need a negative gradient. Also, note that Taylor Expansion only applies to small \\(\\Delta x\\) which further requires \\(\\eta\\) to be small (e.g. \\(2 \\times 10^{-5}, 5 \\times 10^{-5}\\)).\nBut how to compute the gradient needs a powerful technique: back-propagation.\n3. Definition of back-propagation Back-propagation allows information from the cost to then flow backwards through the network, in order to compute the gradients used to adjust the parameters.\nBack-propagation can be new to the novices, but it does exist in the life widely. For instance, the loss can be your teacher’s attitude towards you. If you fail in one examination, your teacher can be disappointed with you. Then, he can tell your parents about your failure. Your parents then ask you to work harder to win the examination.\nYour parents can be seen as hidden units in the neural network, and you are the parameter of the network. Your teacher’s bad attitude towards your failure can ask you to make adjustments: working harder. Similarly, the loss can require the parameters to make adjustments via gradients.\n4. Chain Rule Suppose \\(z = f(y), y = g(x) \\implies z = (f \\circ g)(x)\\), how to calculate the derivative of \\(z\\) with respect to \\(x\\)? The chain rule of calculus is used to compute the derivatives of functions formed by composing other functions whose derivatives are known.\n$$ \\frac{dz}{dx} = \\frac{dz}{dy} \\frac{dy}{dx} \\tag{4.1} $$\n5. Case Study Let’s first see an important example. In fully connected layers, one input neuron sends information (i.e., multiplied by weights) to every output neuron. Denote \\(w_{ji}\\) as the weight from \\(x_i\\) to \\(y_j\\). Then for every output neuron (e.g., \\(y_j\\)), it accepts the information sent by every input neuron:\n$$ y_{j}= \\sum\\limits_{i} w_{ji} x_{i} \\tag{5.1} $$\nThen the partial derivative of \\(y_j\\) with respect to \\(x_i\\):\n$$ \\frac{\\partial y_j}{\\partial x_{i}}= w_{ji} \\tag{5.2} $$\nLet’s see another example. Comes from Bishop-Pattern-Recognition-and-Machine-Learning-2006 And we can represent it by the computational graph below.\nAnd we can perform a forward propagation according to the computational graph.\n$$ \\begin{align} h_{j} \u0026= \\sum\\limits_{i} w_{ji}^{(1)} x_{i} \\tag{5.3} \\\\ z_{j} \u0026= f(h_{j}) \\tag{5.4} \\\\ y_{k} \u0026= \\sum\\limits_{j}w_{kj}^{(2)} z_{j} \\tag{5.5} \\end{align} $$ where\n$$ f(h) = \\tanh(h) = \\frac{e^h - e^{-h}}{e^h + e^{-h}} \\tag{5.6} $$\nA useful feature of this activation is that its derivative can be expressed in a particularly simple form:\n$$ f’(h) = 1 - f(h)^2 \\tag{5.7} $$\nThe error function can be mean squared errors:\n$$ E(\\mathbf{w}) = \\frac{1}{2} \\sum\\limits_{k}(y_{k}- \\hat{y}_k)^2 \\tag{5.8} $$\nIf we want to update the parameters, we need first to compute the partial derivative of \\(E(\\mathbf{w})\\) with respect to them.\n$$ \\frac{\\partial E(\\mathbf{w})}{\\partial w_{kj}^{(2)}} = \\frac{\\partial E(\\mathbf{w})}{\\partial y_{k}} \\frac{\\partial y_k}{\\partial w_{kj}^{(2)}} = (y_{k}- \\hat{y}_k)z_{j} \\tag{5.9} $$\n$$ \\begin{align} \\frac{\\partial E(\\mathbf{w})}{\\partial w_{ji}^{(1)}} \u0026= \\frac{\\partial E(\\mathbf{w})}{\\partial h_{j}}\\frac{\\partial h_j}{\\partial w_{ji}^{(1)}} = \\left(\\frac{\\partial E(\\mathbf{w})}{\\partial z_{j}} \\frac{\\partial z_j}{\\partial h_j}\\right)x_{i} \\tag{5.10} \\end{align} $$\n$$ \\frac{\\partial E(\\mathbf{w})}{\\partial z_j} = \\sum\\limits_{k}\\frac{\\partial E(\\mathbf{w})}{\\partial y_{k}}\\frac{\\partial y_k}{\\partial z_{j}}= \\sum\\limits_{k} (y_{k}- \\hat{y}_{k}) w_{kj}^{(2)}\\tag{5.11} $$\n\\(\\text{Remark.}\\) \\(z_j\\) can send information to all the output neurons (e.g., \\(y_k\\)), thus we need to sum over all the derivatives with respect to \\(z_j\\).\nSubstituting \\(\\text{(4.11)}\\) into \\(\\text{(4.10)}\\) we obtain\n$$ \\frac{\\partial E(\\mathbf{w})}{\\partial w_{ji}^{(1)}} = (1 - z_j^2)x_{i} \\sum\\limits_{k} (y_{k}- \\hat{y}_{k}) w_{kj}^{(2)} \\tag{5.12} $$ 6. Interpretation Recall the Taylor approximation of the two variables function:\n$$ f(x, y) = f(x_0, y_0) + f_x (x- x_0) + f_y(y-y_0) \\tag{6.1} $$\n\\(\\text{Remark.}\\) \\((x, y)\\) needs to be close to \\((x_0, y_0)\\), otherwise the approximation can fail.\nWe can transform \\(\\text{(5.1)}\\) into \\(\\text{(5.3)}\\):\n$$ \\begin{align} f(x,y) - f(x_{0},y_0) \u0026= f_x (x- x_0) + f_y(y-y_0) \\tag{6.2}\\\\ \\implies \\Delta f \u0026= f_x \\Delta x + f_y \\Delta y\\tag{6.3} \\end{align} $$ If we apply \\(\\text{(5.3)}\\) in the example above, we can obtain\n$$ \\Delta E(\\mathbf{w}) = \\nabla_{\\mathbf{w}}E(\\mathbf{w}) \\Delta \\mathbf{w} \\tag{6.4} $$\nFrom another perspective, a small change in the parameters will propagate into a small change in object function by getting multiplied by the gradient.\nTo summarize, back-propagation allows information to flow backwards through the network. This information can tell the model a small change in one particular parameter can result in what change in the object function. And gradient descent can use this information to adjust the parameters for optimizing the object function.\n","wordCount":"1054","inLanguage":"en","datePublished":"2022-09-07T11:10:00+08:00","dateModified":"2022-09-07T11:10:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://yunpengtai.top/posts/back-propagation/"},"publisher":{"@type":"Organization","name":"Tai's Blog","logo":{"@type":"ImageObject","url":"https://yunpengtai.top/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://yunpengtai.top accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://yunpengtai.top/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://yunpengtai.top/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://yunpengtai.top/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://yunpengtai.top/friends/ title=Friends><span>Friends</span></a></li><li><a href=https://yunpengtai.top/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://yunpengtai.top>Home</a>&nbsp;»&nbsp;<a href=https://yunpengtai.top/posts/>Posts</a></div><h1 class=post-title>Going Deeper into Back-propagation</h1><div class=post-meta><span title='2022-09-07 11:10:00 +0800 CST'>September 7, 2022</span>&nbsp;·&nbsp;1054 words</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-gradient-descent-optimization aria-label="1. Gradient descent optimization">1. Gradient descent optimization</a></li><li><a href=#2-why-negative-gradient aria-label="2. Why negative gradient">2. Why negative gradient</a></li><li><a href=#3-definition-of-back-propagation aria-label="3. Definition of back-propagation">3. Definition of back-propagation</a></li><li><a href=#4-chain-rule aria-label="4. Chain Rule">4. Chain Rule</a></li><li><a href=#5-case-study aria-label="5. Case Study">5. Case Study</a></li><li><a href=#6-interpretation aria-label="6. Interpretation">6. Interpretation</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h3 id=1-gradient-descent-optimization>1. Gradient descent optimization<a hidden class=anchor aria-hidden=true href=#1-gradient-descent-optimization>#</a></h3><p>Gradient-based methods make use of the gradient information to adjust the parameters. Among them, gradient descent can be the simplest. Gradient descent makes the parameters to walk a small step in the direction of the negative gradient.</p><p>$$
\mathbf{w}^{\tau + 1} = \mathbf{w}^{\tau} - \eta \nabla_{\mathbf{w}^{\tau}} E \tag{1.1}
$$</p><p>where \(\eta, \tau, E\) label learning rate (\(\eta > 0\)), the iteration step and the loss function.</p><p>Wait! But why is the negative gradient?</p><h3 id=2-why-negative-gradient>2. Why negative gradient<a hidden class=anchor aria-hidden=true href=#2-why-negative-gradient>#</a></h3><blockquote class=quote><p>The function increases the most sharply by following the direction of the gradient.</p></blockquote><p>The below is an example. The three-dimensional plane is \(z = F(x, y)\). The black point is on the plane. You can try to move the point to see how the arrow changes. Interestingly, the arrow always points to the direction which leads to the biggest increase of the function value. Note that when you move one step, the gradient just changes. Thus if you still want to increase the function value in the most sharp way, another computation is needed.</p><div class="notice notice-tip"><div class=notice-title><svg xmlns="http://www.w3.org/2000/svg" class="icon notice-icon" viewBox="0 0 512 512" fill="hsl(140, 65%, 65%)"><path d="M504 256A248 248 0 118 256a248 248 0 01496 0zM227 387l184-184c7-6 7-16 0-22l-22-23c-7-6-17-6-23 0L216 308l-70-70c-6-6-16-6-23 0l-22 23c-7 6-7 16 0 22l104 104c6 7 16 7 22 0z"/></svg></div><p>The starting point of the arrow is the mapping of the black point to the \(xoy\) plane. The arrow is parallel to the gradient.</p></div><p><details><summary markdown=span>the illustration of the direction of gradient</summary>
<center><iframe scrolling=no title="Directional derivatives and Gradient" src=https://www.geogebra.org/material/iframe/id/wd5mrudh/width/700/height/500/border/888888/rc/false/ai/false/sdz/false/smb/false/stb/false/stbh/false/ld/false/sri/false/at/auto width=500px height=290px style=border:0></iframe></center></details></p><p>Let us use another graph to better understand what the mapping means. The left graph is contour plot while the right is the plane. The red point is just the mapping of the black point to $xoy$ plane. The blue arrow is just the direction of the gradient. And you can move the point to feel about it.</p><p><details><summary markdown=span>another illustration</summary>
<center><iframe scrolling=no title="Directional derivatives and Gradient" src=https://www.geogebra.org/material/iframe/id/vpt37qtt/width/788/height/520/border/888888/sfsb/true/smb/false/stb/false/stbh/false/ai/false/asb/false/sri/false/rc/false/ld/false/sdz/true/ctl/false width=560px height=420px style=border:0></iframe></center></details></p><p>That is the intuitive way to feel about the gradient. Furthermore, we can just try to prove it.</p><p>Consider a Taylor Expansion:</p><div>$$
\begin{aligned}
F(\mathbf{r_0} + \mathbf{r}) &= F(\mathbf{r}_0) + \nabla_{\mathbf{r}_0}F \cdot \mathbf{r}\\
&= F(\mathbf{r}_0) + \|\nabla_{\mathbf{r}_0}F\|\cdot \|\mathbf{r}\| \cdot \cos \theta
\end{aligned}\tag{2.1}
$$</div><p>When you decide to move a small step, the two magnitudes are certain. If $\theta=0$, you can maximize the function value (i.e. in the direction of the gradient).</p><p>Thus if we want to minimize our loss function, we need to go in the opposite direction of the gradient. That is why we need a negative gradient. Also, note that Taylor Expansion only applies to small \(\Delta x\) which further requires \(\eta\) to be small (e.g. \(2 \times 10^{-5}, 5 \times 10^{-5}\)).</p><p>But how to compute the gradient needs a powerful technique: back-propagation.</p><h3 id=3-definition-of-back-propagation>3. Definition of back-propagation<a hidden class=anchor aria-hidden=true href=#3-definition-of-back-propagation>#</a></h3><div class="notice notice-note"><div class=notice-title><svg xmlns="http://www.w3.org/2000/svg" class="icon notice-icon" viewBox="0 0 512 512" fill="hsl(200, 65%, 65%)"><path d="M504 256A248 248 0 118 256a248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165 8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z"/></svg></div><p>Back-propagation allows information from the cost to then flow backwards through the network, in order to compute the gradients used to adjust the parameters.</p></div><p>Back-propagation can be new to the novices, but it does exist in the life widely. For instance, the loss can be your teacher&rsquo;s attitude towards you. If you fail in one examination, your teacher can be disappointed with you. Then, he can tell your parents about your failure. Your parents then ask you to work harder to win the examination.</p><p>Your parents can be seen as hidden units in the neural network, and you are the parameter of the network. Your teacher&rsquo;s bad attitude towards your failure can ask you to make adjustments: working harder. Similarly, the loss can require the parameters to make adjustments via gradients.</p><h3 id=4-chain-rule>4. Chain Rule<a hidden class=anchor aria-hidden=true href=#4-chain-rule>#</a></h3><p>Suppose \(z = f(y), y = g(x) \implies z = (f \circ g)(x)\), how to calculate the derivative of \(z\) with respect to \(x\)? The chain rule of calculus is used to compute the derivatives of functions formed by composing other functions whose derivatives are known.</p><p>$$
\frac{dz}{dx} = \frac{dz}{dy} \frac{dy}{dx} \tag{4.1}
$$</p><h3 id=5-case-study>5. Case Study<a hidden class=anchor aria-hidden=true href=#5-case-study>#</a></h3><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/09/07/iTFg9de8RyfJavm.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/09/07/iTFg9de8RyfJavm.png#center width=300 height=150></figure></a><p>Let&rsquo;s first see an important example. In fully connected layers, one input neuron sends information (i.e., multiplied by weights) to every output neuron. Denote \(w_{ji}\) as the weight from \(x_i\) to \(y_j\). Then for every output neuron (e.g., \(y_j\)), it accepts the information sent by every input neuron:</p><p>$$
y_{j}= \sum\limits_{i} w_{ji} x_{i} \tag{5.1}
$$</p><p>Then the partial derivative of \(y_j\) with respect to \(x_i\):</p><p>$$
\frac{\partial y_j}{\partial x_{i}}= w_{ji} \tag{5.2}
$$</p><p>Let&rsquo;s see another example.
<span class=sidenote-number><small class=sidenote>Comes from Bishop-Pattern-Recognition-and-Machine-Learning-2006</small></span></p><p>And we can represent it by the computational graph below.</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/09/07/QOJYtIw6BNmsc2i.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/09/07/QOJYtIw6BNmsc2i.png#center width=290 height=200></figure></a><p>And we can perform a forward propagation according to the computational graph.</p><div>$$
\begin{align}
h_{j} &= \sum\limits_{i} w_{ji}^{(1)} x_{i} \tag{5.3} \\
z_{j} &= f(h_{j})     \tag{5.4}      \\
y_{k} &= \sum\limits_{j}w_{kj}^{(2)} z_{j} \tag{5.5}
\end{align}
$$</div><p>where</p><p>$$
f(h) = \tanh(h) = \frac{e^h - e^{-h}}{e^h + e^{-h}} \tag{5.6}
$$</p><p>A useful feature of this activation is that its derivative can be expressed in a particularly simple form:</p><p>$$
f&rsquo;(h) = 1 - f(h)^2 \tag{5.7}
$$</p><p>The error function can be mean squared errors:</p><p>$$
E(\mathbf{w}) = \frac{1}{2} \sum\limits_{k}(y_{k}- \hat{y}_k)^2 \tag{5.8}
$$</p><p>If we want to update the parameters, we need first to compute the partial derivative of \(E(\mathbf{w})\) with respect to them.</p><p>$$
\frac{\partial E(\mathbf{w})}{\partial w_{kj}^{(2)}} = \frac{\partial E(\mathbf{w})}{\partial y_{k}} \frac{\partial y_k}{\partial w_{kj}^{(2)}} = (y_{k}- \hat{y}_k)z_{j} \tag{5.9}
$$</p><p>$$
\begin{align}
\frac{\partial E(\mathbf{w})}{\partial w_{ji}^{(1)}} &= \frac{\partial E(\mathbf{w})}{\partial h_{j}}\frac{\partial h_j}{\partial w_{ji}^{(1)}} = \left(\frac{\partial E(\mathbf{w})}{\partial z_{j}} \frac{\partial z_j}{\partial h_j}\right)x_{i} \tag{5.10}
\end{align}
$$</p><p>$$
\frac{\partial E(\mathbf{w})}{\partial z_j} = \sum\limits_{k}\frac{\partial E(\mathbf{w})}{\partial y_{k}}\frac{\partial y_k}{\partial z_{j}}= \sum\limits_{k} (y_{k}- \hat{y}_{k}) w_{kj}^{(2)}\tag{5.11}
$$</p><p>\(\text{Remark.}\) \(z_j\) can send information to all the output neurons (e.g., \(y_k\)), thus we need to sum over all the derivatives with respect to \(z_j\).</p><p>Substituting \(\text{(4.11)}\) into \(\text{(4.10)}\) we obtain</p><div>$$
\frac{\partial E(\mathbf{w})}{\partial w_{ji}^{(1)}} = (1 - z_j^2)x_{i} \sum\limits_{k} (y_{k}- \hat{y}_{k}) w_{kj}^{(2)} \tag{5.12}
$$</div><h3 id=6-interpretation>6. Interpretation<a hidden class=anchor aria-hidden=true href=#6-interpretation>#</a></h3><p>Recall the Taylor approximation of the two variables function:</p><p>$$
f(x, y) = f(x_0, y_0) + f_x (x- x_0) + f_y(y-y_0) \tag{6.1}
$$</p><p>\(\text{Remark.}\) \((x, y)\) needs to be close to \((x_0, y_0)\), otherwise the approximation can fail.</p><p>We can transform \(\text{(5.1)}\) into \(\text{(5.3)}\):</p><div>$$
\begin{align}
f(x,y) - f(x_{0},y_0) &= f_x (x- x_0) + f_y(y-y_0) \tag{6.2}\\
\implies \Delta f &= f_x \Delta x  + f_y \Delta y\tag{6.3}
\end{align}
$$</div><p>If we apply \(\text{(5.3)}\) in the example above, we can obtain</p><p>$$
\Delta E(\mathbf{w}) = \nabla_{\mathbf{w}}E(\mathbf{w}) \Delta \mathbf{w} \tag{6.4}
$$</p><p>From another perspective, a small change in the parameters will propagate into a small change in object function by getting multiplied by the gradient.</p><div class="notice notice-tip"><div class=notice-title><svg xmlns="http://www.w3.org/2000/svg" class="icon notice-icon" viewBox="0 0 512 512" fill="hsl(140, 65%, 65%)"><path d="M504 256A248 248 0 118 256a248 248 0 01496 0zM227 387l184-184c7-6 7-16 0-22l-22-23c-7-6-17-6-23 0L216 308l-70-70c-6-6-16-6-23 0l-22 23c-7 6-7 16 0 22l104 104c6 7 16 7 22 0z"/></svg></div><p>To summarize, back-propagation allows information to flow backwards through the network. This information can tell the model a small change in one particular parameter can result in what change in the object function. And gradient descent can use this information to adjust the parameters for optimizing the object function.</p></div></div><blockquote class=quote-copyright>Author: Yunpengtai<p>Link: https://yunpengtai.top/posts/back-propagation/<p>License: CC BY-NC-SA 4.0. You must provide a link to the source.</blockquote><footer class=post-footer><ul class=post-tags><li><a href=https://yunpengtai.top/tags/gradients/>Gradients</a></li><li><a href=https://yunpengtai.top/tags/optimization/>Optimization</a></li></ul><nav class=paginav><a class=prev href=https://yunpengtai.top/posts/diving-in-distributed-training/><span class=title>« Prev</span><br><span>Diving in distributed training in PyTorch</span></a>
<a class=next href=https://yunpengtai.top/posts/tips-for-training-neural-networks/><span class=title>Next »</span><br><span>Tips for Training Neural Networks</span></a></nav></footer><link rel=stylesheet href=https://unpkg.com/katex@0.15.3/dist/katex.min.css><script defer src=https://unpkg.com/katex@0.15.3/dist/katex.min.js></script>
<link href=https://cdn.jsdelivr.net/gh/sherlcok314159/artalk-blobcat@main/artalk.css rel=stylesheet><script src=https://comment.yunpengtai.top/lib/artalk/Artalk.js></script>
<script src=https://unpkg.com/@artalk/plugin-katex/dist/artalk-plugin-katex.js></script><div id=Comments></div><script>Artalk.init({el:"#Comments",pageKey:"",pageTitle:"Going Deeper into Back-propagation",server:"https://comment.yunpengtai.top",site:"Tai's Blog"})</script></article></main><footer class=footer><span>&copy; 2024 <a href=https://yunpengtai.top>Tai's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/sherlcok314159/MyPaperMod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>(function(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}})()</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("//cdn.bootcss.com/pangu/4.0.7/pangu.min.js",function(){pangu.spacingPage()})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>