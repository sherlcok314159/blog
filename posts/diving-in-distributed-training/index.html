<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Diving in distributed training in PyTorch | Tai's Blog</title><meta name=keywords content="Multi-gpus,DataParallel,Distributed Training"><meta name=description content="鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！ 关于此部分的代码，可以去这"><meta name=author content><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="eAKh7zszsOtNde1wyq_sUo95ZPH4zTTJhR-_ol4VWDs"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yunpengtai.top/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yunpengtai.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yunpengtai.top/favicon-32x32.png><link rel=apple-touch-icon href=https://yunpengtai.top/apple-touch-icon.png><link rel=mask-icon href=https://yunpengtai.top/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script>MathJax={loader:{load:["[tex]/boldsymbol"]},tex:{tags:"all",inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,packages:{"[+]":["boldsymbol"]}}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js integrity="sha256-kbAFUDxdHwlYv01zraGjvjNZayxKtdoiJ38bDTFJtaQ=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-Y3CX2RWEDY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Y3CX2RWEDY",{anonymize_ip:!1})}</script><meta property="og:title" content="Diving in distributed training in PyTorch"><meta property="og:description" content="鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！ 关于此部分的代码，可以去这"><meta property="og:type" content="article"><meta property="og:url" content="https://yunpengtai.top/posts/diving-in-distributed-training/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-20T21:37:00+08:00"><meta property="article:modified_time" content="2022-11-20T21:37:00+08:00"><meta property="og:site_name" content="Tai's Blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://yunpengtai.top/posts/"},{"@type":"ListItem","position":3,"name":"Diving in distributed training in PyTorch","item":"https://yunpengtai.top/posts/diving-in-distributed-training/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Diving in distributed training in PyTorch","name":"Diving in distributed training in PyTorch","description":"鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！ 关于此部分的代码，可以去这","keywords":["Multi-gpus","DataParallel","Distributed Training"],"articleBody":"鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！\n关于此部分的代码，可以去这里查看\n在开始前，我需要特别致谢一下一位挚友，他送了我双显卡的机器来赞助我做个人研究，否则多卡的相关实验就得付费在云平台上跑了，感谢好朋友一路以来的支持，这份友谊值得一辈子铭记！这篇文章作为礼物赠与挚友。\n并行化的原因 我们在两种情况下进行并行化训练：\n模型一张卡放不下：我们需要将模型不同的结构放置到不同的GPU上运行，这种情况叫ModelParallel(MP) 单卡batch size过小：有些时候数据的最大长度调的比较高（e.g., 512），可用的bs就很小，较小的bs会导致收敛不稳定，因而将数据分发到多个GPU上进行并行训练，这种情况叫DataParallel(DP)。当然，DP肯定还可以加速训练，常见于大模型的训练中 这里只讲一下DP在pytorch中的原理和相关实现，即DataParallel和DistributedParallel\nData Parallel 实现原理 实现就是循环往复一个过程：数据分发，模型复制，各自前向传播，汇聚输出，计算损失，梯度回传，梯度汇聚更新，可以参见下图\npytorch中部分关键源码截取如下：\ndata_parallel源码 def data_parallel( module, input, device_ids, output_device=None ): if not device_ids: return module(input) if output_device is None: output_device = device_ids[0] # 复制模型 replicas = nn.parallel.replicate(module, device_ids) # 拆分数据 inputs = nn.parallel.scatter(input, device_ids) replicas = replicas[:len(inputs)] # 各自前向传播 outputs = nn.parallel.parallel_apply(replicas, inputs) # 汇聚输出 return nn.parallel.gather(outputs, output_device) 代码使用 因为运行时会将数据平均拆分到GPU上，所以我们准备数据的时候， batch size = per_gpu_batch_size * n_gpus\n同时，需要注意主GPU需要进行汇聚等操作，因而需要比单卡运行时「多留出一些空间」\nimport torch.nn as nn # device_ids默认所有可使用的设备 # output_device默认cuda:0 net = nn.DataParallel(model, device_ids=[0, 1, 2], output_device=None, dim=0) # input_var can be on any device, including CPU output = net(input_var) 接下来看个更详细的例子，需要注意的是被DP包裹之后涉及到模型相关的，需要调用DP.module，比如「加载模型」\ndata_parallel示例 class Model(nn.Module): # Our model def __init__(self, input_size, output_size): super(Model, self).__init__() # for convenience self.fc = nn.Linear(input_size, output_size) def forward(self, input): output = self.fc(input) print(\"\\tIn Model: input size\", input.size(), \"output size\", output.size()) return output bs, input_size, output_size = 6, 8, 10 # define inputs inputs = torch.randn((bs, input_size)).cuda() model = Model(input_size, output_size) if torch.cuda.device_count() \u003e 1: print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\") # dim = 0 [6, xxx] -\u003e [2, ...], [2, ...], [2, ...] on 3 GPUs model = nn.DataParallel(model) # 先DataParallel，再cuda model = model.cuda() outputs = model(inputs) print(\"Outside: input size\", inputs.size(), \"output_size\", outputs.size()) # assume 2 GPUS are available # Let's use 2 GPUs! # In Model: input size torch.Size([3, 8]) output size torch.Size([3, 10]) # In Model: input size torch.Size([3, 8]) output size torch.Size([3, 10]) # Outside: input size torch.Size([6, 8]) output_size torch.Size([6, 10]) # save the model torch.save(model.module.state_dict(), PATH) # load again model.module.load_state_dict(torch.load(PATH)) # do anything you want 如果经常使用huggingface，这里有两个误区需要小心：\ndata_parallel两个误区 # data parallel object has no save_pretrained model = xxx.from_pretrained(PATH) model = nn.DataParallel(model).cuda() model.save_pretrained(NEW_PATH) # error # 因为model被DP wrap了，得先取出模型 # model.module.save_pretrained(NEW_PATH) # HF实现貌似是返回N个loss（N为GPU数量） # 然后对N个loss取mean outputs = model(**inputs) loss, logits = outputs.loss, outputs.logits loss = loss.mean() loss.backward() # 返回的logits是汇聚后的 # HF实现和我们手动算loss有细微差异 # 手动算略好于HF loss2 = loss_fct(logits, labels) assert loss != loss2 True 显存不均匀 了解前面的原理后，就会明白为什么会显存不均匀。因为GPU0比其他GPU多了汇聚的工作，得留一些显存，而其他GPU显然是不需要的。那么，解决方案就是让其他GPU的batch size开大点，GPU0维持原状，即不按照默认实现的平分数据\n首先参考这里我们继承原来的DataParallel，这里我们给定第一个GPU的bs就可以，这个是实际的bs而不是乘上梯度后的。假如你想要总的bs为64，梯度累积为2，一共2张GPU，而一张最多只能18，那么保险一点GPU0设置为14，GPU1是18，也就是说你DataLoader每个batch大小是32，gpu0_bsz=14\nclass BalancedDataParallel(DataParallel): def __init__(self, gpu0_bsz, *args, **kwargs): self.gpu0_bsz = gpu0_bsz super().__init__(*args, **kwargs) 核心代码就在于我们重新分配chunk_sizes，实现思路就是将总的减去第一个GPU的再除以剩下的设备，源码的话有些死板，用的时候不妨参考我的：\n我修改后的scatter def scatter(self, inputs, kwargs, device_ids): # 不同于源码，获取batch size更加灵活 # 支持只有kwargs的情况，如model(**inputs) if len(inputs) \u003e 0: bsz = inputs[0].size(self.dim) elif kwargs: bsz = list(kwargs.values())[0].size(self.dim) else: raise ValueError(\"You must pass inputs to the model!\") num_dev = len(self.device_ids) gpu0_bsz = self.gpu0_bsz # 除第一块之外每块GPU的bsz bsz_unit = (bsz - gpu0_bsz) // (num_dev - 1) if gpu0_bsz \u003c bsz_unit: # adapt the chunk sizes chunk_sizes = [gpu0_bsz] + [bsz_unit] * (num_dev - 1) delta = bsz - sum(chunk_sizes) # 补足偏移量 # 会有显存溢出的风险，因而最好给定的bsz是可以整除的 # e.g., 总的=52 =\u003e bsz_0=16, bsz_1=bsz_2=18 # 总的=53 =\u003e bsz_0=16, bsz_1=19, bsz_2=18 for i in range(delta): chunk_sizes[i + 1] += 1 if gpu0_bsz == 0: chunk_sizes = chunk_sizes[1:] else: return super().scatter(inputs, kwargs, device_ids) return scatter_kwargs(inputs, kwargs, device_ids, chunk_sizes, dim=self.dim) 优缺点 优点：便于操作，理解简单 缺点：GPU分配不均匀；每次更新完都得销毁线程（运行程序后会有一个进程，一个进程可以有很多个线程）重新复制模型，因而速度慢 DDP 实现原理 与DataParallel不同的是，Distributed Data Parallel会开设多个进程而非线程，进程数 = GPU数，每个进程都可以独立进行训练，也就是说代码的所有部分都会被每个进程同步调用，如果你某个地方print张量，你会发现device的差异 sampler会将数据按照进程数切分，确保不同进程的数据不同 每个进程独立进行前向训练 每个进程利用Ring All-Reduce进行通信，将梯度信息进行聚合 每个进程同步更新模型参数，进行新一轮训练 如何确保数据不同呢？\nDistributedSampler的源码 # 判断数据集长度是否可以整除GPU数 # 如果不能，选择舍弃还是补全，进而决定总数 # If the dataset length is evenly divisible by # of replicas # then there is no need to drop any data, since the dataset # will be split equally. if (self.drop_last and len(self.dataset) % self.num_replicas != 0): # num_replicas = num_gpus self.num_samples = math.ceil((len(self.dataset) - self.num_replicas) /self.num_replicas) else: self.num_samples = math.ceil(len(self.dataset) / self.num_replicas) self.total_size = self.num_samples * self.num_replicas # 根据是否shuffle来创建indices if self.shuffle: # deterministically shuffle based on epoch and seed g = torch.Generator() g.manual_seed(self.seed + self.epoch) indices = torch.randperm(len(self.dataset), generator=g).tolist() else: indices = list(range(len(self.dataset))) if not self.drop_last: # add extra samples to make it evenly divisible padding_size = self.total_size - len(indices) if padding_size \u003c= len(indices): # 不够就按indices顺序加 # e.g., indices为[0, 1, 2, 3 ...]，而padding_size为4 # 加好之后的indices[..., 0, 1, 2, 3] indices += indices[:padding_size] else: indices += (indices * math.ceil(padding_size / len(indices)))[:padding_size] else: # remove tail of data to make it evenly divisible. indices = indices[:self.total_size] assert len(indices) == self.total_size # subsample # rank代表进程id indices = indices[self.rank:self.total_size:self.num_replicas] return iter(indices) 接下来用Ring All-Reduce可以降低通信成本\n首先将每块GPU上的梯度拆分成四个部分\\(1\\)，比如\\(g_0 = [a_0; b_0; c_0; d_0]\\)，此部分原理主要参考王老师\n所有GPU的传播都是同步进行的，传播的规律有两条：\n只与自己「下一个位置」的GPU进行通信，比如0 \u003e 1，3 \u003e 0 四个部分，哪块GPU上占的多，就由该块GPU往它下一个传，初始从主节点传播，即GPU0，你可以想象跟接力一样，a传b，b负责传给c 第一次传播如下：\n那么结果就是：\n那么，按照谁多谁往下传的原则，此时应该是GPU1往GPU2传a0和a1，GPU2往GPU3传b1和b2，以此类推\n接下来再传播就会有GPU3 a的部分全有，GPU0上b的部分全有等，就再往下传\n再来几遍便可以使得每块GPU上都获得了来自其他GPU的梯度啦\n代码使用 第一个是后端的选择，即数据传输协议，当使用CPU时可以选择gloo或mpi，而GPU则可以是nccl\n接下来是一些参数的解释\nArg Meaning group 一次发起的所有进程构成一个group，除非想更精细通信，创建new_group world_size 一个group中进程数目，即为GPU的数量 rank 进程id，主节点rank=0，其他的在0和world_size-1之间 local_rank 进程在本地节点/机器的id 举个例子，假如你有两台服务器（又被称为node），每台服务器有4张GPU，那么，world_size即为8，rank=[0, 1, 2, 3, 4, 5, 6, 7], 每个服务器上的进程的local_rank为[0, 1, 2, 3]\n然后是初始化方法的选择，有TCP和共享文件两种，一般指定rank=0为master节点\nTCP显而易见是通过网络进行传输，需要指定主节点的ip（可以为主节点实际IP，或者是localhost）和空闲的端口\nimport torch.distributed as dist dist.init_process_group(backend, init_method='tcp://ip:port', rank=rank, world_size=world_size) 共享文件的话需要手动删除上次启动时残留的文件，加上官方有一堆警告，还是建议使用TCP\ndist.init_process_group(backend, init_method='file://Path', rank=rank, world_size=world_size) 这里先讲用launch初始化的方法，关于torch.multiprocessing留到后面讲\n在启动后，rank和world_size都会自动被DDP写入环境中，可以提前准备好参数类，如argparse这种\nargs.rank = int(os.environ['RANK']) args.world_size = int(os.environ['WORLD_SIZE']) args.local_rank = int(os.environ['LOCAL_RANK']) 首先，在使用distributed包的任何其他函数之前，按照tcp方法进行初始化，需要注意的是需要手动指定一共可用的设备CUDA_VISIBLE_DEVICES\nlaunch初始化 def dist_setup_launch(args): # tell DDP available devices [NECESSARY] os.environ['CUDA_VISIBLE_DEVICES'] = args.devices args.rank = int(os.environ['RANK']) args.world_size = int(os.environ['WORLD_SIZE']) args.local_rank = int(os.environ['LOCAL_RANK']) dist.init_process_group(args.backend, args.init_method, rank=args.rank, world_size=args.world_size) # this is optional, otherwise you may need to specify the # device when you move something e.g., model.cuda(1) # or model.to(args.rank) # Setting device makes things easy: model.cuda() torch.cuda.set_device(args.rank) print('The Current Rank is %d | The Total Ranks are %d' %(args.rank, args.world_size)) 接下来创建DistributedSampler，是否pin_memory，根据你本机的内存决定。pin_memory的意思是提前在内存中申请一部分专门存放Tensor。假如说你内存比较小，就会跟虚拟内存，即硬盘进行交换，这样转义到GPU上会比内存直接到GPU耗时。\n因而，如果你的内存比较大，可以设置为True；然而，如果开了导致卡顿的情况，建议关闭\n加载数据 from torch.utils.data import DataLoader, DistributedSampler train_sampler = DistributedSampler(train_dataset, seed=args.seed) train_dataloader = DataLoader(train_dataset, pin_memory=True, shuffle=(train_sampler is None), batch_size=args.per_gpu_train_bs, num_workers=args.num_workers, sampler=train_sampler) eval_sampler = DistributedSampler(eval_dataset, seed=args.seed) eval_dataloader = DataLoader(eval_dataset, pin_memory=True, batch_size=args.per_gpu_eval_bs, num_workers=args.num_workers, sampler=eval_sampler) 然后加载模型，跟DataParallel不同的是需要提前放置到cuda上，还记得上面关于设置cuda_device的语句嘛，因为设置好之后每个进程只能看见一个GPU，所以直接model.cuda()，不需要指定device\n同时，我们必须给DDP提示目前是哪个rank\nfrom torch.nn.parallel import DistributedDataParallel as DDP model = model.cuda() # tell DDP which rank model = DDP(model, find_unused_parameters=True, device_ids=[rank]) 注意，当模型带有Batch Norm时：\nif args.syncBN: nn.SyncBatchNorm.convert_sync_batchnorm(model).cuda() 现在说训练的事情，每个epoch开始训练的时候，记得用sampler的set_epoch，这样使得每个epoch打乱顺序是不一致的\n关于梯度回传和参数更新，跟正常情况无异\nfor epoch in range(epochs): # record epochs train_dataloader.sampler.set_epoch(epoch) outputs = model(inputs) loss = loss_fct(outputs, labels) loss.backward() optimizer.step() optimizer.zero_grad() 这里有一点需要小心，这个loss是各个进程的loss之和，如果想要存储每个step平均损失，可以进行all_reduce操作，进行平均，不妨看官方的小例子来理解下：\nreduce相关代码 \u003e\u003e\u003e # All tensors below are of torch.int64 type. \u003e\u003e\u003e # We have 2 process groups, 2 ranks. \u003e\u003e\u003e tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank \u003e\u003e\u003e tensor tensor([1, 2]) # Rank 0 tensor([3, 4]) # Rank 1 \u003e\u003e\u003e dist.all_reduce(tensor, op=ReduceOp.SUM) \u003e\u003e\u003e tensor tensor([4, 6]) # Rank 0 tensor([4, 6]) # Rank 1 @torch.no_grad() def reduce_value(value, average=True): world_size = get_world_size() if world_size \u003c 2: # 单GPU的情况 return value dist.all_reduce(value) if average: value /= world_size return value 看到这，肯定有小伙伴要问，那这样我们是不是得先求平均损失再回传梯度啊，不用，因为，当我们回传loss后，参照这里，DDP会自动对所有梯度进行平均，也就是说回传后我们更新的梯度和DP或者单卡同样batch训练都是一致的\nloss = loss_fct(...) loss.backward() # 注意在backward后面 loss = reduce_value(loss, world_size) mean_loss = (step * mean_loss + loss.item()) / (step + 1) 还有个注意点就是学习率的变化，这个是和batch size息息相关的，如果batch扩充了几倍，也就是说step比之前少了很多，还采用同一个学习率，肯定会出问题的，这里，我们进行线性增大，感兴趣可以看讨论\nN = world_size lr = args.lr * N 肯定有人说，诶，你线性增大肯定不能保证梯度的variance一致了，正确的应该是正比于\\(\\sqrt{N}\\)，关于这个的讨论不妨参考这里\n接下来，细心的同学肯定好奇了，如果验证集也切分了，metric怎么计算呢？此时就需要咱们把每个进程得到的预测情况集合起来，t就是一个我们需要gather的张量，最后将每个进程中的t按照第一维度拼接，先看官方小例子来理解all_gather\ngather相关代码 \u003e\u003e\u003e # All tensors below are of torch.int64 dtype. \u003e\u003e\u003e # We have 2 process groups, 2 ranks. \u003e\u003e\u003e tensor_list = [torch.zeros(2, dtype=torch.int64) for _ in range(2)] \u003e\u003e\u003e tensor_list [tensor([0, 0]), tensor([0, 0])] # Rank 0 and 1 \u003e\u003e\u003e tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank \u003e\u003e\u003e tensor tensor([1, 2]) # Rank 0 tensor([3, 4]) # Rank 1 \u003e\u003e\u003e dist.all_gather(tensor_list, tensor) \u003e\u003e\u003e tensor_list [tensor([1, 2]), tensor([3, 4])] # Rank 0 [tensor([1, 2]), tensor([3, 4])] # Rank 1 def sync_across_gpus(t, world_size): gather_t_tensor = [torch.zeros_like(t) for _ in range(world_size)] dist.all_gather(gather_t_tensor, t) return torch.cat(gather_t_tensor, dim=0) 可以简单参考我前面提供的源码的evaluate部分，我们首先将预测和标签比对，把结果为bool的张量存储下来，最终gather求和取平均。\n这里还有个有趣的地方，tensor默认的类型可能是int，bool型的res拼接后自动转为0和1了，另外bool型的张量是不支持gather的\neval函数 def eval(...) results = torch.tensor([]).cuda() for step, (inputs, labels) in enumerate(dataloader): outputs = model(inputs) res = (outputs.argmax(-1) == labels) results = torch.cat([results, res], dim=0) results = sync_across_gpus(results, world_size) mean_acc = (results.sum() / len(results)).item() return mean_acc 模型保存，参考部分官方教程，我们只需要在主进程保存模型即可，注意，这里是被DDP包裹后的，DDP并没有state_dict，这里barrier的目的是为了让其他进程等待主进程保存模型，以防不同步\n保存模型 def save_checkpoint(rank, model, path): if is_main_process(rank): # All processes should see same parameters as they all # start from same random parameters and gradients are # synchronized in backward passes. # Therefore, saving it in one process is sufficient. torch.save(model.module.state_dict(), path) # Use a barrier() to keep process 1 waiting for process 0 dist.barrier() 加载的时候别忘了map_location，我们一开始会保存模型至主进程，这样就会导致cuda:0显存被占据，我们需要将模型remap到其他设备\ndef load_checkpoint(rank, model, path): # remap the model from cuda:0 to other devices map_location = {'cuda:%d' % 0: 'cuda:%d' % rank} model.module.load_state_dict( torch.load(path, map_location=map_location) ) 运行结束后记得销毁进程：\ndef cleanup(): dist.destroy_process_group() cleanup() 然后如何启动呢？在终端输入下列命令「单机多卡」\npython -m torch.distributed.launch --nproc_per_node=NUM_GPUS main.py (--arg1 --arg2 --arg3 and all other arguments of your training script) 目前torch 1.10以后更推荐用run\ntorch.distributed.launch -\u003e torch.distributed.run / torchrun 多机多卡是这样的：\n多机多卡启动 # 第一个节点启动 python -m torch.distributed.launch \\ --nproc_per_node=NUM_GPUS \\ --nnodes=2 \\ --node_rank=0 \\ --master_addr=\"192.168.1.1\" \\ --master_port=1234 main.py # 第二个节点启动 python -m torch.distributed.launch \\ --nproc_per_node=NUM_GPUS \\ --nnodes=2 \\ --node_rank=1 \\ --master_addr=\"192.168.1.1\" \\ --master_port=1234 main.py 第二个方法就是利用torch的多线程包\nimport torch.multiprocessing as mp # rank mp会自动填入 def main(rank, arg1, ...): pass if __name__ == '__main__': mp.spawn(main, nprocs=TOTAL_GPUS, args=(arg1, ...)) 这种运行的时候就跟正常的python文件一致：\npython main.py 优缺点 优点： 相比于DP而言，不需要反复创建和销毁线程；Ring-AllReduce算法提高通信效率；模型同步方便 缺点：操作起来可能有些复杂，一般可满足需求的可先试试看DataParallel ","wordCount":"5363","inLanguage":"en","datePublished":"2022-11-20T21:37:00+08:00","dateModified":"2022-11-20T21:37:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://yunpengtai.top/posts/diving-in-distributed-training/"},"publisher":{"@type":"Organization","name":"Tai's Blog","logo":{"@type":"ImageObject","url":"https://yunpengtai.top/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://yunpengtai.top accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://yunpengtai.top/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://yunpengtai.top/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://yunpengtai.top/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://yunpengtai.top/friends/ title=Friends><span>Friends</span></a></li><li><a href=https://yunpengtai.top/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://yunpengtai.top>Home</a>&nbsp;»&nbsp;<a href=https://yunpengtai.top/posts/>Posts</a></div><h1 class=post-title>Diving in distributed training in PyTorch</h1><div class=post-meta><span title='2022-11-20 21:37:00 +0800 CST'>November 20, 2022</span>&nbsp;·&nbsp;5363 words</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%b9%b6%e8%a1%8c%e5%8c%96%e7%9a%84%e5%8e%9f%e5%9b%a0 aria-label=并行化的原因>并行化的原因</a></li><li><a href=#data-parallel aria-label="Data Parallel">Data Parallel</a><ul><li><a href=#%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86 aria-label=实现原理>实现原理</a></li><li><a href=#%e4%bb%a3%e7%a0%81%e4%bd%bf%e7%94%a8 aria-label=代码使用>代码使用</a></li><li><a href=#%e6%98%be%e5%ad%98%e4%b8%8d%e5%9d%87%e5%8c%80 aria-label=显存不均匀>显存不均匀</a></li><li><a href=#%e4%bc%98%e7%bc%ba%e7%82%b9 aria-label=优缺点>优缺点</a></li></ul></li><li><a href=#ddp aria-label=DDP>DDP</a><ul><li><a href=#%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86-1 aria-label=实现原理>实现原理</a></li><li><a href=#%e4%bb%a3%e7%a0%81%e4%bd%bf%e7%94%a8-1 aria-label=代码使用>代码使用</a></li><li><a href=#%e4%bc%98%e7%bc%ba%e7%82%b9-1 aria-label=优缺点>优缺点</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><p>鉴于网上此类教程有不少模糊不清，对原理不得其法，代码也难跑通，故而花了几天细究了一下相关原理和实现，欢迎批评指正！</p><div class="notice notice-tip"><div class=notice-title><svg xmlns="http://www.w3.org/2000/svg" class="icon notice-icon" viewBox="0 0 512 512" fill="hsl(140, 65%, 65%)"><path d="M504 256A248 248 0 118 256a248 248 0 01496 0zM227 387l184-184c7-6 7-16 0-22l-22-23c-7-6-17-6-23 0L216 308l-70-70c-6-6-16-6-23 0l-22 23c-7 6-7 16 0 22l104 104c6 7 16 7 22 0z"/></svg></div><p>关于此部分的代码，可以去<a href=https://github.com/sherlcok314159/dl-tools>这里</a>查看</p></div><p>在开始前，我需要特别致谢一下一位挚友，他送了我双显卡的机器来赞助我做个人研究，否则多卡的相关实验就得付费在云平台上跑了，感谢好朋友一路以来的支持，这份友谊值得一辈子铭记！这篇文章作为礼物赠与挚友。</p><h2 id=并行化的原因>并行化的原因<a hidden class=anchor aria-hidden=true href=#并行化的原因>#</a></h2><p>我们在两种情况下进行并行化训练：</p><ol><li><strong>模型一张卡放不下</strong>：我们需要将模型不同的结构放置到不同的GPU上运行，这种情况叫ModelParallel(MP)</li><li><strong>单卡batch size过小</strong>：有些时候数据的最大长度调的比较高（e.g., 512），可用的bs就很小，较小的bs会导致收敛不稳定，因而将数据分发到多个GPU上进行并行训练，这种情况叫DataParallel(DP)。当然，DP肯定还可以加速训练，常见于大模型的训练中</li></ol><p>这里只讲一下DP在pytorch中的原理和相关实现，即DataParallel和DistributedParallel</p><h2 id=data-parallel>Data Parallel<a hidden class=anchor aria-hidden=true href=#data-parallel>#</a></h2><h3 id=实现原理>实现原理<a hidden class=anchor aria-hidden=true href=#实现原理>#</a></h3><p>实现就是循环往复一个过程：数据分发，模型复制，各自前向传播，汇聚输出，计算损失，梯度回传，梯度汇聚更新，可以参见<a href=2022-07-30-Tips-for-Training-Neural-Networks>下图</a></p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/cGkHbLx8S7jlpOd.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/cGkHbLx8S7jlpOd.png#center width=450 height=350></figure></a><p>pytorch中部分关键<a href="https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html?highlight=dataparallel">源码</a>截取如下：</p><p><details><summary markdown=span>data_parallel源码</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>data_parallel</span><span class=p>(</span>
</span></span><span class=line><span class=cl>	<span class=n>module</span><span class=p>,</span>
</span></span><span class=line><span class=cl>	<span class=nb>input</span><span class=p>,</span>
</span></span><span class=line><span class=cl>	<span class=n>device_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>	<span class=n>output_device</span><span class=o>=</span><span class=kc>None</span>
</span></span><span class=line><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>device_ids</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>module</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>output_device</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>output_device</span> <span class=o>=</span> <span class=n>device_ids</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 复制模型</span>
</span></span><span class=line><span class=cl>    <span class=n>replicas</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>parallel</span><span class=o>.</span><span class=n>replicate</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 拆分数据</span>
</span></span><span class=line><span class=cl>    <span class=n>inputs</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>parallel</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>replicas</span> <span class=o>=</span> <span class=n>replicas</span><span class=p>[:</span><span class=nb>len</span><span class=p>(</span><span class=n>inputs</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 各自前向传播</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>parallel</span><span class=o>.</span><span class=n>parallel_apply</span><span class=p>(</span><span class=n>replicas</span><span class=p>,</span> <span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 汇聚输出</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>nn</span><span class=o>.</span><span class=n>parallel</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>output_device</span><span class=p>)</span>
</span></span></code></pre></div></details></p><h3 id=代码使用>代码使用<a hidden class=anchor aria-hidden=true href=#代码使用>#</a></h3><div class="notice notice-info"><div class=notice-title><svg xmlns="http://www.w3.org/2000/svg" class="icon notice-icon" viewBox="0 0 512 512" fill="hsl(30, 80%, 70%)"><path d="M256 8a248 248 0 100 496 248 248 0 000-496zm0 110a42 42 0 110 84 42 42 0 010-84zm56 254c0 7-5 12-12 12h-88c-7 0-12-5-12-12v-24c0-7 5-12 12-12h12v-64h-12c-7 0-12-5-12-12v-24c0-7 5-12 12-12h64c7 0 12 5 12 12v1e2h12c7 0 12 5 12 12v24z"/></svg></div><p>因为运行时会将数据平均拆分到GPU上，所以我们准备数据的时候， batch size = per_gpu_batch_size * n_gpus</p></div><p>同时，需要注意主GPU需要进行汇聚等操作，因而需要比单卡运行时「多留出一些空间」</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=c1># device_ids默认所有可使用的设备</span>
</span></span><span class=line><span class=cl><span class=c1># output_device默认cuda:0</span>
</span></span><span class=line><span class=cl><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                      <span class=n>output_device</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># input_var can be on any device, including CPU</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>net</span><span class=p>(</span><span class=n>input_var</span><span class=p>)</span>
</span></span></code></pre></div><p>接下来看个更详细的<a href=https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html>例子</a>，需要注意的是被DP包裹之后涉及到模型相关的，需要调用DP.module，比如「加载模型」</p><p><details><summary markdown=span>data_parallel示例</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Model</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Our model</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_size</span><span class=p>,</span> <span class=n>output_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>Model</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># for convenience</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_size</span><span class=p>,</span> <span class=n>output_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=nb>input</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\t</span><span class=s2>In Model: input size&#34;</span><span class=p>,</span> <span class=nb>input</span><span class=o>.</span><span class=n>size</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>              <span class=s2>&#34;output size&#34;</span><span class=p>,</span> <span class=n>output</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>bs</span><span class=p>,</span> <span class=n>input_size</span><span class=p>,</span> <span class=n>output_size</span> <span class=o>=</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=c1># define inputs</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>((</span><span class=n>bs</span><span class=p>,</span> <span class=n>input_size</span><span class=p>))</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Model</span><span class=p>(</span><span class=n>input_size</span><span class=p>,</span> <span class=n>output_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Let&#39;s use&#34;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>(),</span> <span class=s2>&#34;GPUs!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># dim = 0 [6, xxx] -&gt; [2, ...], [2, ...], [2, ...] on 3 GPUs</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 先DataParallel，再cuda</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Outside: input size&#34;</span><span class=p>,</span> <span class=n>inputs</span><span class=o>.</span><span class=n>size</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>	  <span class=s2>&#34;output_size&#34;</span><span class=p>,</span> <span class=n>outputs</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=c1># assume 2 GPUS are available</span>
</span></span><span class=line><span class=cl><span class=c1># Let&#39;s use 2 GPUs!</span>
</span></span><span class=line><span class=cl><span class=c1>#    In Model: input size torch.Size([3, 8]) output size torch.Size([3, 10])</span>
</span></span><span class=line><span class=cl><span class=c1>#    In Model: input size torch.Size([3, 8]) output size torch.Size([3, 10])</span>
</span></span><span class=line><span class=cl><span class=c1># Outside: input size torch.Size([6, 8]) output_size torch.Size([6, 10])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># save the model</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span> <span class=n>PATH</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># load again</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>PATH</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=c1># do anything you want</span>
</span></span></code></pre></div></details></p><p>如果经常使用huggingface，这里有两个误区需要小心：</p><p><details><summary markdown=span>data_parallel两个误区</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># data parallel object has no save_pretrained</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>xxx</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>PATH</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>NEW_PATH</span><span class=p>)</span> <span class=c1># error</span>
</span></span><span class=line><span class=cl><span class=c1># 因为model被DP wrap了，得先取出模型 #</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>NEW_PATH</span><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># HF实现貌似是返回N个loss（N为GPU数量）</span>
</span></span><span class=line><span class=cl><span class=c1># 然后对N个loss取mean</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>loss</span><span class=p>,</span> <span class=n>logits</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>loss</span><span class=p>,</span> <span class=n>outputs</span><span class=o>.</span><span class=n>logits</span>
</span></span><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>loss</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 返回的logits是汇聚后的</span>
</span></span><span class=line><span class=cl><span class=c1># HF实现和我们手动算loss有细微差异</span>
</span></span><span class=line><span class=cl><span class=c1># 手动算略好于HF</span>
</span></span><span class=line><span class=cl><span class=n>loss2</span> <span class=o>=</span> <span class=n>loss_fct</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=n>loss</span> <span class=o>!=</span> <span class=n>loss2</span>
</span></span><span class=line><span class=cl><span class=kc>True</span>
</span></span></code></pre></div></details></p><h3 id=显存不均匀>显存不均匀<a hidden class=anchor aria-hidden=true href=#显存不均匀>#</a></h3><p>了解前面的原理后，就会明白为什么会显存不均匀。因为GPU0比其他GPU多了汇聚的工作，得留一些显存，而其他GPU显然是不需要的。那么，解决方案就是让其他GPU的batch size开大点，GPU0维持原状，即不按照默认实现的平分数据</p><p>首先参考<a href=https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html>这里</a>我们继承原来的DataParallel，这里我们给定第一个GPU的bs就可以，这个是实际的bs而不是乘上梯度后的。假如你想要总的bs为64，梯度累积为2，一共2张GPU，而一张最多只能18，那么保险一点GPU0设置为14，GPU1是18，也就是说你DataLoader每个batch大小是32，gpu0_bsz=14</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>BalancedDataParallel</span><span class=p>(</span><span class=n>DataParallel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>gpu0_bsz</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gpu0_bsz</span> <span class=o>=</span> <span class=n>gpu0_bsz</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span></code></pre></div><p>核心代码就在于我们重新分配chunk_sizes，实现思路就是将总的减去第一个GPU的再除以剩下的设备，源码的话有些死板，用的时候不妨参考我的：</p><p><details><summary markdown=span>我修改后的scatter</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>scatter</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>kwargs</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 不同于源码，获取batch size更加灵活</span>
</span></span><span class=line><span class=cl>    <span class=c1># 支持只有kwargs的情况，如model(**inputs)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>bsz</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=n>kwargs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>bsz</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>kwargs</span><span class=o>.</span><span class=n>values</span><span class=p>())[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;You must pass inputs to the model!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_dev</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>gpu0_bsz</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gpu0_bsz</span>
</span></span><span class=line><span class=cl>    <span class=c1># 除第一块之外每块GPU的bsz</span>
</span></span><span class=line><span class=cl>    <span class=n>bsz_unit</span> <span class=o>=</span> <span class=p>(</span><span class=n>bsz</span> <span class=o>-</span> <span class=n>gpu0_bsz</span><span class=p>)</span> <span class=o>//</span> <span class=p>(</span><span class=n>num_dev</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>gpu0_bsz</span> <span class=o>&lt;</span> <span class=n>bsz_unit</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># adapt the chunk sizes</span>
</span></span><span class=line><span class=cl>        <span class=n>chunk_sizes</span> <span class=o>=</span> <span class=p>[</span><span class=n>gpu0_bsz</span><span class=p>]</span> <span class=o>+</span> <span class=p>[</span><span class=n>bsz_unit</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>num_dev</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>delta</span> <span class=o>=</span> <span class=n>bsz</span> <span class=o>-</span> <span class=nb>sum</span><span class=p>(</span><span class=n>chunk_sizes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 补足偏移量</span>
</span></span><span class=line><span class=cl>        <span class=c1># 会有显存溢出的风险，因而最好给定的bsz是可以整除的</span>
</span></span><span class=line><span class=cl>        <span class=c1># e.g., 总的=52 =&gt; bsz_0=16, bsz_1=bsz_2=18</span>
</span></span><span class=line><span class=cl>        <span class=c1># 总的=53 =&gt; bsz_0=16, bsz_1=19, bsz_2=18</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>delta</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>chunk_sizes</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>gpu0_bsz</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>chunk_sizes</span> <span class=o>=</span> <span class=n>chunk_sizes</span><span class=p>[</span><span class=mi>1</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>kwargs</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>scatter_kwargs</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>kwargs</span><span class=p>,</span> <span class=n>device_ids</span><span class=p>,</span> <span class=n>chunk_sizes</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>dim</span><span class=p>)</span>
</span></span></code></pre></div></details></p><h3 id=优缺点>优缺点<a hidden class=anchor aria-hidden=true href=#优缺点>#</a></h3><ul><li>优点：便于操作，理解简单</li><li>缺点：GPU分配不均匀；每次更新完都得销毁<strong>线程</strong>（运行程序后会有一个进程，一个进程可以有很多个线程）重新复制模型，因而速度慢</li></ul><h2 id=ddp>DDP<a hidden class=anchor aria-hidden=true href=#ddp>#</a></h2><h3 id=实现原理-1>实现原理<a hidden class=anchor aria-hidden=true href=#实现原理-1>#</a></h3><ol><li>与DataParallel不同的是，Distributed Data Parallel会开设多个进程而非线程，进程数 = GPU数，每个进程都可以独立进行训练，也就是说代码的所有部分都会被每个进程同步调用，如果你某个地方print张量，你会发现device的差异</li><li>sampler会将数据按照进程数切分，<strong>确保不同进程的数据不同</strong></li><li>每个进程独立进行前向训练</li><li>每个进程利用Ring All-Reduce进行通信，将梯度信息进行聚合</li><li>每个进程同步更新模型参数，进行新一轮训练</li></ol><p>如何确保数据不同呢？</p><p><details><summary markdown=span>DistributedSampler的源码</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 判断数据集长度是否可以整除GPU数</span>
</span></span><span class=line><span class=cl><span class=c1># 如果不能，选择舍弃还是补全，进而决定总数</span>
</span></span><span class=line><span class=cl><span class=c1># If the dataset length is evenly divisible by # of replicas</span>
</span></span><span class=line><span class=cl><span class=c1># then there is no need to drop any data, since the dataset</span>
</span></span><span class=line><span class=cl><span class=c1># will be split equally.</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>drop_last</span> <span class=ow>and</span>
</span></span><span class=line><span class=cl>	<span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span> <span class=o>%</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=c1># num_replicas = num_gpus</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>num_samples</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>((</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span> <span class=o>-</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span><span class=p>)</span> <span class=o>/</span><span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>num_samples</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span> <span class=o>/</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>total_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_samples</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 根据是否shuffle来创建indices</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>shuffle</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># deterministically shuffle based on epoch and seed</span>
</span></span><span class=line><span class=cl>    <span class=n>g</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>Generator</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>g</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>seed</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>epoch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randperm</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>),</span> <span class=n>generator</span><span class=o>=</span><span class=n>g</span><span class=p>)</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataset</span><span class=p>)))</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>drop_last</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># add extra samples to make it evenly divisible</span>
</span></span><span class=line><span class=cl>    <span class=n>padding_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>total_size</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>padding_size</span> <span class=o>&lt;=</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 不够就按indices顺序加</span>
</span></span><span class=line><span class=cl>        <span class=c1># e.g., indices为[0, 1, 2, 3 ...]，而padding_size为4</span>
</span></span><span class=line><span class=cl>        <span class=c1># 加好之后的indices[..., 0, 1, 2, 3]</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>+=</span> <span class=n>indices</span><span class=p>[:</span><span class=n>padding_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>+=</span> <span class=p>(</span><span class=n>indices</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>padding_size</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)))[:</span><span class=n>padding_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># remove tail of data to make it evenly divisible.</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=n>indices</span><span class=p>[:</span><span class=bp>self</span><span class=o>.</span><span class=n>total_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>total_size</span>
</span></span><span class=line><span class=cl><span class=c1># subsample</span>
</span></span><span class=line><span class=cl><span class=c1># rank代表进程id</span>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=n>indices</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=p>:</span><span class=bp>self</span><span class=o>.</span><span class=n>total_size</span><span class=p>:</span><span class=bp>self</span><span class=o>.</span><span class=n>num_replicas</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=nb>iter</span><span class=p>(</span><span class=n>indices</span><span class=p>)</span>
</span></span></code></pre></div></details></p><p>接下来用<strong>Ring All-Reduce</strong>可以降低通信成本</p><p>首先将每块GPU上的梯度拆分成四个部分\(1\)，比如\(g_0 = [a_0; b_0; c_0; d_0]\)，此部分原理主要参考<a href="https://www.youtube.com/watch?v=rj-hjS5L8Bw">王老师</a></p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/q72OKSHhmuXYWvN.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/q72OKSHhmuXYWvN.png#center width=450 height=250></figure></a><p>所有GPU的传播都是<strong>同步</strong>进行的，传播的规律有两条：</p><ol><li>只与自己「下一个位置」的GPU进行通信，比如0 > 1，3 > 0</li><li>四个部分，哪块GPU上占的多，就由该块GPU往它下一个传，初始从主节点传播，即GPU0，你可以想象跟接力一样，a传b，b负责传给c</li></ol><p>第一次传播如下：</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/MNWF2dtB7wOsIoK.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/MNWF2dtB7wOsIoK.png#center width=450 height=250></figure></a><p>那么结果就是：</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/qj1VHUlSDiXstTz.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/qj1VHUlSDiXstTz.png#center width=450 height=250></figure></a><p>那么，按照谁多谁往下传的原则，此时应该是GPU1往GPU2传a0和a1，GPU2往GPU3传b1和b2，以此类推</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/4mfqWSMjO3IokxH.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/4mfqWSMjO3IokxH.png#center width=450 height=250></figure></a><p>接下来再传播就会有GPU3 a的部分全有，GPU0上b的部分全有等，就再往下传</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/v3jzp4PIQSYERZy.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/v3jzp4PIQSYERZy.png#center width=450 height=250></figure></a><p>再来几遍便可以使得每块GPU上都获得了来自其他GPU的梯度啦</p><script src=https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script>
<a data-fancybox=gallery href=https://s2.loli.net/2022/11/20/OA2Ikvxt59YGiVH.png><figure class=align-center><img loading=lazy src=https://s2.loli.net/2022/11/20/OA2Ikvxt59YGiVH.png#center width=450 height=250></figure></a><h3 id=代码使用-1>代码使用<a hidden class=anchor aria-hidden=true href=#代码使用-1>#</a></h3><p>第一个是后端的<a href=https://pytorch.org/docs/stable/distributed.html#backends>选择</a>，即数据传输协议，当使用CPU时可以选择gloo或mpi，而GPU则可以是nccl</p><p>接下来是一些参数的<a href=https://stackoverflow.com/questions/58271635/in-distributed-computing-what-are-world-size-and-rank>解释</a></p><table><thead><tr><th style=text-align:left>Arg</th><th style=text-align:center>Meaning</th></tr></thead><tbody><tr><td style=text-align:left>group</td><td style=text-align:center>一次发起的所有进程构成一个group，除非想更精细通信，创建new_group</td></tr><tr><td style=text-align:left>world_size</td><td style=text-align:center>一个group中进程数目，即为GPU的数量</td></tr><tr><td style=text-align:left>rank</td><td style=text-align:center>进程id，主节点rank=0，其他的在0和world_size-1之间</td></tr><tr><td style=text-align:left>local_rank</td><td style=text-align:center>进程在本地节点/机器的id</td></tr></tbody></table><p>举个例子，假如你有两台服务器（又被称为node），每台服务器有4张GPU，那么，world_size即为8，rank=[0, 1, 2, 3, 4, 5, 6, 7], 每个服务器上的进程的local_rank为[0, 1, 2, 3]</p><p>然后是<strong>初始化方法</strong>的选择，有TCP和共享文件两种，一般指定rank=0为master节点</p><p>TCP显而易见是通过网络进行传输，需要指定主节点的ip（可以为主节点实际IP，或者是localhost）和空闲的端口</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.distributed</span> <span class=k>as</span> <span class=nn>dist</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span><span class=n>backend</span><span class=p>,</span> <span class=n>init_method</span><span class=o>=</span><span class=s1>&#39;tcp://ip:port&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=o>=</span><span class=n>world_size</span><span class=p>)</span>
</span></span></code></pre></div><p>共享文件的话需要手动删除上次启动时残留的文件，加上官方有一堆警告，还是建议使用TCP</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span><span class=n>backend</span><span class=p>,</span> <span class=n>init_method</span><span class=o>=</span><span class=s1>&#39;file://Path&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=o>=</span><span class=n>world_size</span><span class=p>)</span>
</span></span></code></pre></div><p>这里先讲用launch初始化的方法，关于torch.multiprocessing留到后面讲</p><p>在启动后，rank和world_size都会自动被DDP写入环境中，可以提前准备好参数类，如<code>argparse</code>这种</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>args</span><span class=o>.</span><span class=n>rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;RANK&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>args</span><span class=o>.</span><span class=n>world_size</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;WORLD_SIZE&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>args</span><span class=o>.</span><span class=n>local_rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;LOCAL_RANK&#39;</span><span class=p>])</span>
</span></span></code></pre></div><p>首先，在使用distributed包的任何其他函数之前，按照tcp方法进行初始化，需要注意的是需要手动指定一共可用的设备CUDA_VISIBLE_DEVICES</p><p><details><summary markdown=span>launch初始化</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>dist_setup_launch</span><span class=p>(</span><span class=n>args</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># tell DDP available devices [NECESSARY]</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>args</span><span class=o>.</span><span class=n>devices</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>.</span><span class=n>rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;RANK&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>.</span><span class=n>world_size</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;WORLD_SIZE&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span><span class=o>.</span><span class=n>local_rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;LOCAL_RANK&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>backend</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>args</span><span class=o>.</span><span class=n>init_method</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>rank</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>rank</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>world_size</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># this is optional, otherwise you may need to specify the</span>
</span></span><span class=line><span class=cl>    <span class=c1># device when you move something e.g., model.cuda(1)</span>
</span></span><span class=line><span class=cl>    <span class=c1># or model.to(args.rank)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Setting device makes things easy: model.cuda()</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>set_device</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>rank</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;The Current Rank is </span><span class=si>%d</span><span class=s1> | The Total Ranks are </span><span class=si>%d</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>          <span class=o>%</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>rank</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>world_size</span><span class=p>))</span>
</span></span></code></pre></div></details></p><p>接下来创建DistributedSampler，是否pin_memory，根据你本机的内存决定。pin_memory的意思是提前在内存中申请一部分专门存放Tensor。假如说你内存比较小，就会跟虚拟内存，即硬盘进行交换，这样转义到GPU上会比内存直接到GPU耗时。</p><p>因而，如果你的内存比较大，可以设置为True；然而，如果开了导致卡顿的情况，建议关闭</p><p><details><summary markdown=span>加载数据</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>DataLoader</span><span class=p>,</span> <span class=n>DistributedSampler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train_sampler</span> <span class=o>=</span> <span class=n>DistributedSampler</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>,</span> <span class=n>seed</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>train_dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>shuffle</span><span class=o>=</span><span class=p>(</span><span class=n>train_sampler</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                              <span class=n>batch_size</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>per_gpu_train_bs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>num_workers</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>num_workers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>sampler</span><span class=o>=</span><span class=n>train_sampler</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>eval_sampler</span> <span class=o>=</span> <span class=n>DistributedSampler</span><span class=p>(</span><span class=n>eval_dataset</span><span class=p>,</span> <span class=n>seed</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>eval_dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>eval_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=n>batch_size</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>per_gpu_eval_bs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=n>num_workers</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>num_workers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=n>sampler</span><span class=o>=</span><span class=n>eval_sampler</span><span class=p>)</span>
</span></span></code></pre></div></details></p><p>然后加载模型，跟DataParallel不同的是需要提前放置到cuda上，还记得上面关于设置cuda_device的语句嘛，因为设置好之后每个进程只能看见一个GPU，所以直接model.cuda()，不需要指定device</p><p>同时，我们必须给DDP提示目前是哪个rank</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.nn.parallel</span> <span class=kn>import</span> <span class=n>DistributedDataParallel</span> <span class=k>as</span> <span class=n>DDP</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># tell DDP which rank</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>DDP</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>find_unused_parameters</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=p>[</span><span class=n>rank</span><span class=p>])</span>
</span></span></code></pre></div><p>注意，当模型带有Batch Norm时：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=n>args</span><span class=o>.</span><span class=n>syncBN</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>nn</span><span class=o>.</span><span class=n>SyncBatchNorm</span><span class=o>.</span><span class=n>convert_sync_batchnorm</span><span class=p>(</span><span class=n>model</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span></code></pre></div><p>现在说训练的事情，每个epoch开始训练的时候，记得用sampler的set_epoch，这样使得每个epoch打乱顺序是不一致的</p><p>关于梯度回传和参数更新，跟正常情况无异</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># record epochs</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataloader</span><span class=o>.</span><span class=n>sampler</span><span class=o>.</span><span class=n>set_epoch</span><span class=p>(</span><span class=n>epoch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>loss_fct</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span></code></pre></div><p>这里有一点需要小心，这个loss是各个进程的loss之和，如果想要存储每个step平均损失，可以进行all_reduce操作，进行平均，不妨看官方的小例子来理解下：</p><p><details><summary markdown=span>reduce相关代码</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=c1># All tensors below are of torch.int64 type.</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=c1># We have 2 process groups, 2 ranks.</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>rank</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span> <span class=c1># Rank 0</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span> <span class=c1># Rank 1</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>dist</span><span class=o>.</span><span class=n>all_reduce</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>op</span><span class=o>=</span><span class=n>ReduceOp</span><span class=o>.</span><span class=n>SUM</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>4</span><span class=p>,</span> <span class=mi>6</span><span class=p>])</span> <span class=c1># Rank 0</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>4</span><span class=p>,</span> <span class=mi>6</span><span class=p>])</span> <span class=c1># Rank 1</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@torch.no_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>reduce_value</span><span class=p>(</span><span class=n>value</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>world_size</span> <span class=o>=</span> <span class=n>get_world_size</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>world_size</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>:</span>  <span class=c1># 单GPU的情况</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>value</span>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>all_reduce</span><span class=p>(</span><span class=n>value</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>average</span><span class=p>:</span>
</span></span><span class=line><span class=cl>	    <span class=n>value</span> <span class=o>/=</span> <span class=n>world_size</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>value</span>
</span></span></code></pre></div></details></p><p>看到这，肯定有小伙伴要问，那这样我们是不是得先求平均损失再回传梯度啊，不用，因为，当我们回传loss后，参照<a href=https://discuss.pytorch.org/t/average-loss-in-dp-and-ddp/93306/4>这里</a>，DDP会自动对所有梯度进行平均，也就是说回传后我们更新的梯度和DP或者单卡同样batch训练都是一致的</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>loss_fct</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># 注意在backward后面</span>
</span></span><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>reduce_value</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mean_loss</span> <span class=o>=</span> <span class=p>(</span><span class=n>step</span> <span class=o>*</span> <span class=n>mean_loss</span> <span class=o>+</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>())</span> <span class=o>/</span> <span class=p>(</span><span class=n>step</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><p>还有个注意点就是学习率的变化，这个是和batch size息息相关的，如果batch扩充了几倍，也就是说step比之前少了很多，还采用同一个学习率，肯定会出问题的，这里，我们进行线性增大，感兴趣可以看<a href=https://discuss.pytorch.org/t/average-loss-in-dp-and-ddp/93306/4>讨论</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>N</span> <span class=o>=</span> <span class=n>world_size</span>
</span></span><span class=line><span class=cl><span class=n>lr</span> <span class=o>=</span> <span class=n>args</span><span class=o>.</span><span class=n>lr</span> <span class=o>*</span> <span class=n>N</span>
</span></span></code></pre></div><p>肯定有人说，诶，你线性增大肯定不能保证梯度的variance一致了，正确的应该是正比于\(\sqrt{N}\)，关于这个的讨论不妨参考<a href=https://github.com/Lightning-AI/lightning/discussions/3706>这里</a></p><p>接下来，细心的同学肯定好奇了，如果验证集也切分了，metric怎么计算呢？此时就需要咱们把每个进程得到的预测情况集合起来，t就是一个我们需要gather的张量，最后将每个进程中的t按照第一维度拼接，先看官方小例子来理解all_gather</p><p><details><summary markdown=span>gather相关代码</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=c1># All tensors below are of torch.int64 dtype.</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=c1># We have 2 process groups, 2 ranks.</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor_list</span> <span class=o>=</span> <span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>)]</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor_list</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>tensor</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]),</span> <span class=n>tensor</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>])]</span> <span class=c1># Rank 0 and 1</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>rank</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span> <span class=c1># Rank 0</span>
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])</span> <span class=c1># Rank 1</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>dist</span><span class=o>.</span><span class=n>all_gather</span><span class=p>(</span><span class=n>tensor_list</span><span class=p>,</span> <span class=n>tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>tensor_list</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]),</span> <span class=n>tensor</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])]</span> <span class=c1># Rank 0</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]),</span> <span class=n>tensor</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>])]</span> <span class=c1># Rank 1</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>sync_across_gpus</span><span class=p>(</span><span class=n>t</span><span class=p>,</span> <span class=n>world_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>gather_t_tensor</span> <span class=o>=</span> <span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>t</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span>
</span></span><span class=line><span class=cl>                       <span class=nb>range</span><span class=p>(</span><span class=n>world_size</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>all_gather</span><span class=p>(</span><span class=n>gather_t_tensor</span><span class=p>,</span> <span class=n>t</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>gather_t_tensor</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span></code></pre></div></details></p><p>可以简单参考我前面提供的源码的evaluate部分，我们首先将预测和标签比对，把结果为bool的张量存储下来，最终gather求和取平均。</p><p>这里还有个有趣的地方，tensor默认的类型可能是int，bool型的res拼接后自动转为0和1了，另外bool型的张量是不支持gather的</p><p><details><summary markdown=span>eval函数</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>eval</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([])</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>step</span><span class=p>,</span> <span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>res</span> <span class=o>=</span> <span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>results</span><span class=p>,</span> <span class=n>res</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>sync_across_gpus</span><span class=p>(</span><span class=n>results</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mean_acc</span> <span class=o>=</span> <span class=p>(</span><span class=n>results</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>))</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mean_acc</span>
</span></span></code></pre></div></details></p><p>模型保存，参考部分官方<a href=https://pytorch.org/tutorials/intermediate/ddp_tutorial.html>教程</a>，我们只需要在主进程保存模型即可，注意，这里是被DDP包裹后的，DDP并没有state_dict，这里barrier的目的是为了让其他进程等待主进程保存模型，以防不同步</p><p><details><summary markdown=span>保存模型</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>save_checkpoint</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>is_main_process</span><span class=p>(</span><span class=n>rank</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    	<span class=c1># All processes should see same parameters as they all</span>
</span></span><span class=line><span class=cl>        <span class=c1># start from same random parameters and gradients are</span>
</span></span><span class=line><span class=cl>        <span class=c1># synchronized in backward passes.</span>
</span></span><span class=line><span class=cl>        <span class=c1># Therefore, saving it in one process is sufficient.</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span> <span class=n>path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Use a barrier() to keep process 1 waiting for process 0</span>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>barrier</span><span class=p>()</span>
</span></span></code></pre></div></details></p><p>加载的时候别忘了map_location，我们一开始会保存模型至主进程，这样就会导致cuda:0显存被占据，我们需要将模型remap到其他设备</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_checkpoint</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># remap the model from cuda:0 to other devices</span>
</span></span><span class=line><span class=cl>    <span class=n>map_location</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;cuda:</span><span class=si>%d</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=mi>0</span><span class=p>:</span> <span class=s1>&#39;cuda:</span><span class=si>%d</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=n>rank</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=n>map_location</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p>运行结束后记得销毁进程：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>cleanup</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>dist</span><span class=o>.</span><span class=n>destroy_process_group</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cleanup</span><span class=p>()</span>
</span></span></code></pre></div><p>然后如何启动呢？在终端输入下列命令「单机多卡」</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python -m torch.distributed.launch --nproc_per_node<span class=o>=</span>NUM_GPUS
</span></span><span class=line><span class=cl>           main.py <span class=o>(</span>--arg1 --arg2 --arg3 and all other
</span></span><span class=line><span class=cl>           arguments of your training script<span class=o>)</span>
</span></span></code></pre></div><p>目前torch 1.10以后更推荐用run</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>distributed</span><span class=o>.</span><span class=n>launch</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>distributed</span><span class=o>.</span><span class=n>run</span> <span class=o>/</span> <span class=n>torchrun</span>
</span></span></code></pre></div><p>多机多卡是这样的：</p><p><details><summary markdown=span>多机多卡启动</summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 第一个节点启动</span>
</span></span><span class=line><span class=cl>python -m torch.distributed.launch <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nproc_per_node<span class=o>=</span>NUM_GPUS <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nnodes<span class=o>=</span><span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --node_rank<span class=o>=</span><span class=m>0</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --master_addr<span class=o>=</span><span class=s2>&#34;192.168.1.1&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --master_port<span class=o>=</span><span class=m>1234</span> main.py
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 第二个节点启动</span>
</span></span><span class=line><span class=cl>python -m torch.distributed.launch <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nproc_per_node<span class=o>=</span>NUM_GPUS <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --nnodes<span class=o>=</span><span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --node_rank<span class=o>=</span><span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --master_addr<span class=o>=</span><span class=s2>&#34;192.168.1.1&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --master_port<span class=o>=</span><span class=m>1234</span> main.py
</span></span></code></pre></div></details></p><p>第二个方法就是利用torch的多线程包</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.multiprocessing</span> <span class=k>as</span> <span class=nn>mp</span>
</span></span><span class=line><span class=cl><span class=c1># rank mp会自动填入</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>arg1</span><span class=p>,</span> <span class=o>...</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>pass</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>mp</span><span class=o>.</span><span class=n>spawn</span><span class=p>(</span><span class=n>main</span><span class=p>,</span> <span class=n>nprocs</span><span class=o>=</span><span class=n>TOTAL_GPUS</span><span class=p>,</span> <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=n>arg1</span><span class=p>,</span> <span class=o>...</span><span class=p>))</span>
</span></span></code></pre></div><p>这种运行的时候就跟正常的python文件一致：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python main.py
</span></span></code></pre></div><h3 id=优缺点-1>优缺点<a hidden class=anchor aria-hidden=true href=#优缺点-1>#</a></h3><ul><li><strong>优点</strong>： 相比于DP而言，不需要反复创建和销毁线程；Ring-AllReduce算法提高通信效率；模型同步方便</li><li><strong>缺点</strong>：操作起来可能有些复杂，一般可满足需求的可先试试看DataParallel</li></ul></div><blockquote class=quote-copyright>Author: Yunpengtai<p>Link: https://yunpengtai.top/posts/diving-in-distributed-training/<p>License: CC BY-NC-SA 4.0. You must provide a link to the source.</blockquote><footer class=post-footer><ul class=post-tags><li><a href=https://yunpengtai.top/tags/multi-gpus/>Multi-gpus</a></li><li><a href=https://yunpengtai.top/tags/dataparallel/>DataParallel</a></li><li><a href=https://yunpengtai.top/tags/distributed-training/>Distributed Training</a></li></ul><nav class=paginav><a class=prev href=https://yunpengtai.top/posts/hello-world/><span class=title>« Prev</span><br><span>新的主题</span></a>
<a class=next href=https://yunpengtai.top/posts/back-propagation/><span class=title>Next »</span><br><span>Going Deeper into Back-propagation</span></a></nav></footer><link rel=stylesheet href=https://unpkg.com/katex@0.15.3/dist/katex.min.css><script defer src=https://unpkg.com/katex@0.15.3/dist/katex.min.js></script>
<link href=https://comment.yunpengtai.top/dist/Artalk.css rel=stylesheet><script src=https://comment.yunpengtai.top/dist/Artalk.js></script>
<script src=https://unpkg.com/@artalk/plugin-katex/dist/artalk-plugin-katex.js></script><div id=Comments></div><script>Artalk.init({el:"#Comments",pageKey:"",pageTitle:"",server:"https://comment.yunpengtai.top",site:"Tai's Blog"})</script></article></main><footer class=footer><span>&copy; 2024 <a href=https://yunpengtai.top>Tai's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/sherlcok314159/MyPaperMod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>(function(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}})()</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("//cdn.bootcss.com/pangu/4.0.7/pangu.min.js",function(){pangu.spacingPage()})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>