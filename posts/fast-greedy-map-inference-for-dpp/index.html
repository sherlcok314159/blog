<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Fast Greedy MAP Inference for DPP | Tai's Blog</title><meta name=keywords content="retrieval,probabilistic models"><meta name=description content="问题 先规定一些术语：记选中元素构成的集合为$\mathcal{S}$，未选中构成的元素记为$\mathcal{R}$，$\mathbf{L}"><meta name=author content><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="eAKh7zszsOtNde1wyq_sUo95ZPH4zTTJhR-_ol4VWDs"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yunpengtai.top/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yunpengtai.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yunpengtai.top/favicon-32x32.png><link rel=apple-touch-icon href=https://yunpengtai.top/apple-touch-icon.png><link rel=mask-icon href=https://yunpengtai.top/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script>MathJax={loader:{load:["[tex]/boldsymbol"]},tex:{tags:"all",inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,packages:{"[+]":["boldsymbol"]}}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js integrity="sha256-kbAFUDxdHwlYv01zraGjvjNZayxKtdoiJ38bDTFJtaQ=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/pseudocode@2.4.1/build/pseudocode.min.css><script src=https://cdn.jsdelivr.net/npm/pseudocode@2.4.1/build/pseudocode.min.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y3CX2RWEDY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Y3CX2RWEDY",{anonymize_ip:!1})}</script><meta property="og:title" content="Fast Greedy MAP Inference for DPP"><meta property="og:description" content="问题 先规定一些术语：记选中元素构成的集合为$\mathcal{S}$，未选中构成的元素记为$\mathcal{R}$，$\mathbf{L}"><meta property="og:type" content="article"><meta property="og:url" content="https://yunpengtai.top/posts/fast-greedy-map-inference-for-dpp/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-16T10:50:00+08:00"><meta property="article:modified_time" content="2023-05-16T10:50:00+08:00"><meta property="og:site_name" content="Tai's Blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://yunpengtai.top/posts/"},{"@type":"ListItem","position":3,"name":"Fast Greedy MAP Inference for DPP","item":"https://yunpengtai.top/posts/fast-greedy-map-inference-for-dpp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Fast Greedy MAP Inference for DPP","name":"Fast Greedy MAP Inference for DPP","description":"问题 先规定一些术语：记选中元素构成的集合为$\\mathcal{S}$，未选中构成的元素记为$\\mathcal{R}$，$\\mathbf{L}","keywords":["retrieval","probabilistic models"],"articleBody":"问题 先规定一些术语：记选中元素构成的集合为$\\mathcal{S}$，未选中构成的元素记为$\\mathcal{R}$，$\\mathbf{L}$是核矩阵（核函数是内积），$\\mathbf{L_{V}}$是由集合$S$的元素构成的子矩阵\n在Determinatal Point Process中我们提到在大小为$n$的集合里去挑选$k$个物品构成集合$S$, 使得$\\det(\\mathbf{L}_{\\mathbf{V}})$最大便是我们的目标，然而，怎么去里面挑选$\\mathbf{V}$却是 NP-Hard 问题，为此，Chen et al., 2018 提出了一篇比较巧妙的贪婪算法作为近似解，并且整个算法的复杂仅有$\\mathcal{O}(nk^{2})$\n暴力求解 我们人为规定了要选择$k$个，这相当于是一种前验分布，那么 k-DPP 其实就是最大化后验概率（MAP）的一种，每一步的目标就是选择会让新矩阵的行列式变得最大的元素\n$$ j = \\mathop{ \\arg \\max}_{i \\in \\mathcal{R}} \\log \\det(\\mathbf{L}_{\\mathcal{S} \\cup \\{i\\}}) - \\log \\det(\\mathbf{L}_{\\mathcal{S}}) $$\n对于一个$n\\times n$的方阵而言，求它的行列式需要$\\mathcal{O}(n^{3})$（每一轮消元的复杂度是$\\mathcal{O}(n^{2})$，而要进行$n-1$轮消元）\n这里的话，每次要对$\\mathcal{R}$所有的元素求一次行列式，而行列式的为$\\mathcal{O}(|\\mathcal{S}|^{3})$，同时需要选$k$个，复杂度变为了$\\mathcal{O}(|\\mathcal{S}|^{3} \\cdot |\\mathcal{R}| \\cdot k)$，即为$\\mathcal{O}(nk^{4})$，暴力求解的话复杂度很大，此时原作者便提出了利用 Cholesky 分解的方式来进行求解，巧妙地将复杂度降到了$\\mathcal{O}(nk^{2})$\nCholesky 分解 $\\mathbf{L}_{\\mathcal{S}}$是对称半正定矩阵，证明如下：$\\forall \\boldsymbol{z} \\in \\mathbb{R}^{n}$\n$$ \\boldsymbol{z}^{\\top}\\mathbf{L}_{\\mathcal{S}}\\boldsymbol{z} = \\boldsymbol{z}^{\\top} \\mathbf{V}^{\\top}\\mathbf{V} \\boldsymbol{z} = \\|\\mathbf{V}\\boldsymbol{z}\\|_{2}^{2} \\geq 0 \\quad \\blacksquare $$\n那么$\\mathbf{L}_{\\mathcal{S}}$存在 Cholesky 分解，即$\\mathbf{L}_{\\mathcal{S}}=\\mathbf{U}\\mathbf{U}^{\\top}$，这里的$\\mathbf{U}$是大小为$|\\mathcal{S}|\\times|\\mathcal{S}|$的下三角矩阵，$\\mathbf{L}_{\\mathcal{S}\\cup \\{ i \\}}$比$\\mathbf{L}_{\\mathcal{S}}$多了一行和一列，即为：\n$$ \\mathbf{L}_{\\mathcal{S}\\cup \\{ i \\}} = \\begin{bmatrix} \\mathbf{L}_{\\mathcal{S} } \u0026 \\boldsymbol{u}_{i} \\\\ \\boldsymbol{u}_{i}^{\\top} \u0026 \\boldsymbol{u}_{i}^{\\top}\\boldsymbol{u} \\end{bmatrix} $$\n而这里默认每个向量是经过归一化的，即$\\boldsymbol{u}_{i}^{\\top}\\boldsymbol{u}=1$，那么$\\mathbf{L}_{\\mathcal{S}\\cup \\{ i \\}}$的 Cholesky 分解即为下式，其中$\\boldsymbol{c}_{i} \\in \\mathbb{R}^{1 \\times |\\mathcal{S}| }, d_{i} \\geq 0$：\n$$ \\mathbf{L}_{\\mathcal{S}\\cup \\{ i \\}} = \\begin{bmatrix} \\mathbf{U} \u0026 \\boldsymbol{0} \\\\ \\boldsymbol{c}_{i} \u0026 d_{i} \\end{bmatrix}\\begin{bmatrix} \\mathbf{U} \u0026 \\boldsymbol{0} \\\\ \\boldsymbol{c}_{i} \u0026 d_{i} \\end{bmatrix}^{\\top} $$\n结合上面两式：\n$$ \\mathbf{L}_{\\mathcal{S}\\cup \\{ i \\}} = \\begin{bmatrix} \\mathbf{L}_{\\mathcal{S} } \u0026 \\boldsymbol{u}_{i} \\\\ \\boldsymbol{u}_{i}^{\\top} \u0026 \\boldsymbol{u}_{i}^{\\top}\\boldsymbol{u} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{U}\\mathbf{U}^{\\top} \u0026 \\mathbf{U}\\boldsymbol{c}_{i}^{\\top} \\\\ \\boldsymbol{c}_{i}\\mathbf{U}^{\\top} \u0026 \\boldsymbol{c}_{i}\\boldsymbol{c}_{i}^{\\top} + d_{i}^{2} \\end{bmatrix} $$\n可得：\n$$ \\boldsymbol{u}_{i} = \\mathbf{U}\\boldsymbol{c}_{i}^{\\top}, 1 = \\boldsymbol{c}_{i}\\boldsymbol{c}_{i}^{\\top} + d_{i}^{2} $$\n那么：\n$$ \\det(\\mathbf{L}_{\\mathcal{S}\\cup \\{ i \\}}) = \\det \\bigg(\\begin{bmatrix} \\mathbf{U} \u0026 \\boldsymbol{0} \\\\ \\boldsymbol{c}_{i} \u0026 d_{i} \\end{bmatrix}\\begin{bmatrix} \\mathbf{U} \u0026 \\boldsymbol{0} \\\\ \\boldsymbol{c}_{i} \u0026 d_{i} \\end{bmatrix}^{\\top}\\bigg) = \\det(\\mathbf{U}\\mathbf{U}^{\\top})\\cdot d_{i}^{2}= \\det(\\mathbf{L}_{\\mathcal{S}}) \\cdot d_{i}^{2} $$\n这样我们一开始的优化目标就可以简化为：\n$$ j = \\mathop{\\arg \\max}_{i \\in \\mathcal{R}} \\log(d_{i}^{2}) $$\n接下来，当我们得到$d_j$时，便可以算出$c_{j}$，那么添加$j$之后的新集合$\\mathcal{S}'$的 Cholesky 分解便可以求得：\n$$ \\mathbf{L}_{\\mathcal{S}'} = \\begin{bmatrix} \\mathbf{U} \u0026 \\boldsymbol{0} \\\\ \\boldsymbol{c}_{j} \u0026 d_{j} \\end{bmatrix}\\begin{bmatrix} \\mathbf{U} \u0026 \\boldsymbol{0} \\\\ \\boldsymbol{c}_{j} \u0026 d_{j} \\end{bmatrix}^{\\top} $$\n增量更新 接下来便是重头戏，这一轮我们已经得到了最好的$d_{j}$了，下一轮我们怎么求出最大的$d_{i}$呢？\n可以利用之前求出的$c_{i}, d_{i}$来获取当前的$c_{i}', d_{i}'$，这便是论文的核心：增量更新\n在我们选择了$j$后，$c_{i}$多了一个元素，不妨记$\\boldsymbol{c}_{i}' = [\\boldsymbol{c}_{i}, {e}_{i}]$，回忆上面的式子：\n$$ \\mathbf{L}_{\\mathcal{S}\\cup \\{ i \\}} = \\begin{bmatrix} \\mathbf{L}_{\\mathcal{S} } \u0026 \\boldsymbol{u}_{i} \\\\ \\boldsymbol{u}_{i}^{\\top} \u0026 \\boldsymbol{u}_{i}^{\\top}\\boldsymbol{u} \\end{bmatrix} = \\begin{bmatrix} \\mathbf{U}\\mathbf{U}^{\\top} \u0026 \\mathbf{U}\\boldsymbol{c}_{i}^{\\top} \\\\ \\boldsymbol{c}_{i}\\mathbf{U}^{\\top} \u0026 \\boldsymbol{c}_{i}\\boldsymbol{c}_{i}^{\\top} + d_{i}^{2} \\end{bmatrix} $$\n也就是说，其中$\\boldsymbol{u}_{i}$就是第$i$个元素与集合$\\mathcal{S}$对应向量做内积的结果\n$$ \\boldsymbol{u}_{i} = \\mathbf{U}\\boldsymbol{c}_{i}^{\\top} $$\n那么，类比一下，$\\mathbf{U}_{j}$是$\\mathbf{L}_{\\mathcal{S}'}$的 Cholesky 分解\n$$ \\underbrace{\\begin{bmatrix} \\mathbf{U} \u0026 \\boldsymbol{0} \\\\ \\boldsymbol{c}_{j} \u0026 d_{j} \\end{bmatrix}}_{\\mathbf{U}_{j}} \\boldsymbol{c}_{i}'^{\\top} = \\boldsymbol{u}_{i}' = \\begin{bmatrix} \\boldsymbol{u}_{i} \\\\ \\mathbf{L}_{ji} \\end{bmatrix} $$\n继而：\n$$ \\langle \\boldsymbol{c}_{j},\\boldsymbol{c} _{i}\\rangle + d_{j}e_{i} = \\mathbf{L}_{ji} \\implies e_{i} = \\frac{\\mathbf{L}_{ji}-\\langle \\boldsymbol{c}_{j},\\boldsymbol{c}_{i} \\rangle }{d_{j}} $$\n求出$e_{i}$之后，我们便可以求出$d_{i}'$：\n$$ d_{i}'^{2} = 1 - \\|\\boldsymbol{c}_{i}'\\|_{2}^{2} =\\underbrace{ 1- \\|\\boldsymbol{c}_{i}\\|_{2}^{2} }_{ {\\color{blue}d_{i}^{2} }} - e_{i}^{2} = d_{i}^{2} - e_{i}^{2} $$\n流程 \\begin{algorithm} \\caption{Fast Greedy MAP Inference} \\begin{algorithmic} \\STATE $\\textbf{Input: }$ Kernel Matrix $\\mathbf{L}$, stopping criteria \\STATE $\\textbf{Initialize: } \\boldsymbol{c}_i = [], d_i^2=\\mathbf{L}_{ii}, j = \\mathop{\\arg \\max}_{i \\in \\mathcal{R}} \\log (d_i^2), \\mathcal{S}=\\{j\\}$ \\WHILE{stopping criteria not satisfied} \\FOR{$i \\in \\mathcal{R}$} \\STATE $e_i = (\\mathbf{L}_{ji}-\\langle \\boldsymbol{c}_{j},\\boldsymbol{c} _{i}\\rangle)/d_j$ \\STATE $\\boldsymbol{c}_i = [\\boldsymbol{c}_i, e_i], d_i^2=d_i^2-e_i^2$ \\ENDFOR \\STATE $j = \\mathop{\\arg \\max}_{i \\in \\mathcal{R}} \\log(d_i^2), \\mathcal{S}= \\mathcal{S} \\cup \\{j\\}$ \\ENDWHILE \\STATE $\\textbf{Output: } \\mathcal{S}$ \\end{algorithmic} \\end{algorithm} 那我们来分析一下复杂度，每选一个$j$需要进行$|\\mathcal{R}| \\cdot |\\mathcal{S}|$次操作，而$|\\mathcal{R}|\\leq n, |\\mathcal{S}| \\leq k$，也就是$\\mathcal{O}(nk)$，得进行$k$次迭代，那么总的复杂度即为$\\mathcal{O}(nk^{2})$，由$\\mathcal{O}(nk^{4})$降到$\\mathcal{O}(nk^{2})$，是不错的进步\n代码 熟悉了整个流程之后，代码想必也是呼之欲出了\nimport math import numpy as np def fast_map_dpp(kernel_matrix, max_length): cis = np.zeros((max_length, kernel_matrix.shape[0])) di2s = np.copy(np.diag(kernel_matrix)) selected = np.argmax(di2s) selected_items = [selected] while len(selected_items) \u003c max_length: idx = len(selected_items) - 1 ci_optimal = cis[:idx, selected] di_optimal = math.sqrt(di2s[selected]) elements = kernel_matrix[selected, :] eis = (elements - ci_optimal @ cis[:idx, :]) / di_optimal cis[idx, :] = eis di2s -= np.square(eis) di2s[selected] = -np.inf selected = np.argmax(di2s) selected_items.append(selected) return selected_items 这里实现比较有趣的点就是，尽管伪代码中是$i \\in \\mathcal{R}$，这里其实是全部算了，但他对已选的进行了后处理，置之为$-\\infty$\n接下来我们实操一下，从句子对匹配BQ Corpus（Bank Question Corpus）拿出一条来看一下效果，首先是将其用预训练模型转换为表征向量，接着进行归一化操作，为了更好地看出DPP的效果，我们先用最大化内积来召回50个样本，再用DPP从这里召回10个具有多样性的样本：\n原句：我现在申请微粒货？ ['我现在申请微粒货？', '申请微贷粒', '申请微贷粒', '我想申请微粒贷', '可以么想申请微粒贷', '微粒貸申请', '微粒貸申请', '如何申请微粒', '我现在需要申请', '我可以申请微粒贷吗', '怎么申请微粒货', '微粒貸申请', '如何申请微粒', '我可以申请微粒贷吗', '什么情况下才能申请微粒', '我要求申请', '开通微粒货', '开通微粒貨', '开通微粒货', '可以申请开通吗', '开通微粒货', '开通微粒货', '怎么申请微粒货', '申请贷款', '如何申请微粒贷', '怎么申请微粒货', '开通微粒貨', '如何申请微粒', '想办理微粒贷业务', '申请贷款', '可以申请开通吗', '我要微粒贷', '我要微粒贷', '可以么想申请微粒贷', '开通微米粒', '想开通', '我要微粒贷', '如何申请微粒', '想开通', '开通微粒貨', '开通粒微贷', '何时才能申请啊', '现在想获取资格', '怎么申请微粒货', '开通申请', '开通', '开通', '你好我申请借款', '开通微'] 可以看到有不少重复且意思一样的样本：\n接着看DPP的效果：\n['我现在申请微粒货？', '开通', '何时才能申请啊', '怎么申请微粒货', '你好我申请借款', '现在想获取资格', '我可以申请微粒贷吗', '我要微粒贷', '微粒貸申请', '什么情况下才能申请微粒'] 可以发现里面没有重复的情况，而且语义具备多样性，而值得注意的是，此时就有一些和我们的原句意思不匹配的情况，在应用时可以自定义新的 kernel，让它同时注意相似性和多样性；或者可以对 DPP 的样本进行后处理等\nSliding Window 当$|\\mathcal{S}|$相当大的时候，就会有相似的样本开始出现，即超平行体会开始坍缩，不妨我们将$\\mathcal{S}$缩小成一个滑动窗口$\\mathcal{W}$，我们仅仅需要保证窗口内的样本具备多样性即可，即：\n$$ j = \\mathop{\\arg \\max}_{i \\in \\mathcal{R}} \\log \\det(\\mathbf{L}_{\\mathcal{W} \\cup \\{ i \\}}) - \\log \\det(\\mathbf{L}_{\\mathcal{W}}) $$\n推荐系统中有短序推荐（Short Sequence Recommendation）的说法，推荐的时候只考虑用户短期内的一些行为，而长序推荐会考虑一个较长时间跨度来进行推荐\nWindow size 的选择也是比较重要的，不妨看一些 demo：\n$$ \\begin{array}{ccc} \\hline \\text{窗口} \u0026 \\# \\text{不同样本} \u0026 \\# \\text{重复样本} \\\\ \\hline 2 \u0026 2 \u0026 0 \\\\ 3 \u0026 2 \u0026 1 \\\\ 4 \u0026 1 \u0026 2 \\\\ 5 \u0026 1 \u0026 1 \\\\ 7 \u0026 1 \u0026 0 \\\\ 9 \u0026 0 \u0026 0 \\\\ \\hline \\end{array}\\notag $$\n如果我们的目的是为了通过 Sliding Window 获取与直接 DPP 召回不一样的结果，窗口的大小要适当地小一些，然而小了导致看的范围小了，很有可能最后结果出现重复的情况，最好是将窗口设置到召回样本数目的$20\\% \\sim 30\\%$\n同时，为了防止样本重复，可以多召回一些，比较直觉的做法可以再加上一个 window 的大小，然后去重：\nw/o window ['开通', '怎么申请微粒货', '何时才能申请啊', '现在想获取资格', '我要微粒贷', '微粒貸申请', '我可以申请微粒贷吗', '什么情况下才能申请微粒', '你好我申请借款', '我现在申请微粒货？'] w/ window ['开通', '开通申请', '怎么申请微粒货', '何时才能申请啊', '现在想获取资格', '我要微粒贷', '我可以申请微粒贷吗', '可以申请开通吗', '如何申请微粒', '我现在申请微粒货？'] 可以看到会有 3 个不一样的样本，还是比较有效的\n","wordCount":"4326","inLanguage":"en","datePublished":"2023-05-16T10:50:00+08:00","dateModified":"2023-05-16T10:50:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://yunpengtai.top/posts/fast-greedy-map-inference-for-dpp/"},"publisher":{"@type":"Organization","name":"Tai's Blog","logo":{"@type":"ImageObject","url":"https://yunpengtai.top/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://yunpengtai.top accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://yunpengtai.top/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://yunpengtai.top/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://yunpengtai.top/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://yunpengtai.top/friends/ title=Friends><span>Friends</span></a></li><li><a href=https://yunpengtai.top/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://yunpengtai.top>Home</a>&nbsp;»&nbsp;<a href=https://yunpengtai.top/posts/>Posts</a></div><h1 class=post-title>Fast Greedy MAP Inference for DPP</h1><div class=post-meta><span title='2023-05-16 10:50:00 +0800 CST'>May 16, 2023</span>&nbsp;·&nbsp;4326 words</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e9%97%ae%e9%a2%98 aria-label=问题>问题</a></li><li><a href=#%e6%9a%b4%e5%8a%9b%e6%b1%82%e8%a7%a3 aria-label=暴力求解>暴力求解</a></li><li><a href=#cholesky-%e5%88%86%e8%a7%a3 aria-label="Cholesky 分解">Cholesky 分解</a></li><li><a href=#%e5%a2%9e%e9%87%8f%e6%9b%b4%e6%96%b0 aria-label=增量更新>增量更新</a></li><li><a href=#%e6%b5%81%e7%a8%8b aria-label=流程>流程</a></li><li><a href=#%e4%bb%a3%e7%a0%81 aria-label=代码>代码</a></li><li><a href=#sliding-window aria-label="Sliding Window">Sliding Window</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=问题>问题<a hidden class=anchor aria-hidden=true href=#问题>#</a></h2><p>先规定一些术语：记选中元素构成的集合为<code>$\mathcal{S}$</code>，未选中构成的元素记为<code>$\mathcal{R}$</code>，<code>$\mathbf{L}$</code>是核矩阵（核函数是内积），<code>$\mathbf{L_{V}}$</code>是由集合<code>$S$</code>的元素构成的子矩阵</p><p>在<a href=https://yunpengtai.top/posts/determinantal-point-process/>Determinatal Point Process</a>中我们提到在大小为<code>$n$</code>的集合里去挑选<code>$k$</code>个物品构成集合<code>$S$</code>, 使得<code>$\det(\mathbf{L}_{\mathbf{V}})$</code>最大便是我们的目标，然而，怎么去里面挑选<code>$\mathbf{V}$</code>却是 NP-Hard 问题，为此，Chen et al., 2018 提出了一篇比较巧妙的贪婪算法作为近似解，并且整个算法的复杂仅有<code>$\mathcal{O}(nk^{2})$</code></p><h2 id=暴力求解>暴力求解<a hidden class=anchor aria-hidden=true href=#暴力求解>#</a></h2><p>我们人为规定了要选择<code>$k$</code>个，这相当于是一种前验分布，那么 k-DPP 其实就是最大化后验概率（MAP）的一种，每一步的目标就是选择会让新矩阵的行列式变得最大的元素</p><p><code>$$ j = \mathop{ \arg \max}_{i \in \mathcal{R}} \log \det(\mathbf{L}_{\mathcal{S} \cup \{i\}}) - \log \det(\mathbf{L}_{\mathcal{S}}) $$</code></p><p>对于一个<code>$n\times n$</code>的方阵而言，求它的行列式需要<code>$\mathcal{O}(n^{3})$</code>（每一轮消元的复杂度是<code>$\mathcal{O}(n^{2})$</code>，而要进行<code>$n-1$</code>轮消元）</p><p>这里的话，每次要对<code>$\mathcal{R}$</code>所有的元素求一次行列式，而行列式的为<code>$\mathcal{O}(|\mathcal{S}|^{3})$</code>，同时需要选<code>$k$</code>个，复杂度变为了<code>$\mathcal{O}(|\mathcal{S}|^{3} \cdot |\mathcal{R}| \cdot k)$</code>，即为<code>$\mathcal{O}(nk^{4})$</code>，暴力求解的话复杂度很大，此时原作者便提出了利用 Cholesky 分解的方式来进行求解，巧妙地将复杂度降到了<code>$\mathcal{O}(nk^{2})$</code></p><h2 id=cholesky-分解>Cholesky 分解<a hidden class=anchor aria-hidden=true href=#cholesky-分解>#</a></h2><p><code>$\mathbf{L}_{\mathcal{S}}$</code>是对称半正定矩阵，证明如下：<code>$\forall \boldsymbol{z} \in \mathbb{R}^{n}$</code></p><p><code>$$ \boldsymbol{z}^{\top}\mathbf{L}_{\mathcal{S}}\boldsymbol{z} = \boldsymbol{z}^{\top} \mathbf{V}^{\top}\mathbf{V} \boldsymbol{z} = \|\mathbf{V}\boldsymbol{z}\|_{2}^{2} \geq 0 \quad \blacksquare $$</code></p><p>那么<code>$\mathbf{L}_{\mathcal{S}}$</code>存在 Cholesky 分解，即<code>$\mathbf{L}_{\mathcal{S}}=\mathbf{U}\mathbf{U}^{\top}$</code>，这里的<code>$\mathbf{U}$</code>是大小为<code>$|\mathcal{S}|\times|\mathcal{S}|$</code>的下三角矩阵，<code>$\mathbf{L}_{\mathcal{S}\cup \{ i \}}$</code>比<code>$\mathbf{L}_{\mathcal{S}}$</code>多了一行和一列，即为：</p><p><code>$$ \mathbf{L}_{\mathcal{S}\cup \{ i \}} = \begin{bmatrix} \mathbf{L}_{\mathcal{S} } & \boldsymbol{u}_{i} \\ \boldsymbol{u}_{i}^{\top} & \boldsymbol{u}_{i}^{\top}\boldsymbol{u} \end{bmatrix} $$</code></p><p>而这里默认每个向量是经过归一化的，即<code>$\boldsymbol{u}_{i}^{\top}\boldsymbol{u}=1$</code>，那么<code>$\mathbf{L}_{\mathcal{S}\cup \{ i \}}$</code>的 Cholesky 分解即为下式，其中<code>$\boldsymbol{c}_{i} \in \mathbb{R}^{1 \times |\mathcal{S}| }, d_{i} \geq 0$</code>：</p><p><code>$$ \mathbf{L}_{\mathcal{S}\cup \{ i \}} = \begin{bmatrix} \mathbf{U} & \boldsymbol{0} \\ \boldsymbol{c}_{i} & d_{i} \end{bmatrix}\begin{bmatrix} \mathbf{U} & \boldsymbol{0} \\ \boldsymbol{c}_{i} & d_{i} \end{bmatrix}^{\top} $$</code></p><p>结合上面两式：</p><p><code>$$ \mathbf{L}_{\mathcal{S}\cup \{ i \}} = \begin{bmatrix} \mathbf{L}_{\mathcal{S} } & \boldsymbol{u}_{i} \\ \boldsymbol{u}_{i}^{\top} & \boldsymbol{u}_{i}^{\top}\boldsymbol{u} \end{bmatrix} = \begin{bmatrix} \mathbf{U}\mathbf{U}^{\top} & \mathbf{U}\boldsymbol{c}_{i}^{\top} \\ \boldsymbol{c}_{i}\mathbf{U}^{\top} & \boldsymbol{c}_{i}\boldsymbol{c}_{i}^{\top} + d_{i}^{2} \end{bmatrix} $$</code></p><p>可得：</p><p><code>$$ \boldsymbol{u}_{i} = \mathbf{U}\boldsymbol{c}_{i}^{\top}, 1 = \boldsymbol{c}_{i}\boldsymbol{c}_{i}^{\top} + d_{i}^{2} $$</code></p><p>那么：</p><p><code>$$ \det(\mathbf{L}_{\mathcal{S}\cup \{ i \}}) = \det \bigg(\begin{bmatrix} \mathbf{U} & \boldsymbol{0} \\ \boldsymbol{c}_{i} & d_{i} \end{bmatrix}\begin{bmatrix} \mathbf{U} & \boldsymbol{0} \\ \boldsymbol{c}_{i} & d_{i} \end{bmatrix}^{\top}\bigg) = \det(\mathbf{U}\mathbf{U}^{\top})\cdot d_{i}^{2}= \det(\mathbf{L}_{\mathcal{S}}) \cdot d_{i}^{2} $$</code></p><p>这样我们一开始的优化目标就可以简化为：</p><p><code>$$ j = \mathop{\arg \max}_{i \in \mathcal{R}} \log(d_{i}^{2}) $$</code></p><p>接下来，当我们得到<code>$d_j$</code>时，便可以算出<code>$c_{j}$</code>，那么添加<code>$j$</code>之后的新集合<code>$\mathcal{S}'$</code>的 Cholesky 分解便可以求得：</p><p><code>$$ \mathbf{L}_{\mathcal{S}'} = \begin{bmatrix} \mathbf{U} & \boldsymbol{0} \\ \boldsymbol{c}_{j} & d_{j} \end{bmatrix}\begin{bmatrix} \mathbf{U} & \boldsymbol{0} \\ \boldsymbol{c}_{j} & d_{j} \end{bmatrix}^{\top} $$</code></p><h2 id=增量更新>增量更新<a hidden class=anchor aria-hidden=true href=#增量更新>#</a></h2><p>接下来便是重头戏，这一轮我们已经得到了最好的<code>$d_{j}$</code>了，下一轮我们怎么求出最大的<code>$d_{i}$</code>呢？</p><p>可以利用之前求出的<code>$c_{i}, d_{i}$</code>来获取当前的<code>$c_{i}', d_{i}'$</code>，这便是论文的核心：增量更新</p><p>在我们选择了<code>$j$</code>后，<code>$c_{i}$</code>多了一个元素，不妨记<code>$\boldsymbol{c}_{i}' = [\boldsymbol{c}_{i}, {e}_{i}]$</code>，回忆上面的式子：</p><p><code>$$ \mathbf{L}_{\mathcal{S}\cup \{ i \}} = \begin{bmatrix} \mathbf{L}_{\mathcal{S} } & \boldsymbol{u}_{i} \\ \boldsymbol{u}_{i}^{\top} & \boldsymbol{u}_{i}^{\top}\boldsymbol{u} \end{bmatrix} = \begin{bmatrix} \mathbf{U}\mathbf{U}^{\top} & \mathbf{U}\boldsymbol{c}_{i}^{\top} \\ \boldsymbol{c}_{i}\mathbf{U}^{\top} & \boldsymbol{c}_{i}\boldsymbol{c}_{i}^{\top} + d_{i}^{2} \end{bmatrix} $$</code></p><p>也就是说，其中<code>$\boldsymbol{u}_{i}$</code>就是第<code>$i$</code>个元素与集合<code>$\mathcal{S}$</code>对应向量做内积的结果</p><p><code>$$ \boldsymbol{u}_{i} = \mathbf{U}\boldsymbol{c}_{i}^{\top} $$</code></p><p>那么，类比一下，<code>$\mathbf{U}_{j}$</code>是<code>$\mathbf{L}_{\mathcal{S}'}$</code>的 Cholesky 分解</p><p><code>$$ \underbrace{\begin{bmatrix} \mathbf{U} & \boldsymbol{0} \\ \boldsymbol{c}_{j} & d_{j} \end{bmatrix}}_{\mathbf{U}_{j}} \boldsymbol{c}_{i}'^{\top} = \boldsymbol{u}_{i}' = \begin{bmatrix} \boldsymbol{u}_{i} \\ \mathbf{L}_{ji} \end{bmatrix} $$</code></p><p>继而：</p><p><code>$$ \langle \boldsymbol{c}_{j},\boldsymbol{c} _{i}\rangle + d_{j}e_{i} = \mathbf{L}_{ji} \implies e_{i} = \frac{\mathbf{L}_{ji}-\langle \boldsymbol{c}_{j},\boldsymbol{c}_{i} \rangle }{d_{j}} $$</code></p><p>求出<code>$e_{i}$</code>之后，我们便可以求出<code>$d_{i}'$</code>：</p><p><code>$$ d_{i}'^{2} = 1 - \|\boldsymbol{c}_{i}'\|_{2}^{2} =\underbrace{ 1- \|\boldsymbol{c}_{i}\|_{2}^{2} }_{ {\color{blue}d_{i}^{2} }} - e_{i}^{2} = d_{i}^{2} - e_{i}^{2} $$</code></p><h2 id=流程>流程<a hidden class=anchor aria-hidden=true href=#流程>#</a></h2><div><pre id=pseudocode display:hidden;>
    \begin{algorithm}
    \caption{Fast Greedy MAP Inference}
    \begin{algorithmic}
        \STATE $\textbf{Input: }$ Kernel Matrix $\mathbf{L}$, stopping criteria
        \STATE $\textbf{Initialize: } \boldsymbol{c}_i = [], d_i^2=\mathbf{L}_{ii}, j = \mathop{\arg \max}_{i \in \mathcal{R}} \log (d_i^2), \mathcal{S}=\{j\}$
        \WHILE{stopping criteria not satisfied}
        \FOR{$i \in \mathcal{R}$}
            \STATE $e_i = (\mathbf{L}_{ji}-\langle \boldsymbol{c}_{j},\boldsymbol{c} _{i}\rangle)/d_j$
            \STATE $\boldsymbol{c}_i = [\boldsymbol{c}_i, e_i], d_i^2=d_i^2-e_i^2$
        \ENDFOR
        \STATE $j = \mathop{\arg \max}_{i \in \mathcal{R}} \log(d_i^2), \mathcal{S}= \mathcal{S} \cup \{j\}$
        \ENDWHILE
        \STATE $\textbf{Output: } \mathcal{S}$
    \end{algorithmic}
    \end{algorithm}
</pre></div><p>那我们来分析一下复杂度，每选一个<code>$j$</code>需要进行<code>$|\mathcal{R}| \cdot |\mathcal{S}|$</code>次操作，而<code>$|\mathcal{R}|\leq n, |\mathcal{S}| \leq k$</code>，也就是<code>$\mathcal{O}(nk)$</code>，得进行<code>$k$</code>次迭代，那么总的复杂度即为<code>$\mathcal{O}(nk^{2})$</code>，由<code>$\mathcal{O}(nk^{4})$</code>降到<code>$\mathcal{O}(nk^{2})$</code>，是不错的进步</p><h2 id=代码>代码<a hidden class=anchor aria-hidden=true href=#代码>#</a></h2><p>熟悉了整个流程之后，代码想必也是呼之欲出了</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>math</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>fast_map_dpp</span><span class=p>(</span><span class=n>kernel_matrix</span><span class=p>,</span> <span class=n>max_length</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>cis</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>max_length</span><span class=p>,</span> <span class=n>kernel_matrix</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=n>di2s</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>diag</span><span class=p>(</span><span class=n>kernel_matrix</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>selected</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>di2s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>selected_items</span> <span class=o>=</span> <span class=p>[</span><span class=n>selected</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>selected_items</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>max_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>idx</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>selected_items</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=n>ci_optimal</span> <span class=o>=</span> <span class=n>cis</span><span class=p>[:</span><span class=n>idx</span><span class=p>,</span> <span class=n>selected</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>di_optimal</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>di2s</span><span class=p>[</span><span class=n>selected</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>elements</span> <span class=o>=</span> <span class=n>kernel_matrix</span><span class=p>[</span><span class=n>selected</span><span class=p>,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>        <span class=n>eis</span> <span class=o>=</span> <span class=p>(</span><span class=n>elements</span> <span class=o>-</span> <span class=n>ci_optimal</span> <span class=o>@</span> <span class=n>cis</span><span class=p>[:</span><span class=n>idx</span><span class=p>,</span> <span class=p>:])</span> <span class=o>/</span> <span class=n>di_optimal</span>
</span></span><span class=line><span class=cl>        <span class=n>cis</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=p>:]</span> <span class=o>=</span> <span class=n>eis</span>
</span></span><span class=line><span class=cl>        <span class=n>di2s</span> <span class=o>-=</span> <span class=n>np</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>eis</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>di2s</span><span class=p>[</span><span class=n>selected</span><span class=p>]</span> <span class=o>=</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>inf</span>
</span></span><span class=line><span class=cl>        <span class=n>selected</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>di2s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>selected_items</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>selected</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>selected_items</span>
</span></span></code></pre></div><p>这里实现比较有趣的点就是，尽管伪代码中是<code>$i \in \mathcal{R}$</code>，这里其实是全部算了，但他对已选的进行了后处理，置之为<code>$-\infty$</code></p><p>接下来我们实操一下，从句子对匹配BQ Corpus（Bank Question Corpus）拿出一条来看一下效果，首先是将其用预训练模型转换为表征向量，接着进行归一化操作，为了更好地看出DPP的效果，我们先用最大化内积来召回50个样本，再用DPP从这里召回10个具有多样性的样本：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>原句：我现在申请微粒货？
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[&#39;我现在申请微粒货？&#39;, &#39;申请微贷粒&#39;, &#39;申请微贷粒&#39;, &#39;我想申请微粒贷&#39;, &#39;可以么想申请微粒贷&#39;, 
</span></span><span class=line><span class=cl>&#39;微粒貸申请&#39;, &#39;微粒貸申请&#39;, &#39;如何申请微粒&#39;, &#39;我现在需要申请&#39;, &#39;我可以申请微粒贷吗&#39;, 
</span></span><span class=line><span class=cl>&#39;怎么申请微粒货&#39;, &#39;微粒貸申请&#39;, &#39;如何申请微粒&#39;, &#39;我可以申请微粒贷吗&#39;, &#39;什么情况下才能申请微粒&#39;, 
</span></span><span class=line><span class=cl>&#39;我要求申请&#39;, &#39;开通微粒货&#39;, &#39;开通微粒貨&#39;, &#39;开通微粒货&#39;, &#39;可以申请开通吗&#39;, &#39;开通微粒货&#39;, 
</span></span><span class=line><span class=cl>&#39;开通微粒货&#39;, &#39;怎么申请微粒货&#39;, &#39;申请贷款&#39;, &#39;如何申请微粒贷&#39;, &#39;怎么申请微粒货&#39;, &#39;开通微粒貨&#39;, 
</span></span><span class=line><span class=cl>&#39;如何申请微粒&#39;, &#39;想办理微粒贷业务&#39;, &#39;申请贷款&#39;, &#39;可以申请开通吗&#39;, &#39;我要微粒贷&#39;, &#39;我要微粒贷&#39;, 
</span></span><span class=line><span class=cl>&#39;可以么想申请微粒贷&#39;, &#39;开通微米粒&#39;, &#39;想开通&#39;, &#39;我要微粒贷&#39;, &#39;如何申请微粒&#39;, &#39;想开通&#39;, &#39;开通微粒貨&#39;, 
</span></span><span class=line><span class=cl>&#39;开通粒微贷&#39;, &#39;何时才能申请啊&#39;, &#39;现在想获取资格&#39;, &#39;怎么申请微粒货&#39;, &#39;开通申请&#39;, &#39;开通&#39;, &#39;开通&#39;, &#39;你好我申请借款&#39;, &#39;开通微&#39;]
</span></span></code></pre></div><p>可以看到有不少重复且意思一样的样本：</p><p>接着看DPP的效果：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[&#39;我现在申请微粒货？&#39;, &#39;开通&#39;, &#39;何时才能申请啊&#39;, &#39;怎么申请微粒货&#39;, &#39;你好我申请借款&#39;, &#39;现在想获取资格&#39;,
</span></span><span class=line><span class=cl> &#39;我可以申请微粒贷吗&#39;, &#39;我要微粒贷&#39;, &#39;微粒貸申请&#39;, &#39;什么情况下才能申请微粒&#39;]
</span></span></code></pre></div><p>可以发现里面没有重复的情况，而且语义具备多样性，而值得注意的是，此时就有一些和我们的原句意思不匹配的情况，在应用时可以自定义新的 kernel，让它同时注意相似性和多样性；或者可以对 DPP 的样本进行后处理等</p><h2 id=sliding-window>Sliding Window<a hidden class=anchor aria-hidden=true href=#sliding-window>#</a></h2><p>当<code>$|\mathcal{S}|$</code>相当大的时候，就会有相似的样本开始出现，即超平行体会开始坍缩，不妨我们将$\mathcal{S}$缩小成一个滑动窗口$\mathcal{W}$，我们仅仅需要保证窗口内的样本具备多样性即可，即：</p><p><code>$$ j = \mathop{\arg \max}_{i \in \mathcal{R}} \log \det(\mathbf{L}_{\mathcal{W} \cup \{ i \}}) - \log \det(\mathbf{L}_{\mathcal{W}}) $$</code></p><p>推荐系统中有短序推荐（Short Sequence Recommendation）的说法，推荐的时候只考虑用户短期内的一些行为，而长序推荐会考虑一个较长时间跨度来进行推荐</p><p>Window size 的选择也是比较重要的，不妨看一些 demo：</p><p><code>$$ \begin{array}{ccc} \hline \text{窗口} & \# \text{不同样本} & \# \text{重复样本} \\ \hline 2 & 2 & 0 \\ 3 & 2 & 1 \\ 4 & 1 & 2 \\ 5 & 1 & 1 \\ 7 & 1 & 0 \\ 9 & 0 & 0 \\ \hline \end{array}\notag $$</code></p><p>如果我们的目的是为了通过 Sliding Window 获取与直接 DPP 召回不一样的结果，窗口的大小要适当地小一些，然而小了导致看的范围小了，很有可能最后结果出现重复的情况，最好是将窗口设置到召回样本数目的<code>$20\% \sim 30\%$</code></p><p>同时，为了防止样本重复，可以多召回一些，比较直觉的做法可以再加上一个 window 的大小，然后去重：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>w/o window
</span></span><span class=line><span class=cl>[&#39;开通&#39;, &#39;怎么申请微粒货&#39;, &#39;何时才能申请啊&#39;, &#39;现在想获取资格&#39;, &#39;我要微粒贷&#39;, &#39;微粒貸申请&#39;, 
</span></span><span class=line><span class=cl>&#39;我可以申请微粒贷吗&#39;, &#39;什么情况下才能申请微粒&#39;, &#39;你好我申请借款&#39;, &#39;我现在申请微粒货？&#39;]
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>w/ window
</span></span><span class=line><span class=cl>[&#39;开通&#39;, &#39;开通申请&#39;, &#39;怎么申请微粒货&#39;, &#39;何时才能申请啊&#39;, &#39;现在想获取资格&#39;, &#39;我要微粒贷&#39;, 
</span></span><span class=line><span class=cl>&#39;我可以申请微粒贷吗&#39;, &#39;可以申请开通吗&#39;, &#39;如何申请微粒&#39;, &#39;我现在申请微粒货？&#39;]
</span></span></code></pre></div><p>可以看到会有 3 个不一样的样本，还是比较有效的</p></div><blockquote class=quote-copyright>Author: Yunpengtai<p>Link: https://yunpengtai.top/posts/fast-greedy-map-inference-for-dpp/<p>License: CC BY-NC-SA 4.0. You must provide a link to the source.</blockquote><footer class=post-footer><ul class=post-tags><li><a href=https://yunpengtai.top/tags/retrieval/>retrieval</a></li><li><a href=https://yunpengtai.top/tags/probabilistic-models/>probabilistic models</a></li></ul><nav class=paginav><a class=prev href=https://yunpengtai.top/posts/noise-contrastive-estimation/><span class=title>« Prev</span><br><span>Noise Contrastive Estimation</span></a>
<a class=next href=https://yunpengtai.top/posts/determinantal-point-process/><span class=title>Next »</span><br><span>Determinantal Point Process</span></a></nav></footer><link rel=stylesheet href=https://unpkg.com/katex@0.16.7/dist/katex.min.css><script src=https://unpkg.com/katex@0.16.7/dist/katex.min.js></script>
<link href=https://cdn.jsdelivr.net/gh/sherlcok314159/artalk-assets@main/artalk.css rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/artalk/2.8.6/Artalk.js></script>
<script src=https://unpkg.com/@artalk/plugin-katex@latest/dist/artalk-plugin-katex.js></script><div id=Comments></div><script>Artalk.init({el:"#Comments",pageKey:"",pageTitle:"Fast Greedy MAP Inference for DPP",server:"https://comment.yunpengtai.top",site:"Tai's Blog"})</script></article></main><footer class=footer><span>&copy; 2024 <a href=https://yunpengtai.top>Tai's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/sherlcok314159/MyPaperMod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script type=text/javascript>(function(){let t={indentSize:"1.2em",commentDelimiter:"//",lineNumber:!1,lineNumberPunc:":",noEnd:!1,captionCount:void 0};pseudocode.renderElement(document.getElementById("pseudocode"),t)})(document)</script><script>(function(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}})()</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("//cdn.bootcss.com/pangu/4.0.7/pangu.min.js",function(){pangu.spacingPage()})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>