<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Numerical Stability | Tai's Blog</title><meta name=keywords content="training"><meta name=description content="Why å½“è®¡ç®—æ¶‰åŠåˆ°å®æ•°åŸŸæ—¶ï¼Œæ¯”å¦‚åœ†å‘¨ç‡çš„$\pi$ï¼Œå› ä¸ºå°æ•°éƒ¨åˆ†æ˜¯æ— ç©·çš„ï¼Œè®¡ç®—æœºæ˜¯æ— æ³•å‡†ç¡®è¡¨ç¤ºï¼Œå› è€Œåªä¼šç”¨è¿‘ä¼¼çš„å€¼è¿›è¡Œæ›¿ä»£ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œè¯¯å·®ç›¸å¯¹"><meta name=author content><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="eAKh7zszsOtNde1wyq_sUo95ZPH4zTTJhR-_ol4VWDs"><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=http://yunpengtai.top/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://yunpengtai.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://yunpengtai.top/favicon-32x32.png><link rel=apple-touch-icon href=http://yunpengtai.top/apple-touch-icon.png><link rel=mask-icon href=http://yunpengtai.top/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script>MathJax={loader:{load:["[tex]/boldsymbol"]},tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,tags:"all",packages:{"[+]":["boldsymbol"]}}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js integrity="sha256-kbAFUDxdHwlYv01zraGjvjNZayxKtdoiJ38bDTFJtaQ=" crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y3CX2RWEDY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-Y3CX2RWEDY",{anonymize_ip:!1})}</script><meta property="og:title" content="Numerical Stability"><meta property="og:description" content="Why å½“è®¡ç®—æ¶‰åŠåˆ°å®æ•°åŸŸæ—¶ï¼Œæ¯”å¦‚åœ†å‘¨ç‡çš„$\pi$ï¼Œå› ä¸ºå°æ•°éƒ¨åˆ†æ˜¯æ— ç©·çš„ï¼Œè®¡ç®—æœºæ˜¯æ— æ³•å‡†ç¡®è¡¨ç¤ºï¼Œå› è€Œåªä¼šç”¨è¿‘ä¼¼çš„å€¼è¿›è¡Œæ›¿ä»£ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œè¯¯å·®ç›¸å¯¹"><meta property="og:type" content="article"><meta property="og:url" content="http://yunpengtai.top/posts/numerical-stability/"><meta property="og:image" content="http://yunpengtai.top/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-06-25T21:10:00+08:00"><meta property="article:modified_time" content="2023-06-25T21:10:00+08:00"><meta property="og:site_name" content="Tai's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://yunpengtai.top/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Numerical Stability"><meta name=twitter:description content="Why å½“è®¡ç®—æ¶‰åŠåˆ°å®æ•°åŸŸæ—¶ï¼Œæ¯”å¦‚åœ†å‘¨ç‡çš„$\pi$ï¼Œå› ä¸ºå°æ•°éƒ¨åˆ†æ˜¯æ— ç©·çš„ï¼Œè®¡ç®—æœºæ˜¯æ— æ³•å‡†ç¡®è¡¨ç¤ºï¼Œå› è€Œåªä¼šç”¨è¿‘ä¼¼çš„å€¼è¿›è¡Œæ›¿ä»£ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œè¯¯å·®ç›¸å¯¹"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"http://yunpengtai.top/posts/"},{"@type":"ListItem","position":3,"name":"Numerical Stability","item":"http://yunpengtai.top/posts/numerical-stability/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Numerical Stability","name":"Numerical Stability","description":"Why å½“è®¡ç®—æ¶‰åŠåˆ°å®æ•°åŸŸæ—¶ï¼Œæ¯”å¦‚åœ†å‘¨ç‡çš„$\\pi$ï¼Œå› ä¸ºå°æ•°éƒ¨åˆ†æ˜¯æ— ç©·çš„ï¼Œè®¡ç®—æœºæ˜¯æ— æ³•å‡†ç¡®è¡¨ç¤ºï¼Œå› è€Œåªä¼šç”¨è¿‘ä¼¼çš„å€¼è¿›è¡Œæ›¿ä»£ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œè¯¯å·®ç›¸å¯¹","keywords":["training"],"articleBody":"Why å½“è®¡ç®—æ¶‰åŠåˆ°å®æ•°åŸŸæ—¶ï¼Œæ¯”å¦‚åœ†å‘¨ç‡çš„$\\pi$ï¼Œå› ä¸ºå°æ•°éƒ¨åˆ†æ˜¯æ— ç©·çš„ï¼Œè®¡ç®—æœºæ˜¯æ— æ³•å‡†ç¡®è¡¨ç¤ºï¼Œå› è€Œåªä¼šç”¨è¿‘ä¼¼çš„å€¼è¿›è¡Œæ›¿ä»£ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œè¯¯å·®ç›¸å¯¹è¾ƒå°å½±å“ä¸å¤§ï¼›ç„¶è€Œï¼Œå¦‚æœæ•°å€¼å¤§äºæŸä¸ªç‰¹å®šå€¼ä¹‹åå˜æˆäº†$\\inf$ï¼ˆæ•°å€¼ä¸Šæº¢ Overflow ï¼‰ï¼Œè¿˜æœ‰ä¸€ç§æƒ…å†µæ˜¯å½“æ•°å€¼ç‰¹åˆ«å°æ—¶ï¼Œä¼šè¢«è¿‘ä¼¼ä¸º$0$ï¼ˆæ•°å€¼ä¸‹æº¢ Underflowï¼‰ï¼Œè¿™ä¸¤ç§æƒ…å½¢è‹¥ç»§ç»­è®¡ç®—è¯¯å·®å°†ä¼šè¿›ä¸€æ­¥ç´¯ç§¯ï¼Œé‚£ä¹ˆå°±å¯èƒ½å¯¼è‡´åŸæœ¬ç†è®ºä¸Šæˆç«‹çš„åˆ°å®ç°æ—¶å°±ä¸è¡Œäº†ï¼Œæ­¤æ—¶å°±æœ‰å¿…è¦å¯¹æ•°å€¼ç¨³å®šæ€§è¿›è¡Œåˆ†æ\nä¸¾ä¸ªä¾‹å­ï¼š\nimport numpy a = np.array([65599.], dtype=np.float16) print(a) b = np.array([1e-10], dtype=np.float16) print(b) [inf] # Overflow [0.] # Underflow åŸºç¡€çŸ¥è¯† å†è¿›ä¸€æ­¥è§£é‡Šè§£å†³æ–¹æ³•æ—¶è¿˜æ˜¯å…ˆé“ºå«åŸºç¡€çŸ¥è¯†ï¼š\nä¼—æ‰€å‘¨çŸ¥ï¼Œå„ç§æ•°å€¼åœ¨è®¡ç®—æœºåº•å±‚æ˜¯é€šè¿‡æ¯”ç‰¹ï¼ˆbitï¼‰æ¥è¿›è¡Œè¡¨ç¤ºçš„ï¼Œæœ‰$0$å’Œ$1$ï¼Œæ¯”å¦‚ç”¨$8$ä¸ªæ¯”ç‰¹å°±å¯ä»¥è¡¨ç¤º$[-2^{7}, 2^{7}-1]$ï¼ˆæœ‰ä¸€ä½æ˜¯ç¬¦å·ä½ï¼‰\né‚£ä¹ˆ float16 çš„æ„æ€æ˜¯ç”¨$16$ä½æ¯”ç‰¹æ¥è¡¨ç¤ºæµ®ç‚¹æ•°ï¼ŒåŒç† float32 çš„æ„æ€æ˜¯ç”¨$32$ä½æ¯”ç‰¹\næŒ‰ç…§è¡¨ç¤ºç²¾åº¦æ¥çœ‹ï¼š $$ \\text{float64 \u003e float32 \u003e float16} $$ æŒ‰ç…§å ç”¨ç©ºé—´æ¥çœ‹ï¼š\n$$ \\text{float16 \u003c float32 \u003c float64 } $$\n$\\inf$çš„æ„æ€æ˜¯è¶…è¿‡äº†å¯ä»¥è¡¨ç¤ºçš„èŒƒå›´ï¼Œæœ‰$-\\inf$å’Œ$\\inf$ä¸¤ç§ï¼Œè€ŒNaNçš„äº§ç”Ÿå¤§æ¦‚å¯ä»¥åˆ†ä¸ºå‡ ç§æƒ…å†µï¼š\nå¯¹è´Ÿæ•°å¼€æ ¹å· å¯¹$\\inf$è¿›è¡Œè¿ç®— é™¤ä»¥$0$ é‚£ä¹ˆå¦‚ä½•æŸ¥çœ‹ä¸åŒè¡¨ç¤ºçš„èŒƒå›´å‘¢ï¼Ÿ\nnp.finfo(np.float16) # finfo(resolution=0.001, min=-6.55040e+04, max=6.55040e+04, dtype=float16) å½“ç„¶ï¼Œnumpy è¿™é‡Œæœ‰ä¸ªå°å‘ï¼Œå°±æ˜¯ä½ è¾“å…¥çš„å€¼è¾ƒå¤§æˆ–ç•¥å¾®è¶…è¿‡èŒƒå›´æ—¶ï¼Œåè€Œä¼šç”¨å¦ä¸€ä¸ªæ•°æ¥è¡¨ç¤ºï¼Œåªæœ‰å¤§åˆ°ä¸€å®šç¨‹åº¦æ—¶ï¼Œæ‰ä¼šç”¨$\\inf$ï¼Œè¯¦è§å®˜ç½‘çš„release notes\nFloating-point arrays and scalars use a new algorithm for decimal representations, giving the shortest unique representation. This will usually shortenÂ float16Â fractional output, and sometimesÂ float32Â andÂ float128Â output.Â float64Â should be unaffected.\na = np.array([65504.], dtype=np.float16) print(a) b = np.array([65388.], dtype=np.float16) print(b) c = np.array([65700.], dtype=np.float16) print(c) # [65500.] # [65380.] # [inf] æ³¨æ„ï¼Œè¿™é‡Œçš„å¤§æ˜¯ç›¸å¯¹äºè®¡ç®—ç²¾åº¦æ¥è¯´çš„ï¼Œè€Œä¸æ˜¯ä½ æ„Ÿè§‰çš„ï¼Œå½“ä½ æŠŠç²¾åº¦è°ƒæˆfloat32ï¼Œä¸Šé¢éƒ½ä¼šæ‰“å°åŸæ¥è¾“å…¥çš„ç»“æœ\neä¹‹æ®‡ åœ¨ä¸Šé«˜ä¸­æ—¶ï¼Œç‰¹åˆ«å–œçˆ±$e^{x}$ï¼Œæœ‰å¾ˆå¤šå¥½çš„æ€§è´¨ï¼Œæ¯”å¦‚æ±‚å¯¼ç­‰äºæœ¬èº«ï¼Œç„¶è€Œåœ¨å¾ˆå¤šæ•°å€¼æº¢å‡ºçš„æƒ…å½¢ï¼Œæ€»æœ‰å®ƒçš„å‚ä¸ï¼Œè¿™æ˜¯å› ä¸ºæœºå™¨å­¦ä¹ ä¸­å¾ˆå¤šä¸œè¥¿éƒ½ä¼šå’Œå®ƒæŒ‚é’©ï¼Œæ¯”å¦‚å„ç§æ¿€æ´»å‡½æ•°ä¾¿æœ‰å®ƒçš„å½±å­\nçœ‹ä¸ªä¾‹å­ï¼š\na = np.exp(np.array([654.], dtype=np.float16)) print(a) # [inf] é‚£ä¹ˆæˆ‘å¦‚ä½•çŸ¥é“è¾“å…¥å¤§æ¦‚å¤šå¤§ä¼šå¯¼è‡´æº¢å‡ºå‘¢ï¼Ÿå¯ä»¥å‚è§ä¸‹è¿°å…¬å¼ï¼Œå½“è¾“å…¥ä¸º$x$ï¼Œè®¡ç®—$e^{x}$ç”¨åè¿›åˆ¶æ•°è¡¨ç¤ºå¤§æ¦‚æœ‰å¤šå°‘ä½\n$$ \\log_{10}(e^x) = x \\log_{10}(e) $$\nä¸¾ä¸ªä¾‹å­ï¼Œä¸Šé¢æˆ‘ä»¬çœ‹åˆ°float16å½“æœ€å¤§ä½æ•°æ˜¯$5$ä½ï¼ˆç§‘å­¦è®¡æ•°æ³•åé¢å¾—$+1$ï¼‰ï¼Œé‚£ä¹ˆæ ¹æ®ä¸Šè¿°å…¬å¼ä½ å°±å¯ä»¥ç®—å‡ºæœ€å¤§å¯è¢«æ¥å—çš„$x$ï¼Œè¿›è€Œè¿›è¡Œä¸€äº›åå¤„ç†ï¼š\ndef compute_max(n): return int(n * math.log(10)) print(compute_max(5)) # 11 æˆ‘ä»¬æ¥è¯•è¯•çœ‹ï¼š\na = np.exp(np.array([11.], dtype=np.float16)) print(a) b = np.exp(np.array([12.], dtype=np.float16)) print(b) # [59870.] # [inf] æ¥ä¸‹æ¥æŒ‰ç…§æ¶ˆé™¤æº¢å‡ºçš„æ–¹æ³•çœ‹çœ‹å‡ å¤§ç±»å¸¸è§ä¾‹å­ï¼š\nå½’ä¸€åŒ–æŒ‡æ•° å½“$\\exp(x_{i})$å½¢å¼å‡ºç°ï¼Œå°±ä¼šè€ƒè™‘é€šè¿‡ä»£æ•°æ’ç­‰å˜æ¢ä½¿å¾—æŒ‡æ•°ä¸Šå¤šä¸€äº›éƒ¨åˆ†æ¥è¿›è¡Œå½’ä¸€åŒ–\nsoftmax ä¸å¦¨å‡è®¾$\\boldsymbol{x} \\in \\mathbb{R}^{n}$ï¼Œå½“æŸä¸ª$x_{i}$ç‰¹åˆ«å¤§æ—¶ï¼Œ$\\exp(x_{i})$å°±ä¼šå‡ºç°æ•°å€¼ä¸Šæº¢ï¼Œç„¶åå½“åˆ†å­åˆ†æ¯éƒ½æ˜¯$\\inf$çš„æ—¶å€™å°±ä¼šå‡ºç°NaNï¼Œ$0$æ˜¯å› ä¸ºåˆ†æ¯æ˜¯$\\inf$å¯¼è‡´çš„\nimport numpy as np def softmax(x): exp = np.exp(x) return exp / exp.sum(-1) x = np.array([-1., 20000, 0.1], dtype=np.float16) softmax(x) # array([ 0., nan, 0.]) é‚£ä¹ˆï¼Œæœ‰ä»€ä¹ˆå¥½çš„æ–¹æ³•æ¥é˜²æ­¢è¿™ç§æ•°å€¼æº¢å‡ºå‘¢ï¼Œæˆ‘ä»¬é€šè¿‡ä¸€äº›ä¸æ”¹å˜åŸå¼çš„ä»£æ•°è¿ç®—å¯ä»¥åšåˆ°ï¼š\n$$ \\begin{align} \\mathrm{softmax}(x_{j}) \u0026 = \\frac{e^{x_{j}}}{\\sum_{i} e^{x_{i}}} \\\\ \u0026= {\\color{#337dff}\\frac{c}{c}} \\cdot \\frac{ e^{x_{j}}}{ \\sum_{i} e^{x_{i}}} \\\\ \u0026= \\frac{e^{x_{j} + \\log c}}{ \\sum_{i} e^{x_{i} +\\log c}} \\end{align} $$ è§‚å¯Ÿä¸Šå¼ï¼Œä¸éš¾å‘ç°ï¼Œæˆ‘ä»¬å¯ä»¥æ§åˆ¶å¸¸æ•°$c$æ¥å¯¹$x_{i}$è¿›è¡Œè§„èŒƒåŒ–ï¼Œç›¸å½“äºåŠ ä¸Šåç§»é‡ï¼ˆoffsetï¼‰\næ¯”è¾ƒç®€å•çš„åšæ³•å³ä¸ºè®¾ç½®$\\log c = -\\max(\\boldsymbol{x})$\né‚£ä¹ˆï¼š\n$$ \\mathrm{softmax}(x_{j}) = \\frac{e^{x_{j} - \\max(\\boldsymbol{x})}}{\\sum_{i} e^{x_{i} - \\max(\\boldsymbol{x})}} $$\nä»£ç å®ç°å³ä¸ºï¼š\ndef softmax(x): x -= max(x) exp = np.exp(x) return exp / exp.sum(-1) softmax(x) # array([0., 1., 0.]) å› ä¸ºæœ€å¤§çš„æ•°å‡å»è‡ªèº«å˜ä¸ºäº†$0$ï¼Œ$e^{0} = 1$ï¼Œå°±ä¸ä¼šæœ‰ä»€ä¹ˆå½±å“äº†\nè¿™ä¸ªä¸PyTorchå®˜æ–¹å®ç°ä¹Ÿæ˜¯ä¸€è‡´çš„ï¼š\nimport torch import torch.nn.functional as F x = torch.tensor([-1., 20000, 0.1]) F.softmax(x) # tensor([0., 1., 0.]) Logsumexp åŒç†å†çœ‹ä¸€ä¸ªç±»ä¼¼çš„ï¼š\n$$ \\begin{align} \\text{Logsumexp}(\\boldsymbol{x}) \u0026= \\log \\sum_{i} e^{x_{i}} \\\\ \u0026= \\log \\sum_{i} e^{x_{i}} \\frac{c}{c} \\\\ \u0026= \\log \\left( \\frac{1}{c} \\sum_{i} e^{x_{i}} e^{\\log c}\\right) \\\\ \u0026= -\\log c + \\log \\sum_{i} e^{x_{i} + \\log c} \\end{align} $$\nå–$\\log c=-\\max(\\boldsymbol{x})$ï¼Œé‚£ä¹ˆï¼š\n$$ \\text{logsumexp}(\\boldsymbol{x}) = \\max(\\boldsymbol{x}) + \\log \\sum_{i} e^{x_{i}-\\max(\\boldsymbol{x})} $$\ndef logsumexp(x): maximum = max(x) x -= maximum exp = np.exp(x) return maximum + np.log(exp.sum(-1)) è·Ÿ PyTorch å®˜æ–¹å®ç°ä¸€è‡´ï¼š\nprint(torch.logsumexp(x, dim=-1, keepdim=False)) print(logsumexp(x.numpy())) # tensor(200000.) # 200000.0 å±•å¼€logå†…éƒ¨ å°±æ˜¯å°†logæ˜æ˜¾å¯èƒ½å‡ºç°æ•°å€¼æº¢å‡ºçš„éƒ¨åˆ†æ‹†å‡ºæ¥ï¼Œåˆšåˆšlogsumexpå°±æ˜¯åˆ©ç”¨äº†è¿™ä¸ªé“ç†\nlog-softmax å°½ç®¡softmaxç°åœ¨ç¨³å®šäº†ï¼Œç„¶è€Œlog-softmaxè¿˜æ˜¯æœ‰é£é™©æº¢å‡ºï¼Œæ¯”å¦‚ä¸Šé¢çš„$\\log 0$ï¼Œè¿™ä¹Ÿæ˜¯æ•°å€¼ä¸Šæº¢\n$$ \\mathrm{LogSoftmax}(x_{j}) = \\log\\left(\\frac{e^{x_{j}}}{\\sum_{i} e ^{x_{i}}}\\right) $$ æˆ‘ä»¬å°†å…¶æ‹†å¼€ï¼š $$ \\begin{align} \\mathrm{LogSoftmax}(x_{j}) \u0026 = \\log \\left( \\frac{e^{x_{j} - \\max(\\boldsymbol{x})}}{\\sum_{i} e^{x_{i}-\\max(\\boldsymbol{x})}} \\right) \\\\ \u0026= \\log(e^{x_{j} - \\max(\\boldsymbol{x})}) - \\log \\left( \\sum_{i} e^{x_{i}-\\max(\\boldsymbol{x})}\\right) \\\\ \u0026= x_{j} - \\max(\\boldsymbol{x}) - \\log \\underbrace{ \\left( \\sum_{i} e^{x_{i}-\\max(\\boldsymbol{x})}\\right) }_{ \\ge 1 } \\end{align} $$\nå› ä¸ºæ‰€æœ‰çš„$x_{i}$ä¸­è‚¯å®šæœ‰æœ€å¤§çš„ä¸€ä¸ªï¼Œé‚£ä¹ˆ$\\exp(x_{i} -\\max(\\boldsymbol{x}))=1$ï¼Œå‰©ä¸‹çš„è‚¯å®šæ˜¯æ­£æ•°\ndef log_softmax(x): x -= max(x) exp = np.exp(x) return x - np.log(exp.sum(-1)) åŒæ ·ä¸PyTorchä¸€è‡´ï¼Œåé¢æ˜¯ä¸¤ä¸ªæ¡†æ¶æ˜¾ç¤ºæœºåˆ¶ä¸åŒï¼Œä»è¿™ä¸ªè§’åº¦ä¹Ÿå¯ä»¥çœ‹å‡ºï¼Œéƒ½æ˜¯32ä½æ—¶ï¼ŒPyTorchä¼šæ›´ç²¾å‡†\nx = torch.tensor([-1., 200000, 0.1]) print(F.log_softmax(x, dim=-1)) print(log_softmax(x.numpy())) # tensor([-200001.0000, 0.0000, -199999.9062]) # array([-200001. , 0. , -199999.9], dtype=float32) æˆªæ–­ å½“è¾“å…¥å¤§äºæŸç§é˜ˆå€¼ï¼Œç›´æ¥è¾“å‡ºåŸæ¥çš„è¾“å…¥\nSoftplus ä¸‹é¢æ˜¯PyTorchå®˜æ–¹å¯¹äºSoftplusçš„å®ç°\n$$ \\text{Softplus}({x}) = \\begin{cases} \\log (1 + e^{x}), \u0026 x \\leq \\text{threshold} \\\\ x, \u0026 \\text{otherwise} \\end{cases} $$ å®˜æ–¹çš„æ„æ€å¾ˆç®€å•ï¼Œå½“$x$å¤§äºé˜ˆå€¼ï¼ˆè¿™é‡Œæ˜¯ç½®ä¹‹ä¸º$20$ï¼‰ï¼Œç›´æ¥ä¸å˜è¾“å‡º\neps æ€¥æ•‘åŒ… å½“åˆ†æ¯å¯èƒ½å‡ºç°ä¸º$0$æ—¶ï¼Œç»™å®ƒåŠ ä¸Šä¸€ä¸ªè¾ƒå°çš„æ­£æ•°$\\varepsilon$\nLayer Normalization $$ \\text{LayerNorm}(\\boldsymbol{x}) = \\gamma \\left(\\frac{\\boldsymbol{x} - \\bar{\\boldsymbol{x}}}{\\sigma + {\\color{#337dff}\\varepsilon}} \\right) + \\beta $$ åˆ†æ¯åŠ ä¸Šä¸€ä¸ª$\\varepsilon$æ¥é˜²æ­¢å˜ä¸º$0$ï¼š\nclass LayerNorm(nn.Module): def init(self, features, eps=1e-6): super().__init__() self.gamma = nn.Parameter(torch.ones(features)) self.beta = nn.Parameter(torch.zeros(features)) self.eps = eps def forward(self, x): mean = x.mean(-1, keepdim=True) std = x.std(-1, keepdim=True) return self.gamma * (x - mean) / (std + self.eps) + self.beta ","wordCount":"2100","inLanguage":"en","datePublished":"2023-06-25T21:10:00+08:00","dateModified":"2023-06-25T21:10:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://yunpengtai.top/posts/numerical-stability/"},"publisher":{"@type":"Organization","name":"Tai's Blog","logo":{"@type":"ImageObject","url":"http://yunpengtai.top/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://yunpengtai.top accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://yunpengtai.top/archives/ title=å½’æ¡£><span>å½’æ¡£</span></a></li><li><a href=http://yunpengtai.top/search/ title="æœç´¢ (Alt + /)" accesskey=/><span>æœç´¢</span></a></li><li><a href=http://yunpengtai.top/tags/ title=æ ‡ç­¾><span>æ ‡ç­¾</span></a></li><li><a href=http://yunpengtai.top/friends/ title=å‹äºº><span>å‹äºº</span></a></li><li><a href=http://yunpengtai.top/about/ title=å…³äº><span>å…³äº</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://yunpengtai.top>Home</a>&nbsp;Â»&nbsp;<a href=http://yunpengtai.top/posts/>Posts</a></div><h1 class=post-title>Numerical Stability</h1><div class=post-meta><span title='2023-06-25 21:10:00 +0800 CST'>June 25, 2023</span>&nbsp;Â·&nbsp;2100 words</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#why aria-label=Why>Why</a></li><li><a href=#%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86 aria-label=åŸºç¡€çŸ¥è¯†>åŸºç¡€çŸ¥è¯†</a></li><li><a href=#e%e4%b9%8b%e6%ae%87 aria-label=eä¹‹æ®‡>eä¹‹æ®‡</a></li><li><a href=#%e5%bd%92%e4%b8%80%e5%8c%96%e6%8c%87%e6%95%b0 aria-label=å½’ä¸€åŒ–æŒ‡æ•°>å½’ä¸€åŒ–æŒ‡æ•°</a><ul><li><a href=#softmax aria-label=softmax>softmax</a></li><li><a href=#logsumexp aria-label=Logsumexp>Logsumexp</a></li></ul></li><li><a href=#%e5%b1%95%e5%bc%80log%e5%86%85%e9%83%a8 aria-label=å±•å¼€logå†…éƒ¨>å±•å¼€logå†…éƒ¨</a><ul><li><a href=#log-softmax aria-label=log-softmax>log-softmax</a></li></ul></li><li><a href=#%e6%88%aa%e6%96%ad aria-label=æˆªæ–­>æˆªæ–­</a><ul><li><a href=#softplus aria-label=Softplus>Softplus</a></li></ul></li><li><a href=#eps-%e6%80%a5%e6%95%91%e5%8c%85 aria-label="eps æ€¥æ•‘åŒ…">eps æ€¥æ•‘åŒ…</a><ul><li><a href=#layer-normalization aria-label="Layer Normalization">Layer Normalization</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=why>Why<a hidden class=anchor aria-hidden=true href=#why>#</a></h2><p>å½“è®¡ç®—æ¶‰åŠåˆ°å®æ•°åŸŸæ—¶ï¼Œæ¯”å¦‚åœ†å‘¨ç‡çš„<code>$\pi$</code>ï¼Œå› ä¸ºå°æ•°éƒ¨åˆ†æ˜¯æ— ç©·çš„ï¼Œè®¡ç®—æœºæ˜¯æ— æ³•å‡†ç¡®è¡¨ç¤ºï¼Œå› è€Œåªä¼šç”¨è¿‘ä¼¼çš„å€¼è¿›è¡Œæ›¿ä»£ï¼Œè¿™ç§æƒ…å†µä¸‹ï¼Œè¯¯å·®ç›¸å¯¹è¾ƒå°å½±å“ä¸å¤§ï¼›ç„¶è€Œï¼Œå¦‚æœæ•°å€¼å¤§äºæŸä¸ªç‰¹å®šå€¼ä¹‹åå˜æˆäº†<code>$\inf$</code>ï¼ˆæ•°å€¼ä¸Šæº¢ Overflow ï¼‰ï¼Œè¿˜æœ‰ä¸€ç§æƒ…å†µæ˜¯å½“æ•°å€¼ç‰¹åˆ«å°æ—¶ï¼Œä¼šè¢«è¿‘ä¼¼ä¸º<code>$0$</code>ï¼ˆæ•°å€¼ä¸‹æº¢ Underflowï¼‰ï¼Œè¿™ä¸¤ç§æƒ…å½¢è‹¥ç»§ç»­è®¡ç®—è¯¯å·®å°†ä¼šè¿›ä¸€æ­¥ç´¯ç§¯ï¼Œé‚£ä¹ˆå°±å¯èƒ½å¯¼è‡´åŸæœ¬ç†è®ºä¸Šæˆç«‹çš„åˆ°å®ç°æ—¶å°±ä¸è¡Œäº†ï¼Œæ­¤æ—¶å°±æœ‰å¿…è¦å¯¹æ•°å€¼ç¨³å®šæ€§è¿›è¡Œåˆ†æ</p><p>ä¸¾ä¸ªä¾‹å­ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>65599.</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>1e-10</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=n>inf</span><span class=p>]</span> <span class=c1># Overflow</span>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=mf>0.</span><span class=p>]</span> <span class=c1># Underflow</span>
</span></span></code></pre></div><h2 id=åŸºç¡€çŸ¥è¯†>åŸºç¡€çŸ¥è¯†<a hidden class=anchor aria-hidden=true href=#åŸºç¡€çŸ¥è¯†>#</a></h2><p>å†è¿›ä¸€æ­¥è§£é‡Šè§£å†³æ–¹æ³•æ—¶è¿˜æ˜¯å…ˆé“ºå«åŸºç¡€çŸ¥è¯†ï¼š</p><p>ä¼—æ‰€å‘¨çŸ¥ï¼Œå„ç§æ•°å€¼åœ¨è®¡ç®—æœºåº•å±‚æ˜¯é€šè¿‡æ¯”ç‰¹ï¼ˆbitï¼‰æ¥è¿›è¡Œè¡¨ç¤ºçš„ï¼Œæœ‰<code>$0$</code>å’Œ<code>$1$</code>ï¼Œæ¯”å¦‚ç”¨<code>$8$</code>ä¸ªæ¯”ç‰¹å°±å¯ä»¥è¡¨ç¤º<code>$[-2^{7}, 2^{7}-1]$</code>ï¼ˆæœ‰ä¸€ä½æ˜¯ç¬¦å·ä½ï¼‰</p><p>é‚£ä¹ˆ <code>float16</code> çš„æ„æ€æ˜¯ç”¨<code>$16$</code>ä½æ¯”ç‰¹æ¥è¡¨ç¤ºæµ®ç‚¹æ•°ï¼ŒåŒç† <code>float32</code> çš„æ„æ€æ˜¯ç”¨<code>$32$</code>ä½æ¯”ç‰¹</p><p>æŒ‰ç…§è¡¨ç¤ºç²¾åº¦æ¥çœ‹ï¼š
<code>$$ \text{float64 > float32 > float16} $$</code>
æŒ‰ç…§å ç”¨ç©ºé—´æ¥çœ‹ï¼š</p><p><code>$$ \text{float16 &lt; float32 &lt; float64 } $$</code></p><p><code>$\inf$</code>çš„æ„æ€æ˜¯è¶…è¿‡äº†å¯ä»¥è¡¨ç¤ºçš„èŒƒå›´ï¼Œæœ‰<code>$-\inf$</code>å’Œ<code>$\inf$</code>ä¸¤ç§ï¼Œè€ŒNaNçš„äº§ç”Ÿå¤§æ¦‚å¯ä»¥åˆ†ä¸ºå‡ ç§æƒ…å†µï¼š</p><ul><li>å¯¹è´Ÿæ•°å¼€æ ¹å·</li><li>å¯¹<code>$\inf$</code>è¿›è¡Œè¿ç®—</li><li>é™¤ä»¥<code>$0$</code></li></ul><p>é‚£ä¹ˆå¦‚ä½•æŸ¥çœ‹ä¸åŒè¡¨ç¤ºçš„èŒƒå›´å‘¢ï¼Ÿ</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>finfo</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># finfo(resolution=0.001, min=-6.55040e+04, max=6.55040e+04, dtype=float16)</span>
</span></span></code></pre></div><p>å½“ç„¶ï¼Œnumpy è¿™é‡Œæœ‰ä¸ªå°å‘ï¼Œå°±æ˜¯ä½ è¾“å…¥çš„å€¼è¾ƒå¤§æˆ–ç•¥å¾®è¶…è¿‡èŒƒå›´æ—¶ï¼Œåè€Œä¼šç”¨å¦ä¸€ä¸ªæ•°æ¥è¡¨ç¤ºï¼Œåªæœ‰å¤§åˆ°ä¸€å®šç¨‹åº¦æ—¶ï¼Œæ‰ä¼šç”¨<code>$\inf$</code>ï¼Œè¯¦è§å®˜ç½‘çš„<a href=https://docs.scipy.org/doc/numpy-1.14.0/release.html#many-changes-to-array-printing-disableable-with-the-new-legacy-printing-mode>release notes</a></p><div class="notice notice-note"><div class=notice-title><svg xmlns="http://www.w3.org/2000/svg" class="icon notice-icon" viewBox="0 0 512 512"><path d="M504 256A248 248 0 118 256a248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165 8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z"/></svg></div><p>Floating-point arrays and scalars use a new algorithm for decimal representations, giving the shortest unique representation. This will usually shortenÂ float16Â fractional output, and sometimesÂ float32Â andÂ float128Â output.Â float64Â should be unaffected.</p></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>65504.</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>65388.</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>c</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>65700.</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>c</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># [65500.]</span>
</span></span><span class=line><span class=cl><span class=c1># [65380.]</span>
</span></span><span class=line><span class=cl><span class=c1># [inf]</span>
</span></span></code></pre></div><p>æ³¨æ„ï¼Œè¿™é‡Œçš„å¤§æ˜¯ç›¸å¯¹äºè®¡ç®—ç²¾åº¦æ¥è¯´çš„ï¼Œè€Œä¸æ˜¯ä½ æ„Ÿè§‰çš„ï¼Œå½“ä½ æŠŠç²¾åº¦è°ƒæˆ<code>float32</code>ï¼Œä¸Šé¢éƒ½ä¼šæ‰“å°åŸæ¥è¾“å…¥çš„ç»“æœ</p><h2 id=eä¹‹æ®‡>eä¹‹æ®‡<a hidden class=anchor aria-hidden=true href=#eä¹‹æ®‡>#</a></h2><p>åœ¨ä¸Šé«˜ä¸­æ—¶ï¼Œç‰¹åˆ«å–œçˆ±<code>$e^{x}$</code>ï¼Œæœ‰å¾ˆå¤šå¥½çš„æ€§è´¨ï¼Œæ¯”å¦‚æ±‚å¯¼ç­‰äºæœ¬èº«ï¼Œç„¶è€Œåœ¨å¾ˆå¤šæ•°å€¼æº¢å‡ºçš„æƒ…å½¢ï¼Œæ€»æœ‰å®ƒçš„å‚ä¸ï¼Œè¿™æ˜¯å› ä¸ºæœºå™¨å­¦ä¹ ä¸­å¾ˆå¤šä¸œè¥¿éƒ½ä¼šå’Œå®ƒæŒ‚é’©ï¼Œæ¯”å¦‚å„ç§æ¿€æ´»å‡½æ•°ä¾¿æœ‰å®ƒçš„å½±å­</p><p>çœ‹ä¸ªä¾‹å­ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>654.</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># [inf]</span>
</span></span></code></pre></div><p>é‚£ä¹ˆæˆ‘å¦‚ä½•çŸ¥é“è¾“å…¥å¤§æ¦‚å¤šå¤§ä¼šå¯¼è‡´æº¢å‡ºå‘¢ï¼Ÿå¯ä»¥å‚è§ä¸‹è¿°å…¬å¼ï¼Œå½“è¾“å…¥ä¸º<code>$x$</code>ï¼Œè®¡ç®—<code>$e^{x}$</code>ç”¨åè¿›åˆ¶æ•°è¡¨ç¤ºå¤§æ¦‚æœ‰å¤šå°‘ä½</p><p><code>$$ \log_{10}(e^x) = x \log_{10}(e) $$</code></p><p>ä¸¾ä¸ªä¾‹å­ï¼Œä¸Šé¢æˆ‘ä»¬çœ‹åˆ°<code>float16</code>å½“æœ€å¤§ä½æ•°æ˜¯<code>$5$</code>ä½ï¼ˆç§‘å­¦è®¡æ•°æ³•åé¢å¾—<code>$+1$</code>ï¼‰ï¼Œé‚£ä¹ˆæ ¹æ®ä¸Šè¿°å…¬å¼ä½ å°±å¯ä»¥ç®—å‡ºæœ€å¤§å¯è¢«æ¥å—çš„<code>$x$</code>ï¼Œè¿›è€Œè¿›è¡Œä¸€äº›åå¤„ç†ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_max</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>int</span><span class=p>(</span><span class=n>n</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mi>10</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>compute_max</span><span class=p>(</span><span class=mi>5</span><span class=p>))</span> <span class=c1># 11</span>
</span></span></code></pre></div><p>æˆ‘ä»¬æ¥è¯•è¯•çœ‹ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>11.</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>12.</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># [59870.]</span>
</span></span><span class=line><span class=cl><span class=c1># [inf]</span>
</span></span></code></pre></div><p>æ¥ä¸‹æ¥æŒ‰ç…§æ¶ˆé™¤æº¢å‡ºçš„æ–¹æ³•çœ‹çœ‹å‡ å¤§ç±»å¸¸è§ä¾‹å­ï¼š</p><h2 id=å½’ä¸€åŒ–æŒ‡æ•°>å½’ä¸€åŒ–æŒ‡æ•°<a hidden class=anchor aria-hidden=true href=#å½’ä¸€åŒ–æŒ‡æ•°>#</a></h2><p>å½“<code>$\exp(x_{i})$</code>å½¢å¼å‡ºç°ï¼Œå°±ä¼šè€ƒè™‘é€šè¿‡ä»£æ•°æ’ç­‰å˜æ¢ä½¿å¾—æŒ‡æ•°ä¸Šå¤šä¸€äº›éƒ¨åˆ†æ¥è¿›è¡Œå½’ä¸€åŒ–</p><h3 id=softmax>softmax<a hidden class=anchor aria-hidden=true href=#softmax>#</a></h3><p>ä¸å¦¨å‡è®¾<code>$\boldsymbol{x} \in \mathbb{R}^{n}$</code>ï¼Œå½“æŸä¸ª<code>$x_{i}$</code>ç‰¹åˆ«å¤§æ—¶ï¼Œ<code>$\exp(x_{i})$</code>å°±ä¼šå‡ºç°æ•°å€¼ä¸Šæº¢ï¼Œç„¶åå½“åˆ†å­åˆ†æ¯éƒ½æ˜¯<code>$\inf$</code>çš„æ—¶å€™å°±ä¼šå‡ºç°NaNï¼Œ<code>$0$</code>æ˜¯å› ä¸ºåˆ†æ¯æ˜¯<code>$\inf$</code>å¯¼è‡´çš„</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>softmax</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>exp</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>exp</span> <span class=o>/</span> <span class=n>exp</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=o>-</span><span class=mf>1.</span><span class=p>,</span> <span class=mi>20000</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>softmax</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># array([ 0., nan, 0.])</span>
</span></span></code></pre></div><p>é‚£ä¹ˆï¼Œæœ‰ä»€ä¹ˆå¥½çš„æ–¹æ³•æ¥é˜²æ­¢è¿™ç§æ•°å€¼æº¢å‡ºå‘¢ï¼Œæˆ‘ä»¬é€šè¿‡ä¸€äº›ä¸æ”¹å˜åŸå¼çš„ä»£æ•°è¿ç®—å¯ä»¥åšåˆ°ï¼š</p><p><code>$$ \begin{align} \mathrm{softmax}(x_{j}) & = \frac{e^{x_{j}}}{\sum_{i} e^{x_{i}}} \\ &= {\color{#337dff}\frac{c}{c}} \cdot \frac{ e^{x_{j}}}{ \sum_{i} e^{x_{i}}} \\ &= \frac{e^{x_{j} + \log c}}{ \sum_{i} e^{x_{i} +\log c}} \end{align} $$</code>
è§‚å¯Ÿä¸Šå¼ï¼Œä¸éš¾å‘ç°ï¼Œæˆ‘ä»¬å¯ä»¥æ§åˆ¶å¸¸æ•°<code>$c$</code>æ¥å¯¹<code>$x_{i}$</code>è¿›è¡Œè§„èŒƒåŒ–ï¼Œç›¸å½“äºåŠ ä¸Šåç§»é‡ï¼ˆoffsetï¼‰</p><p>æ¯”è¾ƒç®€å•çš„åšæ³•å³ä¸ºè®¾ç½®<code>$\log c = -\max(\boldsymbol{x})$</code></p><p>é‚£ä¹ˆï¼š</p><p><code>$$ \mathrm{softmax}(x_{j}) = \frac{e^{x_{j} - \max(\boldsymbol{x})}}{\sum_{i} e^{x_{i} - \max(\boldsymbol{x})}} $$</code></p><p>ä»£ç å®ç°å³ä¸ºï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>softmax</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>-=</span> <span class=nb>max</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>exp</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>exp</span> <span class=o>/</span> <span class=n>exp</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>softmax</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># array([0., 1., 0.])</span>
</span></span></code></pre></div><p>å› ä¸ºæœ€å¤§çš„æ•°å‡å»è‡ªèº«å˜ä¸ºäº†<code>$0$</code>ï¼Œ<code>$e^{0} = 1$</code>ï¼Œå°±ä¸ä¼šæœ‰ä»€ä¹ˆå½±å“äº†</p><p>è¿™ä¸ªä¸PyTorchå®˜æ–¹å®ç°ä¹Ÿæ˜¯ä¸€è‡´çš„ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=o>-</span><span class=mf>1.</span><span class=p>,</span> <span class=mi>20000</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># tensor([0., 1., 0.])</span>
</span></span></code></pre></div><h3 id=logsumexp>Logsumexp<a hidden class=anchor aria-hidden=true href=#logsumexp>#</a></h3><p>åŒç†å†çœ‹ä¸€ä¸ªç±»ä¼¼çš„ï¼š</p><p><code>$$ \begin{align} \text{Logsumexp}(\boldsymbol{x}) &= \log \sum_{i} e^{x_{i}} \\ &= \log \sum_{i} e^{x_{i}} \frac{c}{c} \\ &= \log \left( \frac{1}{c} \sum_{i} e^{x_{i}} e^{\log c}\right) \\ &= -\log c + \log \sum_{i} e^{x_{i} + \log c} \end{align} $$</code></p><p>å–<code>$\log c=-\max(\boldsymbol{x})$</code>ï¼Œé‚£ä¹ˆï¼š</p><p><code>$$ \text{logsumexp}(\boldsymbol{x}) = \max(\boldsymbol{x}) + \log \sum_{i} e^{x_{i}-\max(\boldsymbol{x})} $$</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>logsumexp</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>maximum</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>-=</span> <span class=n>maximum</span>
</span></span><span class=line><span class=cl>    <span class=n>exp</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>maximum</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>exp</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span>
</span></span></code></pre></div><p>è·Ÿ PyTorch å®˜æ–¹å®ç°ä¸€è‡´ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>logsumexp</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>False</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>logsumexp</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>numpy</span><span class=p>()))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># tensor(200000.)</span>
</span></span><span class=line><span class=cl><span class=c1># 200000.0</span>
</span></span></code></pre></div><h2 id=å±•å¼€logå†…éƒ¨>å±•å¼€logå†…éƒ¨<a hidden class=anchor aria-hidden=true href=#å±•å¼€logå†…éƒ¨>#</a></h2><p>å°±æ˜¯å°†logæ˜æ˜¾å¯èƒ½å‡ºç°æ•°å€¼æº¢å‡ºçš„éƒ¨åˆ†æ‹†å‡ºæ¥ï¼Œåˆšåˆšlogsumexpå°±æ˜¯åˆ©ç”¨äº†è¿™ä¸ªé“ç†</p><h3 id=log-softmax>log-softmax<a hidden class=anchor aria-hidden=true href=#log-softmax>#</a></h3><p>å°½ç®¡softmaxç°åœ¨ç¨³å®šäº†ï¼Œç„¶è€Œlog-softmaxè¿˜æ˜¯æœ‰é£é™©æº¢å‡ºï¼Œæ¯”å¦‚ä¸Šé¢çš„<code>$\log 0$</code>ï¼Œè¿™ä¹Ÿæ˜¯æ•°å€¼ä¸Šæº¢</p><p><code>$$ \mathrm{LogSoftmax}(x_{j}) = \log\left(\frac{e^{x_{j}}}{\sum_{i} e ^{x_{i}}}\right) $$</code>
æˆ‘ä»¬å°†å…¶æ‹†å¼€ï¼š
<code>$$ \begin{align} \mathrm{LogSoftmax}(x_{j}) & = \log \left( \frac{e^{x_{j} - \max(\boldsymbol{x})}}{\sum_{i} e^{x_{i}-\max(\boldsymbol{x})}} \right) \\ &= \log(e^{x_{j} - \max(\boldsymbol{x})}) - \log \left( \sum_{i} e^{x_{i}-\max(\boldsymbol{x})}\right) \\ &= x_{j} - \max(\boldsymbol{x}) - \log \underbrace{ \left( \sum_{i} e^{x_{i}-\max(\boldsymbol{x})}\right) }_{ \ge 1 } \end{align} $$</code></p><p>å› ä¸ºæ‰€æœ‰çš„<code>$x_{i}$</code>ä¸­è‚¯å®šæœ‰æœ€å¤§çš„ä¸€ä¸ªï¼Œé‚£ä¹ˆ<code>$\exp(x_{i} -\max(\boldsymbol{x}))=1$</code>ï¼Œå‰©ä¸‹çš„è‚¯å®šæ˜¯æ­£æ•°</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>log_softmax</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>-=</span> <span class=nb>max</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>exp</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>x</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>exp</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span>
</span></span></code></pre></div><p>åŒæ ·ä¸PyTorchä¸€è‡´ï¼Œåé¢æ˜¯ä¸¤ä¸ªæ¡†æ¶æ˜¾ç¤ºæœºåˆ¶ä¸åŒï¼Œä»è¿™ä¸ªè§’åº¦ä¹Ÿå¯ä»¥çœ‹å‡ºï¼Œéƒ½æ˜¯32ä½æ—¶ï¼ŒPyTorchä¼šæ›´ç²¾å‡†</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=o>-</span><span class=mf>1.</span><span class=p>,</span> <span class=mi>200000</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>log_softmax</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>log_softmax</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>numpy</span><span class=p>()))</span>
</span></span><span class=line><span class=cl><span class=c1># tensor([-200001.0000, 0.0000, -199999.9062])</span>
</span></span><span class=line><span class=cl><span class=c1># array([-200001. , 0. , -199999.9], dtype=float32)</span>
</span></span></code></pre></div><h2 id=æˆªæ–­>æˆªæ–­<a hidden class=anchor aria-hidden=true href=#æˆªæ–­>#</a></h2><p>å½“è¾“å…¥å¤§äºæŸç§é˜ˆå€¼ï¼Œç›´æ¥è¾“å‡ºåŸæ¥çš„è¾“å…¥</p><h3 id=softplus>Softplus<a hidden class=anchor aria-hidden=true href=#softplus>#</a></h3><p>ä¸‹é¢æ˜¯PyTorchå®˜æ–¹å¯¹äºSoftplusçš„<a href=https://pytorch.org/docs/stable/generated/torch.nn.Softplus.html#torch.nn.Softplus>å®ç°</a></p><p><code>$$ \text{Softplus}({x}) = \begin{cases} \log (1 + e^{x}), & x \leq \text{threshold} \\ x, & \text{otherwise} \end{cases} $$</code>
å®˜æ–¹çš„æ„æ€å¾ˆç®€å•ï¼Œå½“<code>$x$</code>å¤§äºé˜ˆå€¼ï¼ˆè¿™é‡Œæ˜¯ç½®ä¹‹ä¸º<code>$20$</code>ï¼‰ï¼Œç›´æ¥ä¸å˜è¾“å‡º</p><h2 id=eps-æ€¥æ•‘åŒ…>eps æ€¥æ•‘åŒ…<a hidden class=anchor aria-hidden=true href=#eps-æ€¥æ•‘åŒ…>#</a></h2><p>å½“åˆ†æ¯å¯èƒ½å‡ºç°ä¸º<code>$0$</code>æ—¶ï¼Œç»™å®ƒåŠ ä¸Šä¸€ä¸ªè¾ƒå°çš„æ­£æ•°<code>$\varepsilon$</code></p><h3 id=layer-normalization>Layer Normalization<a hidden class=anchor aria-hidden=true href=#layer-normalization>#</a></h3><p><code>$$ \text{LayerNorm}(\boldsymbol{x}) = \gamma \left(\frac{\boldsymbol{x} - \bar{\boldsymbol{x}}}{\sigma + {\color{#337dff}\varepsilon}} \right) + \beta $$</code>
åˆ†æ¯åŠ ä¸Šä¸€ä¸ª<code>$\varepsilon$</code>æ¥é˜²æ­¢å˜ä¸º<code>$0$</code>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>LayerNorm</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>init</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>features</span><span class=p>,</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>features</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>beta</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>features</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>=</span> <span class=n>eps</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>mean</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>*</span> <span class=p>(</span><span class=n>x</span> <span class=o>-</span> <span class=n>mean</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>std</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>eps</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>beta</span>
</span></span></code></pre></div></div><div style="margin-top:2em;padding:1em;border:0 solid;border-radius:10px;background-color:var(--code-bg)"><h3>ğŸ±å¦‚æœæ‚¨æƒ³è¦å¼•ç”¨ï¼Œè¯·è€ƒè™‘å¦‚ä¸‹æ ¼å¼ï¼š</h3><div style=padding-top:.5em>å°è¿é¹. (Jun. 25, 2023). ã€ŠNumerical Stabilityã€‹[Blog
post]. Retrieved from http://yunpengtai.top/posts/numerical-stability/</div><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>@online{blog-08a4376a133de6eb59875a437b4d4360,
</span></span><span class=line><span class=cl>        title=Numerical Stability,
</span></span><span class=line><span class=cl>        author={Yunpeng Tai},
</span></span><span class=line><span class=cl>        year=2023,
</span></span><span class=line><span class=cl>        month=Jun,
</span></span><span class=line><span class=cl>        url=http://yunpengtai.top/posts/numerical-stability/,
</span></span><span class=line><span class=cl>        note=yunpengtai.typ@gmail.com,
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><div style=padding-bottom:.4em>è‡ªç”±è½¬è½½-éå•†ç”¨-éè¡ç”Ÿ-ä¿æŒç½²åï¼ˆ<a href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-SA 4.0ï¼‰</a></div></div><footer class=post-footer><ul class=post-tags><li><a href=http://yunpengtai.top/tags/training/>training</a></li></ul><nav class=paginav><a class=prev href=http://yunpengtai.top/posts/nce-friends/><span class=title>Â« Prev</span><br><span>NCE çš„æœ‹å‹ä»¬</span></a>
<a class=next href=http://yunpengtai.top/posts/bias-variance-decomposition/><span class=title>Next Â»</span><br><span>Bias Variance Decomposition</span></a></nav></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/artalk/2.8.6/Artalk.js></script>
<script src=https://unpkg.com/@artalk/plugin-katex@latest/dist/artalk-plugin-katex.js></script><div id=Comments></div><script>const artalk=Artalk.init({el:"#Comments",pageKey:"",pageTitle:"Numerical Stability",server:"https://comment.yunpengtai.top",site:"Tai's Blog",darkMode:"auto"});document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?artalk.setDarkMode(!1):artalk.setDarkMode(!0)})</script></article></main><footer class=footer><span>&copy; 2024 <a href=http://yunpengtai.top>Tai's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/sherlcok314159/MyPaperMod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("/js/pangu.min.js",function(){pangu.spacingPage()})</script><script>(function(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}})()</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>